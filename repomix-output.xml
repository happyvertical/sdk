This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.changeset/
  config.json
  README.md
.gitea/
  workflows/
    agents/
      claude/
        on-assigned-issue.yaml
        on-assigned-pr.yaml
        test-issue-trigger.yaml
    on-merge-master.yaml
.github/
  workflows/
    agents/
      claude.yaml
    on-pr-master-dependabot.yml
  config-dependabot.yml
.husky/
  _/
    pre-commit
    prepare-commit-msg
packages/
  ai/
    src/
      client.ts
      index.spec.ts
      index.ts
      message.ts
      thread.ts
    CLAUDE.md
    package.json
    README.md
    tsconfig.json
  files/
    src/
      fetch.ts
      filesystem-local.ts
      filesystem.ts
      index.spec.ts
      index.ts
    CLAUDE.md
    package.json
    tsconfig.json
  pdf/
    src/
      index.spec.ts
      index.ts
      modules.d.ts
    CLAUDE.md
    package.json
    tsconfig.json
  smrt/
    src/
      class.ts
      collection.ts
      content.ts
      contents.spec.ts
      contents.ts
      document.ts
      fields.ts
      human.ts
      index.ts
      object.ts
      pleb.ts
      utils.spec.ts
      utils.ts
    CLAUDE.md
    package.json
    README.md
    tsconfig.json
  spider/
    src/
      crawl4ai.spec.ts
      crawl4ai.ts
      index.spec.ts
      index.ts
    CLAUDE.md
    package.json
    tsconfig.json
  sql/
    src/
      index.spec.ts
      index.ts
      postgres.spec.ts
      postgres.ts
      sqlite.spec.ts
      sqlite.ts
      types.ts
    .gitignore
    .prettierrc
    CLAUDE.md
    docker-compose.yml
    package.json
    README.md
    tsconfig.json
  utils/
    src/
      index.spec.ts
      index.ts
    CLAUDE.md
    package.json
    tsconfig.json
scripts/
  update-package-versions.cjs
.gitignore
.nvmrc
biome.json
CHANGELOG.md
CLAUDE.md
CONTRIBUTING.md
lefthook.yml
LICENSE
package.json
pnpm-workspace.yaml
README.md
setup_dev.sh
tsconfig.json
vitest.config.ts
vitest.setup.ts
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".changeset/config.json">
{
  "$schema": "https://unpkg.com/@changesets/config@3.0.4/schema.json",
  "changelog": "@changesets/cli/changelog",
  "commit": false,
  "fixed": [],
  "linked": [],
  "access": "restricted",
  "baseBranch": "main",
  "updateInternalDependencies": "patch",
  "ignore": []
}
</file>

<file path=".changeset/README.md">
# Changesets

Hello and welcome! This folder has been automatically generated by `@changesets/cli`, a build tool that works
with multi-package repos, or single-package repos to help you version and publish your code. You can
find the full documentation for it [in our repository](https://github.com/changesets/changesets)

We have a quick list of common questions to get you started engaging with this project in
[our documentation](https://github.com/changesets/changesets/blob/main/docs/common-questions.md)
</file>

<file path=".husky/_/pre-commit">
#!/bin/sh

if [ "$LEFTHOOK_VERBOSE" = "1" -o "$LEFTHOOK_VERBOSE" = "true" ]; then
  set -x
fi

if [ "$LEFTHOOK" = "0" ]; then
  exit 0
fi

call_lefthook()
{
  if test -n "$LEFTHOOK_BIN"
  then
    "$LEFTHOOK_BIN" "$@"
  elif lefthook -h >/dev/null 2>&1
  then
    lefthook "$@"
  else
    dir="$(git rev-parse --show-toplevel)"
    osArch=$(uname | tr '[:upper:]' '[:lower:]')
    cpuArch=$(uname -m | sed 's/aarch64/arm64/;s/x86_64/x64/')
    if test -f "$dir/node_modules/lefthook-${osArch}-${cpuArch}/bin/lefthook"
    then
      "$dir/node_modules/lefthook-${osArch}-${cpuArch}/bin/lefthook" "$@"
    elif test -f "$dir/node_modules/@evilmartians/lefthook/bin/lefthook-${osArch}-${cpuArch}/lefthook"
    then
      "$dir/node_modules/@evilmartians/lefthook/bin/lefthook-${osArch}-${cpuArch}/lefthook" "$@"
    elif test -f "$dir/node_modules/@evilmartians/lefthook-installer/bin/lefthook"
    then
      "$dir/node_modules/@evilmartians/lefthook-installer/bin/lefthook" "$@"
    elif test -f "$dir/node_modules/lefthook/bin/index.js"
    then
      "$dir/node_modules/lefthook/bin/index.js" "$@"
    
    elif go tool lefthook -h >/dev/null 2>&1
    then
      go tool lefthook "$@"
    elif bundle exec lefthook -h >/dev/null 2>&1
    then
      bundle exec lefthook "$@"
    elif yarn lefthook -h >/dev/null 2>&1
    then
      yarn lefthook "$@"
    elif pnpm lefthook -h >/dev/null 2>&1
    then
      pnpm lefthook "$@"
    elif swift package lefthook >/dev/null 2>&1
    then
      swift package --build-path .build/lefthook --disable-sandbox lefthook "$@"
    elif command -v mint >/dev/null 2>&1
    then
      mint run csjones/lefthook-plugin "$@"
    elif uv run lefthook -h >/dev/null 2>&1
    then
      uv run lefthook "$@"
    elif mise exec -- lefthook -h >/dev/null 2>&1
    then
      mise exec -- lefthook "$@"
    else
      echo "Can't find lefthook in PATH"
    fi
  fi
}

call_lefthook run "pre-commit" "$@"
</file>

<file path=".husky/_/prepare-commit-msg">
#!/bin/sh

if [ "$LEFTHOOK_VERBOSE" = "1" -o "$LEFTHOOK_VERBOSE" = "true" ]; then
  set -x
fi

if [ "$LEFTHOOK" = "0" ]; then
  exit 0
fi

call_lefthook()
{
  if test -n "$LEFTHOOK_BIN"
  then
    "$LEFTHOOK_BIN" "$@"
  elif lefthook -h >/dev/null 2>&1
  then
    lefthook "$@"
  else
    dir="$(git rev-parse --show-toplevel)"
    osArch=$(uname | tr '[:upper:]' '[:lower:]')
    cpuArch=$(uname -m | sed 's/aarch64/arm64/;s/x86_64/x64/')
    if test -f "$dir/node_modules/lefthook-${osArch}-${cpuArch}/bin/lefthook"
    then
      "$dir/node_modules/lefthook-${osArch}-${cpuArch}/bin/lefthook" "$@"
    elif test -f "$dir/node_modules/@evilmartians/lefthook/bin/lefthook-${osArch}-${cpuArch}/lefthook"
    then
      "$dir/node_modules/@evilmartians/lefthook/bin/lefthook-${osArch}-${cpuArch}/lefthook" "$@"
    elif test -f "$dir/node_modules/@evilmartians/lefthook-installer/bin/lefthook"
    then
      "$dir/node_modules/@evilmartians/lefthook-installer/bin/lefthook" "$@"
    elif test -f "$dir/node_modules/lefthook/bin/index.js"
    then
      "$dir/node_modules/lefthook/bin/index.js" "$@"
    
    elif go tool lefthook -h >/dev/null 2>&1
    then
      go tool lefthook "$@"
    elif bundle exec lefthook -h >/dev/null 2>&1
    then
      bundle exec lefthook "$@"
    elif yarn lefthook -h >/dev/null 2>&1
    then
      yarn lefthook "$@"
    elif pnpm lefthook -h >/dev/null 2>&1
    then
      pnpm lefthook "$@"
    elif swift package lefthook >/dev/null 2>&1
    then
      swift package --build-path .build/lefthook --disable-sandbox lefthook "$@"
    elif command -v mint >/dev/null 2>&1
    then
      mint run csjones/lefthook-plugin "$@"
    elif uv run lefthook -h >/dev/null 2>&1
    then
      uv run lefthook "$@"
    elif mise exec -- lefthook -h >/dev/null 2>&1
    then
      mise exec -- lefthook "$@"
    else
      echo "Can't find lefthook in PATH"
    fi
  fi
}

call_lefthook run "prepare-commit-msg" "$@"
</file>

<file path="packages/ai/src/index.spec.ts">
import { it, expect } from 'vitest';
import { AIClient, OpenAIClient } from './client.js';
import { AIThread } from './thread.js';
it.skip('should create an AIClient and send it a message', async () => {
  console.log(process.env.OPENAI_API_KEY);
  const client = await OpenAIClient.create({
    apiKey: process.env.OPENAI_API_KEY!,
  });
  const result = await client.message('What is the capital of France?');
  expect(result.toLowerCase()).toContain('paris');
}, 30000);

it.skip('should create an AIThread and ask it a question', async () => {
  const options = {
    ai: {
      type: 'openai',
      apiKey: process.env.OPENAI_API_KEY!,
    },
    prompt: 'What is the capital of France?',
  };

  const ai = await AIClient.create(options.ai);

  // lets talk about it
  const thread = await AIThread.create({
    ai: options.ai,
  });

  await thread.addSystem('You are a helpful assistant.'); // Add the system message

  await thread.addReference('Meeting Minutes', minutes);

  await thread.add({
    role: 'user',
    content:
      'Summarize the key decisions from the meeting and how they impact the budget.',
  });

  const response = await thread.do('Write a short summary.'); // The prompt here is now used *in addition to* the history.

  // const response = await thread.do({
  //   prompt: 'Write an article about what happened in the last meeting',
  //   responseFormat: 'html',
  // });
  // console.log({ response });

  console.log(response);
}, 30000);

const minutes =
  'V, 1/ 7\n' +
  'NRL — un ON\n' +
  'Town\n' +
  'Minutes of the Regular of the Council of the Town of Bentley November 26, 2024\n' +
  'Date and Place\n' +
  'In Attendance\n' +
  'Call to Order\n' +
  'Indigenous Acknowledgement\n' +
  'Agenda\n' +
  'Minutes of the Regular Meeting of the Council of the Town of Bentley held Tuesday, November 26, 2024, at 6:30 p.m., in the Bentley Municipal Office\n' +
  'Mayor Greg Rathjen Deputy Mayor Valiquette Councillor Eastman Councillor Hansen Councillor Grimsdale CAO, Marc Fortais\n' +
  'Mayor Rathjen called the regular council meeting to order at 6:30pm\n' +
  '“We acknowledge that we are meeting on Treaty 6 Territory and Home of Metis Nation Region 3, on land that is part of a historic agreement involving mutuality and respect. We recognize all the many First Nations, Metis, Inuit, and non-First Nations whose footsteps have marked these lands.”\n' +
  'Read by Mayor Rathjen\n' +
  'Motion 228/2024 Moved by Councillor Hansen, “THAT the agenda of the November 26, 2024, regular meeting of council be amended to include the following items as other business:\n' +
  '1) Gull Lake East Trail – letter of support to Lacombe County 2) Local Sustainability Grant Application\n' +
  'Carried\n' +
  'Motion 229/2024 Moved by Councillor Grimsdale, “THAT the‘amended agenda of the October 26, 2024, regular meeting of council be accepted.”\n' +
  'Carried\n' +
  'Regular Council Meeting Minutes November 26, 2024\n' +
  'Previous Minutes\n' +
  'Financial\n' +
  'New Business\n' +
  'Motion 23012024 Moved by Deputy Mayor Valiquette, “THAT the minutes of the October 22, 2024, Regular Meeting of Council be accepted.”\n' +
  'Carried\n' +
  'Motion 231/2024 Moved by Councillor Hansen, “THAT the minutes of the October 22, 2024, Organizational Meeting of Council be accepted.”\n' +
  'Carried\n' +
  'a) Prepaid Cheque Listing – Cheques No. 20240828 to 20240913\n' +
  'Motion 232/2024 Moved by Councillor Eastman, “THAT Cheques No. 20240778 to 20240827 be received for information.”\n' +
  'Carried\n' +
  'a) Delegation – Lacombe County Tourism – 2024 Annual Report\n' +
  'Motion 233/2024 Moved by Councillor Eastman, “THAT the report presented by Lacombe County Tourism – 2024 Annual Report be accepted as information: AND\n' +
  'THAT administration be directed to include funding for 2025 to support Lacombe Tourism in the preliminary budget for consideration by Mayor and Council.\n' +
  'Carried\n' +
  'b) Land Sale – Lot 41, Block 1, Plan 2320333 Motion 234/2024 Moved by Councillor Grimsdale, “THAT Mayor and Council approve the sale of 5604 48A Street (Lot 41, Block 1, Plan 2320333) located in the Tonw of Bentley, within the Sunset Heights Subdivision to Shane David Imber and Diane Marie Imber for the amount of $62,000\n' +
  '(including any applicable GST) subject to the following terms and conditions: Excepting thereout aII mines and minerals\n' +
  'Purchaser Shane David Imber Diane Marie Imber\n' +
  'Sale Price The Sale price is $62,000 including any applicable GST. But does not include any development costs or permits.\n' +
  'l\n' +
  'Regular Council Meeting Minutes November 26, 2024\n' +
  'Environmental Considerations The subject property is sold on an ”as is – where is” basis.\n' +
  'Fees and Disbursements The purchaser shall be responsible for all legal and registration fees associated with the transaction.\n' +
  'Vendor Conditions Subject to approval of this agreement by Town of Bentley Council before 9:00pm November 27, 2024, Seller will not provide an RPR\n' +
  'Purchaser Conditions Financing condition before 9:00pm November 29, 2024\n' +
  'Completion Day Contract completed, the purchase price fully paid and vacant possession given to the buyer at 12 noon on January 6, 2025 (this was amended form the original proposed date of January 2, 2025)"\n' +
  'Carried\n' +
  'c) Lacombe County – RC1 Grant Request $675,000 – Arena Slab Replacement\n' +
  'Motion 235/2024 Moved by Councillor Grimsdale, “THAT Mayor and Council, authorize CAO Marc Fortais to submit an RC1 grant application to Lacombe County to request funding of up to $675,000 (the maximum amount to fund 50% of the project costs for completion and replacement of‘ the Bentley Arena Slab, boards and glass; AND\n' +
  'The project to be completed in the 2025 budget year.”\n' +
  'Carried\n' +
  'd) Asset Management Phase III e Stormwater Plan o Wastewater Plan * Transportation Plan\n' +
  'Motion 236/2024 Moved by Deputy Mayor Valiquette, “THAT Mayor and Council approve the asset management plan reports prepared by Stantec for Stormwater, Wastewater, and Transportation; AND\n' +
  'I\n' +
  'Regular Council Meeting Minutes November 26, 2024\n' +
  'Break\n' +
  'Correspondence\n' +
  'Other Business\n' +
  'THAT Administration be directed to provide Mayor and Council with a reasonable rate strategy for utilities as a part of the 2025 Preliminary Budget approval process to ensure the establishment of a reasonable amount of reserve that does not create an excessive burden for the local rate payer.”\n' +
  'Carried\n' +
  'Councillor Grimsdale requested a break prior to reviewing the 3™ Quarter Financial Report\n' +
  'Motion 237/2024 Moved by Councillor Grimsdale, “THAT Mayor and Council take a short break of 10 minutes at 7:26pm, prior to reviewing the 3 Quarter Financial Report to be presented by the CAO.”\n' +
  'Carried\n' +
  'Mayor Rathjen called the meeting to order at 7:34 pm concluding the break.\n' +
  'e) 3” Quarter Financial Report Motion 238/2024 Moved by Councillor Eastman, “THAT the 3 Quarter Financial Report and presentation be accepted as information by Mayor and Council.\n' +
  'Carried\n' +
  'a) Lacombe County Council Highlights October 24, 2024 b) Lacombe County Council Highlights November 14, 2024\n' +
  'Motion 239/2024 Moved by Deputy Mayor Valiquette, “THAT correspondence item a to b be accepted as information.”\n' +
  'Carried\n' +
  'a) Gull Lake East Trail – Letter of Support to Lacombe County Motion 240/2024 Moved by Councillor Hansen, “THAT Mayor and Council provide a letter of support to Lacombe County for their grant application to the Alberta Strategic Transportation Infrastructure Program for the purpose of paving a 5km trail on the east side of Gull Lake.”\n' +
  'Carried\n' +
  'Regular Council Meeting Minutes November 26, 2024\n' +
  'b) Local Sustainability Grant Application – Town of Bentley Motion 241//2024 Moved by Councillor Eastman, “THAT the CAO be directed to apply to the Local Growth and Sustainability Grant program, under the sustainability component to support a sewer main replacement along 48” Ave in the 2026 budgetary year.”\n' +
  'Carried\n' +
  'Council Reports\n' +
  'a) Mayor Rathjen b) Deputy Mayor Valiquette c) Councillor Grimsdale d) Councillor Eastman e) Councillor Hansen\n' +
  'Motion 242/2024 Moved by Councillor Grimsdale, “THAT the council reports for October be accepted as information.”\n' +
  'Carried\n' +
  'Adjournment\n' +
  'Mayor Rathjen adjourned the meeting at 8:20pm\n' +
  'N ‘ pe. Mayor Greg Rathjen CAO Marc rtais\n' +
  '_— ee —— –— Regular Council Meeting Minutes November 26, 2024';
</file>

<file path="packages/ai/src/index.ts">
export * from './client.js';
export * from './message.js';
export * from './thread.js';
</file>

<file path="packages/ai/src/message.ts">
import { AIThread } from './thread.js';

export interface AIMessageOptions {
  role?: 'user' | 'assistant' | 'system';
  responseFormat?: { type: 'text' | 'json_object' };
}

export class AIMessage {
  protected options;
  public name: string;
  public content: string;
  public role: 'user' | 'assistant' | 'system';

  constructor(options: {
    role: 'user' | 'assistant' | 'system';
    content: string;
    name: string;
  }) {
    this.options = options;
    this.role = options.role;
    this.content = options.content;
    this.name = options.name;
  }

  static async create(options: {
    thread: AIThread;
    role: 'user' | 'assistant' | 'system';
    content: string;
    name: string;
  }) {
    return new AIMessage(options);
  }
}
</file>

<file path="packages/ai/src/thread.ts">
import { AIClient, type AIClientOptions } from './client.js';
import { AIMessage } from './message.js';
import OpenAI from 'openai';
export interface AIThreadOptions {
  ai: AIClientOptions;
}

export class AIThread {
  protected ai!: AIClient;
  protected options: AIThreadOptions;
  private messages: AIMessage[] = [];
  private references: { [name: string]: string } = {}; // Store references

  constructor(options: AIThreadOptions) {
    this.options = options;
  }

  static async create(options: AIThreadOptions) {
    const thread = new AIThread(options);
    await thread.initialize();
    return thread; // No need to add system message here, do it in addSystem
  }

  public async initialize() {
    this.ai = await AIClient.create(this.options.ai);
  }

  public async addSystem(prompt: string) {
    const message = await AIMessage.create({
      thread: this,
      role: 'system',
      name: 'system',
      content: prompt,
    });

    this.messages.push(message);
    return message;
  }

  public async add(options: {
    role: 'user' | 'assistant' | 'system';
    name?: string; // Optional name
    content: string;
  }) {
    const message = await AIMessage.create({
      thread: this,
      role: options.role,
      name: options.name || options.role, // Default name to role if not provided
      content: options.content,
    });

    this.messages.push(message);
    return message;
  }

  public get(): AIMessage[] {
    return this.messages;
  }

  public addReference(name: string, body: string): void {
    this.references[name] = body;
  }

  public assembleHistory(): OpenAI.Chat.ChatCompletionMessageParam[] {
    const history: OpenAI.Chat.ChatCompletionMessageParam[] = [];

    // Add system message first
    const systemMessage = this.messages.find((m) => m.role === 'system');
    if (systemMessage) {
      history.push({
        role: systemMessage.role,
        content: systemMessage.content,
      });
    }

    // Add references as user messages (before other user/assistant messages)
    for (const name in this.references) {
      history.push({
        role: 'user',
        content: `Reference - ${name}:\n${this.references[name]}`,
      });
    }

    // Add other messages
    this.messages
      .filter((m) => m.role !== 'system')
      .forEach((message) => {
        history.push({ role: message.role, content: message.content });
      });

    return history;
  }

  public async do(
    prompt: string,
    options: {
      responseFormat?: 'html' | 'text' | 'json';
    } = {
      responseFormat: 'text',
    },
  ) {
    const { responseFormat } = options;
    const history = this.assembleHistory();

    // Now you can use the assembled history:
    const response = await this.ai.textCompletion(prompt, {
      history, // Use the messages array here
      responseFormat: {
        type: responseFormat === 'json' ? 'json_object' : 'text',
      },
    });
    return response;
  }
}
</file>

<file path="packages/ai/README.md">
# *HA*ppy *VE*rtical _SDK_ ai standardised interface abstraction layer

i know ai !== llm but it's two letters which goes along with fs and db so well
</file>

<file path="packages/ai/tsconfig.json">
{
  "extends": "../../tsconfig.json",
  "compilerOptions": {
    "outDir": "./dist",
    "rootDir": "./src",
    "composite": true,
    "declaration": true,
    "declarationMap": true
  },
  "include": ["src/**/*"],
  "exclude": ["dist", "../../node_modules"]
}
</file>

<file path="packages/files/src/fetch.ts">
import { writeFile } from 'node:fs/promises';

// Rate limiter class implementation
class RateLimiter {
  private domains: Map<
    string,
    {
      lastRequest: number;
      limit: number;
      interval: number;
      queue: number;
    }
  > = new Map();

  private defaultLimit = 6;
  private defaultInterval = 500;

  constructor() {
    // Initialize with default settings
    this.domains.set('default', {
      lastRequest: 0,
      limit: this.defaultLimit,
      interval: this.defaultInterval,
      queue: 0,
    });
  }

  private getDomain(url: string): string {
    try {
      return new URL(url).hostname;
    } catch {
      return 'default';
    }
  }

  async waitForNext(url: string): Promise<void> {
    const domain = this.getDomain(url);
    const now = Date.now();

    const domainConfig =
      this.domains.get(domain) || this.domains.get('default')!;

    // Wait if we're over the limit
    if (domainConfig.queue >= domainConfig.limit) {
      const timeToWait = Math.max(
        0,
        domainConfig.lastRequest + domainConfig.interval - now,
      );
      if (timeToWait > 0) {
        await new Promise((resolve) => setTimeout(resolve, timeToWait));
      }
      domainConfig.queue = 0;
    }

    domainConfig.lastRequest = now;
    domainConfig.queue++;
  }

  setDomainLimit(domain: string, limit: number, interval: number) {
    this.domains.set(domain, {
      lastRequest: 0,
      limit,
      interval,
      queue: 0,
    });
  }

  getDomainLimit(domain: string) {
    return this.domains.get(domain) || this.domains.get('default')!;
  }
}

// Create singleton instance
const rateLimiter = new RateLimiter();

export async function addRateLimit(
  domain: string,
  limit: number,
  interval: number,
) {
  rateLimiter.setDomainLimit(domain, limit, interval);
}

export async function getRateLimit(
  domain: string,
): Promise<{ limit: number; interval: number }> {
  const config = rateLimiter.getDomainLimit(domain);
  return {
    limit: config.limit,
    interval: config.interval,
  };
}

async function rateLimitedFetch(
  url: string,
  options?: RequestInit,
): Promise<Response> {
  await rateLimiter.waitForNext(url);
  return fetch(url, options);
}

export async function fetchText(url: string): Promise<string> {
  const response = await rateLimitedFetch(url);
  return response.text();
}

export async function fetchJSON(url: string): Promise<any> {
  const response = await rateLimitedFetch(url);
  return response.json();
}

export async function fetchBuffer(url: string): Promise<Buffer> {
  const response = await rateLimitedFetch(url);
  return Buffer.from(await response.arrayBuffer());
}

export async function fetchToFile(
  url: string,
  filepath: string,
): Promise<void> {
  const response = await rateLimitedFetch(url);
  const buffer = await response.arrayBuffer();
  await writeFile(filepath, Buffer.from(buffer));
}
</file>

<file path="packages/files/src/filesystem-local.ts">
import { FilesystemAdapter, FilesystemAdapterOptions } from './filesystem.js';
import { getMimeType } from './index.js';
export class LocalFilesystemAdapter extends FilesystemAdapter {
  protected cacheDir: string;
  public type: string;
  protected options: FilesystemAdapterOptions;
  constructor(options: FilesystemAdapterOptions) {
    super(options);
    this.options = options;
    this.type = options.type || 'local';
    this.cacheDir = options.cacheDir || '.cache';
  }

  static async createFromUrl(url: string) {}

  static async create(options: FilesystemAdapterOptions) {
    const fs = new LocalFilesystemAdapter(options);
    return fs;
  }

  async exists(path: string) {
    return false;
  }

  async read(path: string) {
    return '';
  }

  async write(path: string, content: string) {
    return;
  }

  async delete(path: string) {
    return;
  }

  async list(path: string) {
    return [];
  }

  async mimeType(path: string) {
    const extension = path.slice(((path.lastIndexOf('.') - 1) >>> 0) + 2);
    return getMimeType(`.${extension}`);
  }
}
</file>

<file path="packages/files/src/index.spec.ts">
// index.test.ts
import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
import * as fs from 'node:fs';
import * as path from 'node:path';
import {
  isFile,
  isDirectory,
  ensureDirectoryExists,
  upload,
  download,
  downloadFileWithCache,
  listFiles,
} from './index';
import { createServer, Server } from 'node:http';
import { TMP_DIR } from '@have/utils';

// Mock fs modulesq
// vi.mock('node:fs');
// vi.mock('node:fs/promises');

describe('File utilities', () => {
  let tmpDir: string;
  let server: Server;
  let serverUrl: string;

  beforeEach(() => {
    // Create a unique temporary directory for each test
    tmpDir = path.join(TMP_DIR, 'file-utils-test');
    fs.mkdirSync(tmpDir, { recursive: true });

    // Create and start test server
    server = createServer((req, res) => {
      if (req.method === 'PUT' && req.url === '/upload') {
        let data = '';
        req.on('data', (chunk) => {
          data += chunk;
        });
        req.on('end', () => {
          res.writeHead(200, { 'Content-Type': 'text/plain' });
          res.end('Upload successful');
        });
      } else if (req.method === 'PUT') {
        // Explicitly handle failed uploads
        res.writeHead(403, { 'Content-Type': 'text/plain' });
        res.end('Upload failed');
      } else if (req.url === '/test.txt') {
        res.writeHead(200, { 'Content-Type': 'text/plain' });
        res.end('Test content');
      } else {
        res.writeHead(404);
        res.end('Not found');
      }
    });

    return new Promise<void>((resolve) => {
      server.listen(0, '127.0.0.1', () => {
        const addr = server.address();
        if (addr && typeof addr === 'object') {
          serverUrl = `http://127.0.0.1:${addr.port}`;
        }
        resolve();
      });
    });
  });

  afterEach(() => {
    // Clean up temporary directory and server after each test
    fs.rmSync(tmpDir, { recursive: true, force: true });
    return new Promise<void>((resolve) => server.close(() => resolve()));
  });

  describe('isFile', () => {
    it('should return stat when path is a file', () => {
      const filePath = path.join(tmpDir, 'test.txt');
      fs.writeFileSync(filePath, 'test content');

      const result = isFile(filePath);
      expect(result).toBeTruthy();
      // expect(isDirectory(result?.)).toBe(false);
    });

    it('should return false when path is a directory', () => {
      const dirPath = path.join(tmpDir, 'test-dir');
      fs.mkdirSync(dirPath);

      const result = isFile(dirPath);
      expect(result).toBe(false);
    });

    it('should return false when path does not exist', () => {
      const result = isFile(path.join(tmpDir, 'non-existent.txt'));
      expect(result).toBe(false);
    });
  });

  describe('isDirectory', () => {
    it('should return true when path is a directory', () => {
      const dirPath = path.join(tmpDir, 'test-dir');
      fs.mkdirSync(dirPath);

      const result = isDirectory(dirPath);
      expect(result).toBe(true);
    });

    it('should throw error when path exists but is not a directory', () => {
      const filePath = path.join(tmpDir, 'test.txt');
      fs.writeFileSync(filePath, 'test content');

      expect(() => isDirectory(filePath)).toThrow();
    });

    it('should return false when path does not exist', () => {
      const result = isDirectory(path.join(tmpDir, 'non-existent-dir'));
      expect(result).toBe(false);
    });
  });

  describe('ensureDirectoryExists', () => {
    it('should create directory if it does not exist', async () => {
      const dirPath = path.join(tmpDir, 'new-dir');
      await ensureDirectoryExists(dirPath);
      expect(fs.existsSync(dirPath)).toBe(true);
      expect(fs.statSync(dirPath).isDirectory()).toBe(true);
    });

    it('should not throw if directory already exists', async () => {
      const dirPath = path.join(tmpDir, 'existing-dir');
      fs.mkdirSync(dirPath);

      await expect(ensureDirectoryExists(dirPath)).resolves.not.toThrow();
    });
  });

  describe('listFiles', () => {
    it('should list all files when no match pattern is provided', async () => {
      const files = ['file1.txt', 'file2.jpg', 'file3.png'];
      for (const file of files) {
        fs.writeFileSync(path.join(tmpDir, file), 'test content');
      }

      const result = await listFiles(tmpDir);
      expect(result.sort()).toEqual(files.sort());
    });

    it('should filter files based on match pattern', async () => {
      const files = ['file1.txt', 'file2.jpg', 'file3.png'];
      for (const file of files) {
        fs.writeFileSync(path.join(tmpDir, file), 'test content');
      }

      const result = await listFiles(tmpDir, { match: /\.txt$/ });
      expect(result).toEqual(['file1.txt']);
    });
  });

  describe('upload', () => {
    it('should upload data successfully', async () => {
      const response = await upload(`${serverUrl}/upload`, 'test-data');
      expect(response.ok).toBe(true);
    });

    it('should throw error on failed upload', async () => {
      await expect(
        upload(`${serverUrl}/nonexistent`, 'test-data'),
      ).rejects.toThrow();
    });
  });

  describe('download', () => {
    it('should download file successfully', async () => {
      const localPath = path.join(tmpDir, 'test.txt');
      const downloaded = await download(`${serverUrl}/test.txt`, localPath);
      expect(fs.existsSync(localPath)).toBe(true);
    });

    it('should throw error on failed download', async () => {
      await expect(
        download(`${serverUrl}/nonexistent`, path.join(tmpDir, 'nonexistent')),
      ).rejects.toThrow();
    });
  });

  describe('downloadFileWithCache', () => {
    it('should download and cache a text file', async () => {
      const targetPath = path.join(tmpDir, 'test.txt');

      await downloadFileWithCache(`${serverUrl}/test.txt`, targetPath);
      // console.log('targetPath', targetPath);
      // Verify the file exists and has content
      expect(fs.existsSync(targetPath)).toBe(true);
    });
  });
});
</file>

<file path="packages/files/tsconfig.json">
{
  "extends": "../../tsconfig.json",
  "compilerOptions": {
    "outDir": "dist",
    "rootDir": "src",
    "composite": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist"]
}
</file>

<file path="packages/pdf/src/index.ts">
import * as pdfJs from 'pdfjs-dist/legacy/build/pdf.mjs';
import scribe from 'scribe.js-ocr';

import fs from 'fs';

// Set up the worker
// pdfjsLib.GlobalWorkerOptions.workerSrc = 'pdfjs-dist/legacy/build/pdf.worker';

export async function extractImagesFromPDF(
  pdfPath: string,
): Promise<any[] | null> {
  try {
    const data = new Uint8Array(fs.readFileSync(pdfPath));
    const loadingTask = pdfJs.getDocument(data);
    const pdf = await loadingTask.promise;

    const page = await pdf.getPage(1);
    // const operatorList = await page.getOperatorList();

    const images: any[] = [];
    // Get all image keys and their corresponding objects
    // console.log('page.commonObjs', page.commonObjs);
    const keys = page.commonObjs.getKeys();
    for (const key of keys) {
      if (key.startsWith('img_')) {
        const value = page.commonObjs.get(key);
        images.push(value);
      }
    }

    return images;
  } catch (error) {
    console.error('Error extracting images:', error);
    return null;
    // throw error;
  }
}

export async function extractTextFromPDF(pdfPath: string) {
  try {
    const loadingTask = pdfJs.getDocument(pdfPath);
    const pdf = await loadingTask.promise;
    let text = '';
    for (let i = 1; i <= pdf.numPages; i++) {
      const page = await pdf.getPage(i);
      const content = await page.getTextContent();
      const strings = content.items.map((item: { str: string }) => item.str);
      text += strings.join(' ');
    }
    if (!text.trim()) {
      text = await scribe.extractText([pdfPath]);
    }
    return text;
  } catch (error) {
    console.error(`Error extracting text from ${pdfPath}:`, error);
    return null;
  }
}

// export function extractImagesFromPDF(pdfPath: string): Promise<string[]> {
//   return Promise.resolve([]);
// }
</file>

<file path="packages/pdf/src/modules.d.ts">
declare module 'scribe.js-ocr';
declare module 'pdfjs-dist/legacy/build/pdf.mjs';
</file>

<file path="packages/pdf/tsconfig.json">
{
  "extends": "../../tsconfig.json",
  "compilerOptions": {
    "outDir": "./dist",
    "rootDir": "./src",
    "composite": true,
    "declaration": true,
    "declarationMap": true
  },
  "include": ["src/**/*"],
  "exclude": ["dist", "node_modules", "**/*.test.ts"]
}
</file>

<file path="packages/smrt/src/class.ts">
import { getDatabase } from '@have/sql';
import type { DatabaseOptions, DatabaseInterface } from '@have/sql';
import { FilesystemAdapter } from '@have/files';
import type { FilesystemAdapterOptions } from '@have/files';
import type { AIClientOptions } from '@have/ai';
import { AIClient } from '@have/ai';

export interface BaseClassOptions {
  _className?: string;
  db?: DatabaseOptions;
  fs?: FilesystemAdapterOptions;
  ai?: AIClientOptions;
}

export class BaseClass<T extends BaseClassOptions = BaseClassOptions> {
  protected _ai!: AIClient;
  protected _fs!: FilesystemAdapter;
  protected _db!: DatabaseInterface;
  protected _className!: string;
  protected options: T;

  constructor(options: T) {
    this.options = options;
    this._className = this.constructor.name;
  }

  protected async initialize(): Promise<void> {
    if (this.options.db) {
      this._db = await getDatabase(this.options.db);
    }
    if (this.options.fs) {
      this._fs = await FilesystemAdapter.create(this.options.fs);
    }
    if (this.options.ai) {
      this._ai = await AIClient.create(this.options.ai);
    }
  }

  // Getter for fs
  get fs() {
    return this._fs;
  }

  // Getter for db
  get db() {
    return this._db;
  }

  // Getter for ai
  get ai() {
    return this._ai;
  }
}
</file>

<file path="packages/smrt/src/fields.ts">
/*
this should work, but I want to get an initial commit in before refactoring



class Person extends BaseObject {
  name = new BaseText();
  age = new BaseReal();
  created_at = new BaseDate();
}

const person = new Person();
person.name = 'John';  // Works!
person.age = 30;      // Works!
person.created_at = new Date();  // Works!

console.log(`Hello ${person.name}`);  // "Hello John"


*/

export class Field<T> {
  protected _value: T | null = null;

  constructor(value: T | null = null) {
    this._value = value;
    return new Proxy(this, {
      set(target: any, prop: string, value: any) {
        if (prop === '_value') {
          target._value = value;
          return true;
        }
        target[prop] = value;
        return true;
      },
    });
  }

  get value(): T | null {
    return this._value;
  }

  toString() {
    return this._value?.toString() ?? '';
  }
}

export class TextField extends Field<string> {
  static readonly type = 'TEXT';
}

export class DecimalField extends Field<number> {
  static readonly type = 'REAL';
}

export class DateField extends Field<Date> {
  static readonly type = 'TEXT';
}
</file>

<file path="packages/smrt/src/human.ts">
export interface HumanOptions {
  name?: string;
}

export class Human {
  public name: string;
  private _slug?: string;

  constructor(options: HumanOptions) {
    this.name = options.name || '';
  }

  /**
   * Private method to handle async initialization
   */
  protected async initialize(): Promise<Human> {
    // Perform any async initialization here
    return this;
  }

  /*
   * Factory method to create a Human
   */
  static async create(options: HumanOptions): Promise<Human> {
    const person = new Human(options);
    return await person.initialize();
  }

  get slug(): string {
    if (!this._slug) {
      // Implement slug generation logic directly here
      this._slug = ''; // TODO: Add actual slug generation
    }
    return this._slug;
  }
}
</file>

<file path="packages/smrt/src/index.ts">
export * from './human.js';
export * from './document.js';
export * from './content.js';
export * from './contents.js';
export * from './class.js';
export * from './object.js';
export * from './collection.js';
export * from './pleb.js';
</file>

<file path="packages/smrt/src/pleb.ts">
import { BaseObject } from './object.js';
import type { BaseObjectOptions } from './object.js';

export interface PlebOptions extends BaseObjectOptions {}

export class Pleb<T extends PlebOptions = PlebOptions> extends BaseObject<T> {
  constructor(options: T) {
    super(options);
    this._className = this.constructor.name;
  }

  static async create(options: PlebOptions) {
    const pleb = new Pleb(options);
    await pleb.initialize();
    return pleb;
  }

  protected async initialize(): Promise<void> {
    await super.initialize();
    // const db = await getDatabase();
    // const schema = await syncSchema(options.schema);
  }

  // protected async getThread(options: {
  //   prompt: string;
  //   references: Content[];
  //   ai: GetAIClientOptions;
  // }) {
  //   const ai = options.ai
  //     ? await getAIClient(options.ai)
  //     : await getAIClient(this.options.ai);

  //   const thread = await AIThread.create({
  //     ai,
  //   });

  //   thread.addMessage({
  //     role: 'system',
  //     content: options.prompt,
  //   });

  //   for (const reference of options.references) {
  //     thread.addMessage({
  //       role: 'system',
  //       content: JSON.stringify(reference),
  //     });
  //   }

  //   const contentPrompt = `
  //     You are a writer for a local newspaper.
  //     You are given a bit of content from the internet and you are asked to write a short article about it.
  //     The article should be 100 words or less.
  //   `;
  //   const body = await thread.addMessage(contentPrompt);

  //   console.log(body);
  // }
}
</file>

<file path="packages/smrt/src/utils.spec.ts">
import { it, expect } from 'vitest';
import { fieldsFromClass, contentToString, stringToContent } from './utils.js';
import { faker } from '@faker-js/faker';
import { Content } from './content.js';
// Test class with various field types
class TestClass {
  test_string: string = 'test';
  test_number: number = 123;
  test_date: Date = new Date();
  private _privateField: string = 'private';
  methodField() {
    return true;
  }
}

it('should get fields from a class without values', () => {
  const fields = fieldsFromClass(TestClass);
  expect(fields).toEqual({
    test_string: {
      name: 'test_string',
      type: 'TEXT',
    },
    test_number: {
      name: 'test_number',
      type: 'INTEGER',
    },
    test_date: {
      name: 'test_date',
      type: 'DATETIME',
    },
  });

  // Verify private and method fields are excluded
  expect(fields).not.toHaveProperty('_privateField');
  expect(fields).not.toHaveProperty('methodField');
});

it('should get fields from a class with values', () => {
  const values = {
    test_string: 'custom value',
    test_number: 456,
    test_date: '2024-01-01',
    extraField: 'should not appear',
  };

  const fields = fieldsFromClass(TestClass, values);

  expect(fields).toEqual({
    test_string: {
      name: 'test_string',
      type: 'TEXT',
      value: 'custom value',
    },
    test_number: {
      name: 'test_number',
      type: 'INTEGER',
      value: 456,
    },
    test_date: {
      name: 'test_date',
      type: 'DATETIME',
      value: '2024-01-01',
    },
  });

  // Verify extra field from values doesn't appear
  expect(fields).not.toHaveProperty('extraField');
});

it.only('should be able to parse a content string', () => {
  const data = {
    type: 'article',
    title: faker.lorem.sentence(),
    author: faker.person.fullName(),
    publish_date: faker.date.recent(),
    body: faker.lorem.paragraph(),
  };

  const toString = contentToString(data as Content);
  const toObject = stringToContent(toString);
  expect(toObject).toEqual(data);
});
</file>

<file path="packages/smrt/src/utils.ts">
import { syncSchema } from '@have/sql';
import yaml from 'yaml';
import { Content } from './content.js';
export function isDateField(key: string) {
  return key.endsWith('_date') || key.endsWith('_at') || key === 'date';
}

export function dateAsString(date: Date | string) {
  if (typeof date === 'string') {
    return new Date(date);
  }
  return date;
}

export function dateAsObject(date: Date | string) {
  if (date instanceof Date) {
    return date.toISOString();
  }
  return date;
}

export function fieldsFromClass(
  ClassType: new (...args: any[]) => any,
  values?: Record<string, any>,
) {
  const fields: Record<string, any> = {};
  // just for introspection, dont need real creds
  const instance = new ClassType({
    ai: {
      type: 'openai',
      apiKey: 'sk-proj-1234567890',
    },
    db: {
      url: 'file:/tmp/dummy.db',
    },
  });

  // Get descriptors from the instance and all ancestors
  const descriptors = new Map<string, PropertyDescriptor>();

  // Start with the instance
  Object.entries(Object.getOwnPropertyDescriptors(instance)).forEach(
    ([key, descriptor]) => {
      descriptors.set(key, descriptor);
    },
  );

  // Walk up the prototype chain
  let proto = Object.getPrototypeOf(instance);
  while (proto && proto !== Object.prototype) {
    Object.entries(Object.getOwnPropertyDescriptors(proto)).forEach(
      ([key, descriptor]) => {
        // Only add if we haven't seen this property before
        if (!descriptors.has(key)) {
          descriptors.set(key, descriptor);
        }
      },
    );
    proto = Object.getPrototypeOf(proto);
  }

  // Process all collected descriptors
  for (const [key, descriptor] of descriptors) {
    // Skip methods, getters/setters, and internal properties
    if (
      typeof descriptor.value === 'function' ||
      descriptor.get ||
      descriptor.set ||
      key.startsWith('_') ||
      key.startsWith('#') ||
      key === 'constructor'
    ) {
      continue;
    }

    // If it's a data property with a defined type
    if (descriptor.value !== undefined) {
      let type: string | undefined;

      // Check the property definition
      const defaultValue = descriptor.value;
      if (defaultValue instanceof Date || isDateField(key)) {
        type = 'DATETIME';
      } else if (typeof defaultValue === 'string') {
        type = 'TEXT';
      } else if (typeof defaultValue === 'number') {
        type = 'INTEGER';
      } else if (defaultValue === null) {
        type = 'TEXT';
      }

      if (type) {
        fields[key] = {
          name: key,
          type,
          ...(values && key in values
            ? {
                value: values[key],
              }
            : {}),
        };
      }
    }
  }
  return fields;
}

export function generateSchema(ClassType: new (...args: any[]) => any) {
  const tableName = tableNameFromClass(ClassType);
  const fields = fieldsFromClass(ClassType);
  let schema = `CREATE TABLE IF NOT EXISTS ${tableName} (\n`;

  // Add id field first (always required)
  schema += '  id TEXT PRIMARY KEY,\n';

  // Add slug and context fields
  schema += '  slug TEXT NOT NULL,\n';
  schema += "  context TEXT NOT NULL DEFAULT '',\n";

  // Add other fields
  for (const [key, field] of Object.entries(fields)) {
    if (key === 'id' || key === 'slug' || key === 'context') continue;
    schema += `  ${key} ${field.type},\n`;
  }

  // Add composite unique constraint for slug and context
  schema += '  UNIQUE(slug, context),\n';

  schema = schema.slice(0, -2); // Remove trailing comma and newline
  schema += '\n);';

  schema += `\nCREATE INDEX IF NOT EXISTS ${tableName}_id_idx ON ${tableName} (id);`;
  schema += `\nCREATE INDEX IF NOT EXISTS ${tableName}_slug_context_idx ON ${tableName} (slug, context);`;
  return schema;
}

export function tableNameFromClass(
  // eslint-disable-next-line @typescript-eslint/no-unsafe-function-type
  ClassType: Function | (new (...args: any[]) => any),
) {
  return (
    ClassType.name
      // Insert underscore between lower & upper case letters
      .replace(/([a-z])([A-Z])/g, '$1_$2')
      // Convert to lowercase
      .toLowerCase()
      // Handle basic pluralization rules
      .replace(/([^s])$/, '$1s')
      // Handle special cases ending in 'y'
      .replace(/y$/, 'ies')
  );
}

// export function escapeSqlValue(value: any): string {
//   if (value === null) {
//     return 'NULL';
//   }
//   if (value instanceof Date) {
//     return `'${value.toISOString()}'`;
//   }
//   if (typeof value === 'number') {
//     return value.toString();
//   }
//   if (typeof value === 'boolean') {
//     return value ? '1' : '0';
//   }
//   // Escape single quotes and wrap in quotes
//   return `'${String(value).replace(/'/g, "''")}'`;
// }

// function validateColumnName(column: string): string {
//   // Only allow alphanumeric characters, underscores, and dots (for table.column notation)
//   if (!/^[a-zA-Z0-9_.]+$/.test(column)) {
//     throw new Error(`Invalid column name: ${column}`);
//   }
//   return column;
// }

// export function addWhere({
//   sql,
//   replacements = [],
//   where = {},
//   required = true,
// }: {
//   sql: string;
//   replacements?: any[];
//   where?: object;
//   required?: boolean;
// }): { sql: string; replacements: any[] } {
//   const wheres = [];
//   for (const [key, value] of Object.entries(where)) {
//     const safeColumnName = validateColumnName(key);
//     wheres.push(`${safeColumnName} = $${replacements.length + 1}`);
//     replacements.push(value);
//   }

//   if (wheres.length > 0) {
//     sql += ` WHERE ${wheres.join(' AND ')}`;
//   } else if (required) {
//     throw new Error('WHERE clause is required but no conditions were provided');
//   }

//   return { sql, replacements };
// }

export function classnameToTablename(className: string) {
  // Convert camelCase/PascalCase to snake_case and pluralize
  const tableName = className
    // Insert underscore between lower & upper case letters
    .replace(/([a-z])([A-Z])/g, '$1_$2')
    // Convert to lowercase
    .toLowerCase()
    // Handle basic pluralization rules
    .replace(/([^s])$/, '$1s')
    // Handle special cases ending in 'y'
    .replace(/y$/, 'ies');

  return tableName;
}

const _setup_table_from_class_promises: Record<string, Promise<void> | null> =
  {};

export async function setupTableFromClass(db: any, ClassType: any) {
  const tableName = classnameToTablename(ClassType.name);

  if (_setup_table_from_class_promises[tableName] !== undefined || null) {
    return _setup_table_from_class_promises[tableName];
  }

  _setup_table_from_class_promises[tableName] = (async () => {
    try {
      const schema = generateSchema(ClassType);
      await syncSchema({ db, schema });
      await setupTriggers(db, tableName);
    } catch (error) {
      _setup_table_from_class_promises[tableName] = null; // Allow retry on failure
      throw error;
    }
  })();

  return _setup_table_from_class_promises[tableName];
}

export async function setupTriggers(db: any, tableName: string) {
  const triggers = [
    `${tableName}_set_created_at`,
    `${tableName}_set_updated_at`,
  ];

  for (const trigger of triggers) {
    const exists =
      await db.pluck`SELECT name FROM sqlite_master WHERE type='trigger' AND name=${trigger}`;
    if (!exists) {
      if (trigger === `${tableName}_set_created_at`) {
        const createTriggerSQL = `
          CREATE TRIGGER ${trigger}
          AFTER INSERT ON ${tableName}
          BEGIN
            UPDATE ${tableName} 
            SET created_at = CURRENT_TIMESTAMP, updated_at = CURRENT_TIMESTAMP 
            WHERE id = NEW.id;
          END;
        `;
        await db.query(createTriggerSQL);
      } else if (trigger === `${tableName}_set_updated_at`) {
        const createTriggerSQL = `
          CREATE TRIGGER ${trigger}
          AFTER UPDATE ON ${tableName}
          BEGIN
            UPDATE ${tableName} 
            SET updated_at = CURRENT_TIMESTAMP 
            WHERE id = NEW.id;
          END;
        `;
        await db.query(createTriggerSQL);
      }
    }
  }
}

export function contentToString(content: Content) {
  const { body, ...frontmatter } = content;
  const separator = '---';
  const frontmatterYAML = yaml.stringify(frontmatter);
  return `${separator}\n${frontmatterYAML}\n${separator}\n${body}`;
}

export function stringToContent(data: string) {
  const separator = '---';
  const frontmatterStart = data.indexOf(separator);

  let frontmatter = {};
  let body = data;

  if (frontmatterStart !== -1) {
    const frontmatterEnd = data.indexOf(
      separator,
      frontmatterStart + separator.length,
    );

    if (frontmatterEnd !== -1) {
      const frontmatterYAML = data
        .substring(frontmatterStart + separator.length, frontmatterEnd)
        .trim();
      frontmatter = yaml.parse(frontmatterYAML) || {}; // Handle potential YAML parsing errors
      body = data.substring(frontmatterEnd + separator.length).trim();
    }
  }

  return formatDataJs({
    ...frontmatter,
    body,
  });
}

export function formatDataJs(data: Record<string, any>) {
  const normalizedData: Record<string, any> = {};
  for (const [key, value] of Object.entries(data)) {
    if (value instanceof Date) {
      normalizedData[key] = value;
    } else if (isDateField(key) && typeof value === 'string') {
      normalizedData[key] = new Date(value);
    } else {
      normalizedData[key] = value;
    }
  }
  return normalizedData;
}

export function formatDataSql(data: Record<string, any>) {
  const normalizedData: Record<string, any> = {};
  for (const [key, value] of Object.entries(data)) {
    if (value instanceof Date) {
      normalizedData[key] = value.toISOString(); // Postgres accepts ISO format with timezone
    } else {
      normalizedData[key] = value;
    }
  }
  return normalizedData;
}
</file>

<file path="packages/smrt/README.md">
this cant be a good idea

objects that save themselves to a database and have baked in ai functionality

object can be identified by id, slug, name, title, or a composite of these
objects have context to scope slug and deratives matches (title, name)
</file>

<file path="packages/smrt/tsconfig.json">
{
  "extends": "../../tsconfig.json",
  "compilerOptions": {
    "outDir": "./dist",
    "rootDir": "./src",
    "composite": true,
    "declaration": true,
    "declarationMap": true
  },
  "include": ["src/**/*"],
  "exclude": ["dist", "node_modules", "**/*.spec.ts"]
}
</file>

<file path="packages/spider/src/crawl4ai.spec.ts">
import { it, expect } from 'vitest';

it('should be able to use crawl4ai', () => {
  expect(true).toBe(true);
});
</file>

<file path="packages/spider/src/crawl4ai.ts">
// request = {
//   "urls": "https://example.com",
//   "crawler_params": {
//       # Browser Configuration
//       "headless": True,                    # Run in headless mode
//       "browser_type": "chromium",          # chromium/firefox/webkit
//       "user_agent": "custom-agent",        # Custom user agent
//       "proxy": "http://proxy:8080",        # Proxy configuration

//       # Performance & Behavior
//       "page_timeout": 30000,               # Page load timeout (ms)
//       "verbose": True,                     # Enable detailed logging
//       "semaphore_count": 5,               # Concurrent request limit

//       # Anti-Detection Features
//       "simulate_user": True,               # Simulate human behavior
//       "magic": True,                       # Advanced anti-detection
//       "override_navigator": True,          # Override navigator properties

//       # Session Management
//       "user_data_dir": "./browser-data",   # Browser profile location
//       "use_managed_browser": True,         # Use persistent browser
//   }
// }

export function getCrawler() {}

interface CrawlResponse {
  task_id: string;
}

interface TaskStatus {
  status: string;
  [key: string]: any; // For additional fields in the response
}

interface ExtraParams {
  word_count_threshold?: number; // Min words per block
  only_text?: boolean; // Extract only text
  bypass_cache?: boolean; // Force fresh crawl
  process_iframes?: boolean; // Include iframe content
}

interface CrawlerParams {
  // Browser Configuration
  headless?: boolean;
  browser_type?: 'chromium' | 'firefox' | 'webkit';
  user_agent?: string;
  proxy?: string;

  // Performance & Behavior
  page_timeout?: number;
  verbose?: boolean;
  semaphore_count?: number;
  remove_overlay_elements?: boolean; // Remove popups

  // Anti-Detection Features
  simulate_user?: boolean;
  magic?: boolean;
  override_navigator?: boolean;

  // Session Management
  user_data_dir?: string;
  use_managed_browser?: boolean;
}

interface CrawlRequest {
  urls: string | string[];
  crawler_params?: CrawlerParams;
  extra?: ExtraParams;
  css_selector?: string; // CSS selector for targeting specific elements
}

class Crawler {
  private baseUrl: string;

  constructor(baseUrl: string = 'http://localhost:11235') {
    this.baseUrl = baseUrl;
  }

  async submitAndWait(
    requestData: CrawlRequest,
    timeout: number = 300000,
  ): Promise<TaskStatus> {
    // Submit crawl job
    const response = await fetch(`${this.baseUrl}/crawl`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(requestData),
    });

    const { task_id } = (await response.json()) as CrawlResponse;
    console.log(`Task ID: ${task_id}`);

    // Poll for result
    const startTime = Date.now();
    while (true) {
      if (Date.now() - startTime > timeout) {
        throw new Error(`Task ${task_id} timeout`);
      }

      const result = await fetch(`${this.baseUrl}/task/${task_id}`);
      const status = (await result.json()) as TaskStatus;

      if (status.status === 'completed') {
        return status;
      }

      await new Promise((resolve) => setTimeout(resolve, 2000));
    }
  }
}
</file>

<file path="packages/spider/src/index.spec.ts">
import { fetchPageSource, getBrowser } from './index.js';
import { it, expect } from 'vitest';

it('should fetch page source cheaply with caching', async () => {
  const result = (() => true)();
  expect(result).toBe(true);

  const source = await fetchPageSource({
    url: 'https://www.google.com',
    cheap: true,
  });

  const cached = await fetchPageSource({
    url: 'https://www.google.com',
    cheap: true,
  });

  expect(source).toBeDefined();
  expect(source).not.toBe('');
  expect(cached).toBe(source);
});

it('should fetch page source using playwright', async () => {
  const result = (() => true)();
  expect(result).toBe(true);
  const browser = await getBrowser();

  const source = await fetchPageSource({
    url: 'https://www.google.com',
    cheap: false,
    browser,
  });

  const cached = await fetchPageSource({
    url: 'https://www.google.com',
    cheap: false,
    browser,
  });

  expect(cached).toBeDefined();
  expect(source).toBeDefined();
  expect(source).not.toBe('');
  expect(cached).toBe(source);
});
</file>

<file path="packages/spider/src/index.ts">
import path from 'path';
import { chromium } from 'playwright-core';
import type { Browser } from 'playwright-core';
import { urlFilename, urlPath } from '@have/utils';
import * as cheerio from 'cheerio';

import { fetchText, getCached, setCached } from '@have/files';

interface FetchPageSourceOptions {
  url: string;
  cheap: boolean;
  browser?: Browser; // if not supplied, we'll use a cheap fetch
  cache?: boolean;
  cacheExpiry?: number;
}

export async function fetchPageSource(
  options: FetchPageSourceOptions,
): Promise<string> {
  const { url, cheap = true, browser, cacheExpiry = 300000 } = options;

  if (cheap || !browser) {
    const cachedFile = path.join(urlPath(url), '.cheap', urlFilename(url));
    const cached = await getCached(cachedFile, cacheExpiry);
    if (cached) {
      console.log(`[${url}] using cached file`);
      return cached;
    }

    // const response = await fetch(url);
    // const content = await response.text();

    const content = await fetchText(url);

    await setCached(cachedFile, content);
    return content;
  }

  const cachedFile = path.join(urlPath(url), urlFilename(url));
  const cached = await getCached(cachedFile, cacheExpiry);
  if (cached) {
    return cached;
  }

  const page = await browser.newPage();
  await page.goto(url, { waitUntil: 'networkidle' });
  const content = await page.content();
  await page.close();
  await setCached(cachedFile, content);
  return content;
}

export async function parseIndexSource(indexSource: string): Promise<string[]> {
  const $ = cheerio.load(indexSource);

  const items: string[] = [];
  let content: string = '';

  // Check if it's an index page by looking for multiple items
  if ($('a').length > 1) {
    $('a').each((_, element) => {
      const item = $(element).attr('href');
      // console.log({ item });
      if (item) items.push(item);
    });
  } else {
    // Assume it's a content page if not an index
    content = $('body').text().trim();
  }
  return items;
}

export async function getBrowser(): Promise<Browser> {
  const browser = await chromium.launch({
    headless: true,
  });
  return browser;
}

export default {
  fetchPageSource,
  parseIndexSource,
  getBrowser,
};
</file>

<file path="packages/spider/tsconfig.json">
{
  "extends": "../../tsconfig.json",
  "compilerOptions": {
    "outDir": "./dist",
    "rootDir": "./src",
    "composite": true
  },
  "include": ["src/**/*"]
}
</file>

<file path="packages/sql/src/postgres.spec.ts">
import { it, expect, describe, beforeEach, afterEach } from "vitest";
import { randomUUID } from "crypto";
import { getDatabase } from "./index.js";
describe.skip("postgres tests", () => {
  let db: Awaited<ReturnType<typeof getDatabase>>;
  beforeEach(async () => {
    db = await getDatabase({
      type: "postgres",
      database: process.env.SQLOO_NAME || "sqloo",
      host: process.env.SQLOO_HOST || "localhost",
      user: process.env.SQLOO_USER || "sqloo",
      password: process.env.SQLOO_PASS || "sqloo",
      port: Number(process.env.SQLOO_PORT) || 5432,
    });

    await db.execute`
      create extension if not exists "uuid-ossp";
      drop table if exists contents;
      create table contents (
        id uuid primary key not null default (uuid_generate_v4()),
        title text, 
        body text
      )
    `;
  });

  afterEach(async () => {
    await db.execute`drop table contents`;
    await db.client.end();
  });

  it("should be able to perform a statement", async () => {
    const result = await db.many`
      select * from contents
    `;
    expect(result).toEqual(expect.arrayContaining([]));
  });

  it("should be able to insert data", async () => {
    const inserted = await db.insert("contents", {
      title: "hello",
      body: "world",
    });
    expect(inserted).toBeDefined();
    expect(inserted.affected).toBe(1);
  });

  it("should be able to insert multiple rows at a time", async () => {
    const inserted = await db.insert("contents", [
      {
        title: "hello",
        body: "world",
      },
      {
        title: "hi",
        body: "universe",
      },
    ]);
    expect(inserted.affected).toBe(2);
  });

  it("should be able to query data with a condition", async () => {
    await db.insert("contents", { title: "hello", body: "world" });
    const result = await db.many`
      select * from contents where title = ${"hello"}
    `;
    expect(result[0]).toEqual(
      expect.objectContaining({
        id: expect.any(String),
        title: "hello",
        body: "world",
      }),
    );
  });

  it("should be able to get a single row", async () => {
    await db.insert("contents", { title: "hello", body: "world" });
    const result = await db.single`
      select * from contents where title = ${"hello"}
    `;
    expect(result).toEqual(
      expect.objectContaining({
        id: expect.any(String),
        title: "hello",
        body: "world",
      }),
    );
  });

  it("should be able to update a row", async () => {
    const id = randomUUID();
    const inserted = await db.insert("contents", {
      id,
      title: "hello",
      body: "world",
    });
    expect(inserted.affected).toBe(1);
    const updated = await db.update(
      "contents",
      { id },
      { title: "hi", body: "universe" },
    );
    expect(updated.affected).toBe(1);
    const result = await db.oO`
      select * from contents where id = ${id}
    `;
    expect(result?.id).toEqual(id);
    expect(result?.title).toEqual("hi");
    expect(result?.body).toEqual("universe");
  });
});
</file>

<file path="packages/sql/src/postgres.ts">
import { Pool, PoolClient, QueryResult } from "pg";

export interface PostgresOptions {
  url?: string;
  database?: string;
  host?: string;
  user?: string;
  password?: string;
  port?: number;
}

interface QueryResponse {
  operation: string;
  affected: number;
}

interface TableMethods {
  insert: (
    data: Record<string, any> | Record<string, any>[],
  ) => Promise<QueryResponse>;
  get: (data: Record<string, any>) => Promise<QueryResult>;
  list: (data: Record<string, any>) => Promise<any[]>;
}

export function getDatabase(options: PostgresOptions = {}) {
  const {
    url = process.env.SQLOO_URL,
    database = process.env.SQLOO_DATABASE,
    host = process.env.SQLOO_HOST || "localhost",
    user = process.env.SQLOO_USER,
    password = process.env.SQLOO_PASSWORD,
    port = Number(process.env.SQLOO_PORT) || 5432,
  } = options;

  const client = new Pool(
    url
      ? { connectionString: url }
      : {
          host,
          user,
          password,
          port,
          database,
        },
  );

  /**
   * Inserts data into a table and returns the inserted rows.
   */
  const insert = async (
    table: string,
    data: Record<string, any> | Record<string, any>[],
  ): Promise<QueryResponse> => {
    // If data is an array, we need to handle multiple rows
    if (Array.isArray(data)) {
      const keys = Object.keys(data[0]);
      const placeholders = data
        .map(
          (_, i) =>
            `(${keys.map((_, j) => `$${i * keys.length + j + 1}`).join(", ")})`,
        )
        .join(", ");
      const query = `INSERT INTO ${table} (${keys.join(
        ", ",
      )}) VALUES ${placeholders}`;
      const values = data.reduce(
        (acc, row) => acc.concat(Object.values(row)),
        [],
      );
      const result = await client.query(query, values);
      return { operation: "insert", affected: result.rowCount ?? 0 };
    } else {
      // If data is an object, we handle a single row
      const keys = Object.keys(data);
      const values = Object.values(data);
      const placeholders = keys.map((_, i) => `$${i + 1}`).join(", ");
      const query = `INSERT INTO ${table} (${keys.join(
        ", ",
      )}) VALUES (${placeholders})`;
      const result = await client.query(query, values);
      return { operation: "insert", affected: result.rowCount ?? 0 };
    }
  };

  /**
   * Retrieves a row from a table based on a where clause.
   */
  const get = async (
    table: string,
    where: Record<string, any>,
  ): Promise<QueryResult> => {
    const keys = Object.keys(where);
    const values = Object.values(where);
    const whereClause = keys
      .map((key, i) => `${key} = $${i + 1}`)
      .join(" AND ");
    const query = `SELECT * FROM ${table} WHERE ${whereClause}`;
    return client.query(query, values);
  };

  /**
   * Retrieves multiple rows from a table based on a where clause.
   */
  const list = async (
    table: string,
    where: Record<string, any>,
  ): Promise<any[]> => {
    const keys = Object.keys(where);
    const values = Object.values(where);
    const whereClause = keys
      .map((key, i) => `${key} = $${i + 1}`)
      .join(" AND ");
    const query = `SELECT * FROM ${table} WHERE ${whereClause}`;
    const result = await client.query(query, values);
    return result.rows;
  };

  /**
   * Updates rows in a table based on a where clause and returns the updated rows.
   */
  const update = async (
    table: string,
    where: Record<string, any>,
    data: Record<string, any>,
  ): Promise<QueryResponse> => {
    const keys = Object.keys(data);
    const values = Object.values(data);
    const setClause = keys.map((key, i) => `${key} = $${i + 1}`).join(", ");
    const whereKeys = Object.keys(where);
    const whereValues = Object.values(where);
    const whereClause = whereKeys
      .map((key, i) => `${key} = $${i + 1 + values.length}`)
      .join(" AND ");

    const sql = `UPDATE ${table} SET ${setClause} WHERE ${whereClause}`;
    const result = await client.query(sql, [...values, ...whereValues]);
    return { operation: "update", affected: result.rowCount ?? 0 };
  };

  const getOrInsert = async (
    table: string,
    where: Record<string, any>,
  ): Promise<QueryResult | QueryResponse> => {
    const result = await get(table, where);
    if (result) return result;
    return insert(table, where);
  };

  const table = (tableName: string): TableMethods => {
    return {
      insert: (data) => insert(tableName, data),
      get: (data) => get(tableName, data),
      list: (data) => list(tableName, data),
    };
  };

  interface SqlTemplate {
    sql: string;
    values: any[];
  }

  const parseTemplate = (
    strings: TemplateStringsArray,
    ...vars: any[]
  ): SqlTemplate => {
    let sql = strings[0];
    const values = [];
    for (let i = 0; i < vars.length; i++) {
      values.push(vars[i]);
      sql += "$" + (i + 1) + strings[i + 1];
    }
    return { sql, values };
  };

  const pluck = async (
    strings: TemplateStringsArray,
    ...vars: any[]
  ): Promise<any> => {
    const { sql, values } = parseTemplate(strings, ...vars);
    const result = await client.query(sql, values);
    return result.rows[0][0];
  };

  const single = async (
    strings: TemplateStringsArray,
    ...vars: any[]
  ): Promise<Record<string, any> | null> => {
    const { sql, values } = parseTemplate(strings, ...vars);
    const result = await client.query(sql, values);
    return result.rows[0];
  };

  const many = async (
    strings: TemplateStringsArray,
    ...vars: any[]
  ): Promise<Record<string, any>[]> => {
    const { sql, values } = parseTemplate(strings, ...vars);
    const { rows } = await client.query(sql, values);
    return rows;
  };

  const execute = async (
    strings: TemplateStringsArray,
    ...vars: any[]
  ): Promise<void> => {
    const { sql, values } = parseTemplate(strings, ...vars);
    await client.query(sql, values);
  };

  const query = async (
    sql: string,
    values: any[],
  ): Promise<{ rows: Record<string, any>[]; rowCount: number }> => {
    const result = await client.query(sql, values);
    return {
      rows: result.rows,
      rowCount: result.rowCount ?? 0,
    };
  };

  const tableExists = async (tableName: string): Promise<boolean> => {
    const result = await client.query(
      `SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = $1)`,
      [tableName],
    );
    return result.rows[0].exists;
  };
  // cute aliases
  const oo = many;
  const oO = single;
  const ox = pluck;
  const xx = execute;

  return {
    client,
    insert,
    update,
    get,
    getOrInsert,
    list,
    table,
    many,
    single,
    pluck,
    execute,
    query,
    oo,
    oO,
    ox,
    xx,
    tableExists,
  };
}
</file>

<file path="packages/sql/src/sqlite.spec.ts">
import { it, expect, describe, beforeEach, afterEach } from "vitest";
import { randomUUID } from "node:crypto";
import { getDatabase } from "./index.js";
// import type { Database } from "./types";

describe("sqlite tests", () => {
  let db: any;

  beforeEach(async () => {
    db = await getDatabase({
      type: "sqlite",
    });
    await db.execute`
      create table contents (
        id uuid primary key not null,
        title text, 
        body text
      )
    `;
  });

  afterEach(async () => {
    await db.execute`
      drop table contents
    `;
  });

  it("should be able to perform a statement", async () => {
    const result = await db.many`
      select * from contents
    `;
    expect(result).toEqual([]);
  });

  it("should be able to insert data", async () => {
    const data = {
      id: randomUUID(),
      title: "hello",
      body: "world",
    } as const;
    const inserted = await db.insert("contents", data);
    expect(inserted).toBeDefined();
  });

  it("should be able to query data with a condition", async () => {
    const data = {
      id: randomUUID(),
      title: "hello",
      body: "world",
    } as const;
    await db.insert("contents", data);
    const result = await db.single`
      select * from contents where id = ${data.id}
    `;
    expect(result).toEqual({
      id: data.id,
      title: data.title,
      body: data.body,
    });
  });

  it("should be able to update a row", async () => {
    const data = {
      id: randomUUID(),
      title: "hello",
      body: "world",
    } as const;
    await db.insert("contents", data);
    await db.update(
      "contents",
      { id: data.id },
      { title: "hi", body: "universe" },
    );
    const result = await db.single`
      select * from contents where id = ${data.id}
    `;
    expect(result).toEqual({ id: data.id, title: "hi", body: "universe" });
  });
});
</file>

<file path="packages/sql/src/types.ts">
export interface DatabaseOptions {
  url?: string;
  authToken?: string;
}

export interface QueryResult {
  operation: string;
  affected: number;
}

export interface DatabaseInterface {
  client: any;
  insert: (
    table: string,
    data: Record<string, any> | Record<string, any>[],
  ) => Promise<QueryResult>;
  get: (
    table: string,
    where: Record<string, any>,
  ) => Promise<Record<string, any> | null>;
  list: (
    table: string,
    where: Record<string, any>,
  ) => Promise<Record<string, any>[]>;
  update: (
    table: string,
    where: Record<string, any>,
    data: Record<string, any>,
  ) => Promise<QueryResult>;
  getOrInsert: (
    table: string,
    where: Record<string, any>,
    data: Record<string, any>,
  ) => Promise<Record<string, any>>;
  table: (table: string) => TableInterface;
  tableExists: (table: string) => Promise<boolean>;
  many: (
    strings: TemplateStringsArray,
    ...vars: any[]
  ) => Promise<Record<string, any>[]>;
  single: (
    strings: TemplateStringsArray,
    ...vars: any[]
  ) => Promise<Record<string, any> | null>;
  pluck: (strings: TemplateStringsArray, ...vars: any[]) => Promise<any>;
  execute: (strings: TemplateStringsArray, ...vars: any[]) => Promise<void>;
  oo: (
    strings: TemplateStringsArray,
    ...vars: any[]
  ) => Promise<Record<string, any>[]>;
  oO: (
    strings: TemplateStringsArray,
    ...vars: any[]
  ) => Promise<Record<string, any> | null>;
  ox: (strings: TemplateStringsArray, ...vars: any[]) => Promise<any>;
  xx: (strings: TemplateStringsArray, ...vars: any[]) => Promise<void>;
  query: (
    str: string,
    ...vars: any[]
  ) => Promise<{ rows: Record<string, any>[]; rowCount: number }>;
}

export interface TableInterface {
  insert: (
    data: Record<string, any> | Record<string, any>[],
  ) => Promise<QueryResult>;
  get: (where: Record<string, any>) => Promise<Record<string, any> | null>;
  list: (where: Record<string, any>) => Promise<Record<string, any>[]>;
}
</file>

<file path="packages/sql/.gitignore">
node_modules/
.envrc
.env
</file>

<file path="packages/sql/.prettierrc">
{
  "tabWidth": 2,
  "useTabs": false
}
</file>

<file path="packages/sql/docker-compose.yml">
version: "3.1"
services:
  postgres:
    image: postgres:latest
    environment:
      POSTGRES_USER: sqloo
      POSTGRES_PASSWORD: sqloo
      POSTGRES_DB: sqloo
    ports:
      - "35432:5432"
</file>

<file path="packages/sql/README.md">
# formerly sqloo

a simple interface to sqlite and/or postgres for basic tasks

```js
// get a postgres database
const db = await getDatabase({
  host: "localhost",
  port: 5432,
  database: "sqlooooo",
  user: "oO",
  password: "ackBillD.C@",
});
```

```js
// get a sqlite database
const db = await getDatabase({
  file: "::memory::",
});
```

```js
// fetch all the posts
const { oo } = db;
const posts = await oo`
  select * from posts
`;
```

```js
// fetch a single post
const { oO } = db;
const post = await oO`
  select * from posts where author = ${author} order by created_at desc limit 1
`;
```

```js
// pluck the first value from the first row
const { ox } = db;
const id = await ox`
  select id from posts where author = ${author} order by created_at desc limit 1
`;
```

```js
// execute a statement
const { xx } = db;
await xx`
  delete from posts where author = ${author}
`;
```

## Functions (db.\*)

### `insert(table, data)`

Inserts data into a table and returns the inserted rows.

- `table` (string): The name of the table.
- `data` (Object | Object[]): The data to insert.
- Returns: `Promise<Object | Object[]>`: The inserted rows, return type will match data.

### `get(table, where)`

Retrieves a row from a table based on a where clause.

- `table` (string): The name of the table.
- `where` (Object): The where clause.
- Returns: `Promise<Object>`: The retrieved row.

### `list(table, where)`

Retrieves multiple rows from a table based on a where clause.

- `table` (string): The name of the table.
- `where` (Object): The where clause.
- Returns: `Promise<Array>`: The retrieved rows.

### `update(table, where, data)`

Updates rows in a table based on a where clause and returns the updated rows.

- `table` (string): The name of the table.
- `where` (Object): The where clause.
- `data` (Object): The data to update.
- Returns: `Promise<Object>`: The updated rows.

### `table(table)`

Returns an object with insert, get, and list methods for a specific table.

- `table` (string): The name of the table.
- Returns: `Object`: An object with insert, get, and list methods.

### `parseTemplate(strings, ...vars)`

Parses a SQL template into a SQL string and an array of values.

- `strings` (Array): The strings in the SQL template.
- `vars` (...any): The variables in the SQL template.
- Returns: `Object`: An object with a sql property and a values property.

### `pluck(strings, ...vars)`

Executes a SQL query and returns the first column of the first row. Handles templates with it's alias "xo"

- `strings` (TemplateStringsArray): The strings in the SQL template.
- `vars` (...any): The variables in the SQL template.
- Returns: `Promise<any>`: The first column of the first row.

### `single(strings, ...vars)`

Executes a SQL query and returns the first row. Handles templates with it's alias "oO"

- `strings` (TemplateStringsArray): The strings in the SQL template.
- `vars` (...any): The variables in the SQL template.
- Returns: `Promise<Object>`: The first row.

### `many(strings, ...vars)`

Executes a SQL query and returns all rows. Handles templates with it's alias "oo"

- `strings` (TemplateStringsArray): The strings in the SQL template.
- `vars` (...any): The variables in the SQL template.
- Returns: `Promise<Array>`: All rows.

### `execute(strings, ...vars)`

Executes a SQL query. Handles templates with it's alias "xx"

- `strings` (TemplateStringsArray): The strings in the SQL template.
- `vars` (...any): The variables in the SQL template.
- Returns: `Promise<pg.QueryResult>`: The result of the query.

## Warning

- dont use variables for anything except values in template queries
- dont accept unsantized user input for table or column names

# chats

## raw sql

is there a standard both sqlite and postgres adhere to? What does ANSI compatible mean exactly?

If I say, "raw sql should be kept as ANSI compatible with more complex operations moved to per-database-adapter functions " does that make sense ?

The goal being the raw sql remains compatible between sqlite and postgres/mysql

ChatGPT said:
ChatGPT
Yes, both SQLite and PostgreSQL adhere to SQL standards, specifically versions of ANSI SQL (American National Standards Institute SQL), also known as ISO SQL (since it’s standardized by ISO/IEC as well). However, no database fully implements the standard, and each has its own extensions and deviations.

What "ANSI Compatible" Means
When you say "ANSI-compatible," it generally means:

Using standard SQL syntax (e.g., SELECT, INSERT, UPDATE, DELETE, JOIN, WHERE, GROUP BY).
Avoiding database-specific extensions (e.g., ILIKE in PostgreSQL, AUTOINCREMENT in SQLite).
Using standard data types where possible (INTEGER, TEXT, DECIMAL instead of SERIAL in Postgres or BOOLEAN in SQLite).
Ensuring compatibility in functions and operators (COALESCE(), CASE WHEN, etc.).
Your Approach
Your statement:

"Raw SQL should be kept as ANSI compatible with more complex operations moved to per-database-adapter functions."
Makes sense and is a good practice. This means:

Keep simple queries ANSI-compliant, so they work across SQLite, PostgreSQL, and potentially MySQL.
Move complex operations (e.g., JSON handling, CTEs, window functions, full-text search, advanced indexing) into per-database adapters.
Considerations
Column types: BOOLEAN is not standard; SQLite treats it as INTEGER. Use INTEGER (0/1) instead.
Auto-increment: PostgreSQL uses SERIAL, while SQLite uses INTEGER PRIMARY KEY AUTOINCREMENT. Standard SQL uses IDENTITY.
Upserts: Use INSERT ... ON CONFLICT DO UPDATE (PostgreSQL, SQLite) vs. INSERT ... ON DUPLICATE KEY UPDATE (MySQL).
JSON: PostgreSQL has jsonb, while SQLite requires extensions.
Date/Time: Use TEXT with ISO 8601 format (YYYY-MM-DD HH:MM:SS) for portability.
Summary
Your approach is solid: keep simple SQL portable and delegate complex operations to database-specific adapters.
</file>

<file path="packages/sql/tsconfig.json">
{
  "extends": "../../tsconfig.json",
  "compilerOptions": {
    "outDir": "./dist",
    "rootDir": "./src",
    "composite": true,
    "declaration": true,
    "declarationMap": true
  },
  "include": ["src/**/*"],
  "exclude": ["dist", "node_modules", "**/*.test.ts"]
}
</file>

<file path="packages/utils/src/index.spec.ts">
import { it, expect } from 'vitest';
import { parseAmazonDateString, sleep, waitFor } from './index.js';

it('should have a test', () => {
  expect(true).toBe(true);
});

it.skip('should waitFor "it"', async () => {
  let attempts = 0;
  const result = await waitFor(
    async () => {
      attempts++;
      if (attempts >= 5) {
        return true;
      }
    },
    {
      timeout: 0, // 0 = don't timeout
      delay: 10,
    },
  );
  expect(result).toEqual(true);
});

it.skip('should waitFor "it" only so long', async () => {
  let attempts = 0;
  expect.assertions(1);
  await expect(
    waitFor(
      async () => {
        attempts++;
        await sleep(1000);
        if (attempts >= 10) {
          return true;
        }
      },
      {
        delay: 1000, // should tick 3 times
        timeout: 30000,
      },
    ),
  ).rejects.toEqual('Timed out');
});

it.skip('shoulde able to parse an amazon date', () => {
  const result = parseAmazonDateString('20220223T215409Z');
  expect(result).toBeDefined();
});
</file>

<file path="packages/utils/tsconfig.json">
{
  "extends": "../../tsconfig.json",
  "compilerOptions": {
    "outDir": "dist",
    "rootDir": "src",
    "composite": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist"]
}
</file>

<file path="scripts/update-package-versions.cjs">
const fs = require('fs');
const path = require('path');

const rootPackageJson = require('../package.json');
const newVersion = rootPackageJson.version;

const packagesDir = path.join(__dirname, '..', 'packages'); // Assuming packages are in 'packages' dir
const packageDirs = fs
  .readdirSync(packagesDir)
  .filter((dir) => fs.statSync(path.join(packagesDir, dir)).isDirectory());

packageDirs.forEach((packageDirName) => {
  const packageJsonPath = path.join(
    packagesDir,
    packageDirName,
    'package.json',
  );
  if (fs.existsSync(packageJsonPath)) {
    const packageJson = require(packageJsonPath);
    packageJson.version = newVersion;
    fs.writeFileSync(
      packageJsonPath,
      JSON.stringify(packageJson, null, 2) + '\n',
    );
    console.log(`Updated version in ${packageJsonPath} to ${newVersion}`);
  }
});

console.log('Package versions updated successfully.');
</file>

<file path=".nvmrc">
v22
</file>

<file path="LICENSE">
Copyright <2025> <Happy Vertical Corporation>

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
</file>

<file path="pnpm-workspace.yaml">
packages:
  - "packages/*"
</file>

<file path="README.md">
# HAppy VEertical _SDK_

# what

- a dangerous library for fools and madmen (currently)
- pure ts, never want to worry about cjs vs esm agin
- test cheap scale easy
- minimise dependencies with monorepo maintained by robots .. shadcdn philosophy applied to backend
- re-useable libraries for building vertical ai agents
- code compartmentalised to keep robots lean
- i want to be able to run stuff in cicd jobs and as part of a (sveltekit) site build

# why

i want to replace dependency hell with robots work
i want to test a crazy idea cheap and if it gets traction move to production without requiring a massive refactor
if shadcdn can do it on the frontend, why not

# how

i hate vendor lock
i hate overhead
i hate dependencies
sqlite is cool and can be useful on the edge

# packages

- ai: a library for interacting with ai models, provides a standardised interface
- sql: a library for interacting with sql databases, provides a standardised interface (sqlite and postgres)
  - not trying to be an orm
- web: tools for crawling the web, scraping content, and parsing it into a standardised format - maybe rename to spider
- files: a library for interacting with file systems, provides a standardised interface for local and remote file systems
- smrt: a library for building vertical ai agents, probably anything but
  - standardised collection, object, classes .. all include db, fs, ai interfaces and options
  - fast and loose database schemas defined by class properties supporting sqlite first and an eye on postgres

# cheatsheet

```bash
pnpx degit huntabyte/shadcdn-svelte/sites/docs/src/lib/registry/default/ui/card ./src/lib/components/card

```

https://github.com/
</file>

<file path="tsconfig.json">
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "ESNext",
    "moduleResolution": "Bundler",
    "declaration": true,
    "strict": true,
    "experimentalDecorators": true,
    "emitDecoratorMetadata": true,
    "skipLibCheck": true,
    "lib": ["ES2020"]
  },
  "exclude": ["node_modules", "**/dist"]
}
</file>

<file path="vitest.config.ts">
import { defineConfig } from 'vitest/config';
import path from 'path';

export default defineConfig({
  test: {
    include: ['packages/**/src/**/*.{test,spec}.{js,ts}'],
    globals: true,
    environment: 'node',
    globalSetup: path.resolve(__dirname, './vitest.setup.ts'),
    sequence: {
      hooks: 'list',
    },
    poolOptions: {
      threads: {
        singleThread: true,
      },
    },
  },
});
</file>

<file path="vitest.setup.ts">
import { promises as fs } from 'fs';
import path from 'path';
import { tmpdir } from 'os';

export const TMP_DIR = path.resolve(`${tmpdir()}/.have-sdk/tests`);

export async function setup() {
  try {
    await fs.mkdir(TMP_DIR, { recursive: true });
    console.log('Test setup complete');
  } catch (error) {
    console.error('Error in test setup', error);
  } finally {
    // cleanup
  }
}
</file>

<file path=".gitea/workflows/on-merge-master.yaml">
name: merged to master

on:
  push:
    branches:
      - master-disabled

jobs:
  versioning:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Fetch all history.

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'

      - name: Install pnpm
        run: npm install -g pnpm

      - name: Show pnpm version
        run: pnpm --version

      - name: Configure pnpm registry and authentication
        run: |
          pnpm config set @happyvertical:registry=https://git.grffn.net/api/packages/happyvertical/npm/
          pnpm config set @have:registry=https://git.grffn.net/api/packages/happyvertical/npm/
          echo "//git.grffn.net/api/packages/happyvertical/npm/:_authToken=${{ secrets.GITEATOKEN }}" > .npmrc

      - name: Cache pnpm store
        uses: actions/cache@v4
        with:
          path: ~/.pnpm-store
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      - name: Install dependencies
        run: pnpm install

      - name: Install Playwright Browsers
        run: pnpm dlx playwright install

      - name: Cache Playwright Browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright # Default Playwright cache directory.
          key: ${{ runner.os }}-playwright-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-playwright-

      - name: Build packages
        run: pnpm build

      - name: Commit and push changes for release
        run: |
          git config user.name "Gitea Bot"
          git config user.email "bot@example.com"

      - name: Bump version and release
        run: pnpm run release

      - name: Commit and push changes
        run: |
          git add .
          git commit -m "chore(release): bump version to $(node -p "require('./package.json').version")" --no-verify
          git push --no-verify --follow-tags

      - name: Publish packages
        run: pnpm run publish-packages
</file>

<file path=".github/workflows/agents/claude.yaml">
name: Claude Assistant
on:
  issue_comment:
    types: [created]
  pull_request_review_comment:
    types: [created]
  issues:
    types: [opened, assigned]
  pull_request_review:
    types: [submitted]

jobs:
  claude-response:
    runs-on: ubuntu-latest
    steps:
      - uses: anthropics/claude-code-action@beta
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          # Optional: add custom trigger phrase (default: @claude)
          # trigger_phrase: "/claude"
          # Optional: add assignee trigger for issues
          # assignee_trigger: "claude"
</file>

<file path=".github/workflows/on-pr-master-dependabot.yml">
name: Dependabot Automation

on:
  pull_request:
    branches: [ master ]

permissions:
  contents: write
  pull-requests: write

jobs:
  dependabot:
    runs-on: ubuntu-latest
    if: ${{ github.actor == 'dependabot[bot]' }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          
      - name: Setup pnpm
        uses: pnpm/action-setup@v3
        with:
          version: latest
          
      - name: Install dependencies
        run: pnpm install
        
      - name: Build packages
        run: pnpm build
        
      - name: Run tests
        run: pnpm test
        
      - name: Dependabot metadata
        id: metadata
        uses: dependabot/fetch-metadata@v2
        with:
          github-token: "${{ secrets.GITHUB_TOKEN }}"
          
      - name: Approve PR
        if: ${{ steps.metadata.outputs.update-type != 'version-update:semver-major' }}
        run: gh pr review --approve "$PR_URL"
        env:
          PR_URL: ${{ github.event.pull_request.html_url }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Enable auto-merge for minor and patch updates
        if: ${{ steps.metadata.outputs.update-type == 'version-update:semver-minor' || steps.metadata.outputs.update-type == 'version-update:semver-patch' }}
        run: gh pr merge --auto --merge "$PR_URL"
        env:
          PR_URL: ${{ github.event.pull_request.html_url }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
</file>

<file path=".github/config-dependabot.yml">
version: 2
updates:
  # Enable version updates for npm/pnpm
  - package-ecosystem: "npm"
    # Look for `package.json` and `lock` files in the root directory
    directory: "/"
    # Check for updates once a week
    schedule:
      interval: "weekly"
    # Allow up to 10 open pull requests at a time
    open-pull-requests-limit: 10
    # Set a version update strategy
    versioning-strategy: increase
    # Specify package manager
    package-manager: "pnpm"
    # Groups to reduce PR noise
    groups:
      # Group all dev dependencies together
      dev-dependencies:
        patterns:
          - "@biomejs/*"
          - "typescript"
          - "vitest"
          - "lefthook"
          - "standard-version"
          - "@changesets/*"
          - "conventional-changelog-cli"
    
  # Also check for updates in each package directory
  - package-ecosystem: "npm"
    directory: "/packages/utils"
    schedule:
      interval: "weekly"
    open-pull-requests-limit: 5
    versioning-strategy: increase
    package-manager: "pnpm"
    
  - package-ecosystem: "npm"
    directory: "/packages/files"
    schedule:
      interval: "weekly"
    open-pull-requests-limit: 5
    versioning-strategy: increase
    package-manager: "pnpm"
    
  - package-ecosystem: "npm"
    directory: "/packages/spider"
    schedule:
      interval: "weekly"
    open-pull-requests-limit: 5
    versioning-strategy: increase
    package-manager: "pnpm"
    
  - package-ecosystem: "npm"
    directory: "/packages/sql"
    schedule:
      interval: "weekly"
    open-pull-requests-limit: 5
    versioning-strategy: increase
    package-manager: "pnpm"
    
  - package-ecosystem: "npm"
    directory: "/packages/pdf"
    schedule:
      interval: "weekly"
    open-pull-requests-limit: 5
    versioning-strategy: increase
    package-manager: "pnpm"
    
  - package-ecosystem: "npm"
    directory: "/packages/ai"
    schedule:
      interval: "weekly"
    open-pull-requests-limit: 5
    versioning-strategy: increase
    package-manager: "pnpm"
    
  - package-ecosystem: "npm"
    directory: "/packages/smrt"
    schedule:
      interval: "weekly"
    open-pull-requests-limit: 5
    versioning-strategy: increase
    package-manager: "pnpm"
    
  - package-ecosystem: "npm"
    directory: "/packages/svelte"
    schedule:
      interval: "weekly"
    open-pull-requests-limit: 5
    versioning-strategy: increase
    package-manager: "pnpm"
    
  # Enable version updates for GitHub Actions
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "weekly"
    open-pull-requests-limit: 5
</file>

<file path="packages/ai/src/client.ts">
import 'openai/shims/node';
import OpenAI from 'openai';

import type { AIMessageOptions } from './message.js';

export interface AIClientOptions {
  type?: string;
  responseFormat?: string;
  apiKey?: string;
  baseUrl?: string;
}


export interface AIClientInterface {
  options: AIClientOptions;
  message(text: string, options: AIMessageOptions): Promise<unknown>;
  textCompletion(text: string, options: AIMessageOptions): Promise<unknown>;
}

function isOpenAIClientOptions(
  options: AIClientOptions,
): options is OpenAIClientOptions {
  return options.type === 'openai' && 'apiKey' in options;
}

export interface AITextCompletionOptions {
  model?: string;
  timeout?: number;
  role?: OpenAI.Chat.ChatCompletionRole;
  history?: OpenAI.Chat.ChatCompletionMessageParam[];
  name?: string;
  frequencyPenalty?: number;
  logitBias?: Record<string, number>;
  logprobs?: boolean;
  topLogprobs?: number;
  maxTokens?: number;
  n?: number;
  presencePenalty?: number;
  responseFormat?: { type: 'text' | 'json_object' };
  seed?: number;
  stop?: string | Array<string>;
  stream?: boolean;
  temperature?: number;
  topProbability?: number;
  tools?: Array<any>; // todo: figure out generic solution - Array<OpenAI.Chat.ChatCompletionTool>;
  toolChoice?:
    | 'none'
    | 'auto'
    | { type: 'function'; function: { name: string } };
  user?: string;
  onProgress?: (partialMessage: string) => void;
}

export class AIClient {
  public options: AIClientOptions;

  constructor(options: AIClientOptions) {
    this.options = options;
  }

  public async message(
    text: string,
    options: AITextCompletionOptions = { role: 'user' },
  ) {
    return 'not a real ai message, this is the base class!';
  }

  public static async create<T extends AIClientOptions>(
    options: T,
  ): Promise<AIClient | OpenAIClient> {
    if (isOpenAIClientOptions(options)) {
      return OpenAIClient.create(options);
    }
    throw new Error('Invalid client type');
  }

  public textCompletion(
    text: string,
    options: AITextCompletionOptions = {
      role: 'user',
    },
  ) {
    return this.message(text, options);
  }
}

export async function getOpenAI(options: {
  apiKey?: string;
  baseUrl?: string;
}) {
  return new OpenAI({
    apiKey: options.apiKey,
    baseURL: options.baseUrl,
  });
}

export interface OpenAITextCompletionOptions {
  model?: string;
  timeout?: number;
  role?: OpenAI.Chat.ChatCompletionRole;
  history?: Array<OpenAI.Chat.ChatCompletionMessageParam>;
  name?: string;
  frequencyPenalty?: number;
  logitBias?: Record<string, number>;
  logprobs?: boolean;
  topLogprobs?: number;
  maxTokens?: number;
  n?: number;
  presencePenalty?: number;
  responseFormat?: { type: 'text' | 'json_object' };
  seed?: number;
  stop?: string | Array<string>;
  stream?: boolean;
  temperature?: number;
  topProbability?: number;
  tools?: Array<OpenAI.Chat.ChatCompletionTool>;
  toolChoice?:
    | 'none'
    | 'auto'
    | { type: 'function'; function: { name: string } };
  user?: string;
  onProgress?: (partialMessage: string) => void;
}

export interface OpenAIClientOptions extends AIClientOptions {
  apiKey?: string;
  baseUrl?: string;
}

export class OpenAIClient extends AIClient {
  protected openai!: OpenAI;
  public options: OpenAIClientOptions;

  constructor(options: OpenAIClientOptions) {
    super(options);
    this.options = options;
  }

  public async message(
    text: string,
    options: AIMessageOptions = { role: 'user' },
  ) {
    const response = await this.textCompletion(text, options);
    return response;
  }

  public static async create(
    options: OpenAIClientOptions,
  ): Promise<OpenAIClient> {
    const client = new OpenAIClient(options);
    await client.initialize();
    return client;
  }

  protected async initialize() {
    this.openai = new OpenAI({
      apiKey: this.options.apiKey,
      baseURL: this.options.baseUrl,
    });
  }

  /**
   * Sends a message using the OpenAI Chat API.
   *
   * @param {string} message - The message to send.
   * @param {object} options - Configuration options for the message.
   * @param {OpenAI} options.openai - The OpenAI instance to use.
   * @param {string} [options.model='gpt-4'] - ID of the model to use. See the model endpoint compatibility table for details on which models work with the Chat API.
   * @param {number} [options.timeout=10000] - Timeout for the API call in milliseconds.
   * @param {string} [options.role='user'] - The role of the sender in the conversation.
   * @param {Array<object>} [options.history=[]] - A list of previous messages in the conversation.
   * @param {string} options.name - The name of the sender.
   * @param {number} [options.frequencyPenalty=0] - Number between -2.0 and 2.0. Penalizes new tokens based on their existing frequency in the text.
   * @param {Record<string, number>} [options.logitBias] - Modifies the likelihood of specified tokens appearing in the completion.
   * @param {boolean} [options.logprobs=false] - Whether to return log probabilities of the output tokens.
   * @param {number} [options.topLogprobs] - Specifies the number of most likely tokens to return at each token position with log probabilities.
   * @param {number} [options.maxTokens] - The maximum number of tokens for chat completion.
   * @param {number} [options.n=1] - Number of chat completion choices to generate.
   * @param {number} [options.presencePenalty=0] - Number between -2.0 and 2.0. Penalizes new tokens based on their appearance in the text.
   * @param {object} [options.responseFormat] - Specifies the format of the model's output.
   * @param {number} [options.seed] - Seed for deterministic sampling.
   * @param {string|string[]} [options.stop] - Sequences where the API stops generating further tokens.
   * @param {boolean} [options.stream=false] - If true, sends partial message deltas.
   * @param {number} [options.temperature=1] - Sampling temperature, between 0 and 2.
   * @param {number} [options.topProbability=1] - Nucleus sampling parameter.
   * @param {Array<OpenAI.Chat.ChatCompletionTool>} [options.tools] - List of tools the model may call.
   * @param {string|object} [options.toolChoice] - Controls which function is called by the model.
   * @param {string} [options.user] - Unique identifier for the end-user.
   * @param {function} [options.onProgress] - Callback function to handle partial message updates.
   *
   * @returns {Promise<string>} The response from the OpenAI API.
   */

  public async textCompletion(
    message: string,
    options: OpenAITextCompletionOptions = {},
  ): Promise<string> {
    const {
      model = 'gpt-4o',
      role = 'user',
      history = [],
      name,
      frequencyPenalty: frequency_penalty = 0,
      logitBias: logit_bias,
      logprobs = false,
      topLogprobs: top_logprobs,
      maxTokens: max_tokens,
      n = 1,
      presencePenalty: presence_penalty = 0,
      responseFormat: response_format,
      seed,
      stop,
      stream = false,
      temperature = 1,
      topProbability: top_p = 1,
      tools,
      toolChoice: tool_choice,
      user,
      onProgress,
    } = options;

    const messages = [
      ...history,
      {
        role: role as OpenAI.Chat.ChatCompletionRole,
        content: message,
      } as OpenAI.Chat.ChatCompletionSystemMessageParam,
    ];

    if (onProgress) {
      const stream = await this.openai.chat.completions.create({
        model,
        messages,
        stream: true,
        frequency_penalty,
        logit_bias,
        logprobs,
        top_logprobs,
        max_tokens,
        n,
        presence_penalty,
        response_format,
        seed,
        stop,
        temperature,
        top_p,
        tools,
        tool_choice,
        user,
      });

      let fullContent = '';
      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content || '';
        fullContent += content;
        onProgress(content);
      }

      return fullContent;
    } else {
      const response = await this.openai.chat.completions.create({
        model,
        messages,
        frequency_penalty,
        logit_bias,
        logprobs,
        top_logprobs,
        max_tokens,
        n,
        presence_penalty,
        response_format,
        seed,
        stop,
        stream: false,
        temperature,
        top_p,
        tools,
        tool_choice,
        user,
      });

      const choice = response.choices[0];
      if (!choice || !choice.message || !choice.message.content) {
        throw new Error('Invalid response from OpenAI API: Missing content');
      }
      return choice.message.content;
    }
  }
}

type GetAIClientOptions = OpenAIClientOptions & { type?: 'openai' };

export async function getAIClient(
  options: GetAIClientOptions,
): Promise<AIClient> {
  if (options.type === 'openai') {
    return OpenAIClient.create(options);
  } else {
    throw new Error('Invalid client type');
  }
}
</file>

<file path="packages/ai/CLAUDE.md">
# @have/ai: AI Model Interface Package

## Purpose and Responsibilities

The `@have/ai` package provides a standardized interface for interacting with various AI models. It currently focuses on OpenAI's API but is designed with an abstraction layer to potentially support other AI providers in the future. This package:

- Offers a unified client interface for AI text completions
- Handles configuration for different AI providers
- Manages streaming responses and progress callbacks
- Provides type definitions for AI model parameters

## Key APIs

### Creating an AI Client

```typescript
import { getAIClient } from '@have/ai';

// Create an OpenAI client (default)
const client = await getAIClient({
  apiKey: 'your-api-key',
  baseUrl: 'https://api.openai.com/v1' // optional
});

// The client can then be used for text completions
```

### Text Completions

```typescript
import { getAIClient } from '@have/ai';

const client = await getAIClient({ apiKey: 'your-api-key' });

// Basic completion
const result = await client.textCompletion("What is the capital of France?");

// Completion with options
const resultWithOptions = await client.textCompletion("Generate a poem about coding", {
  model: "gpt-4o",
  temperature: 0.7,
  maxTokens: 500
});
```

### Streaming Responses

```typescript
import { getAIClient } from '@have/ai';

const client = await getAIClient({ apiKey: 'your-api-key' });

// Stream response with progress callback
const result = await client.textCompletion("Generate a long story", {
  stream: true,
  onProgress: (partialMessage) => {
    console.log("Received chunk:", partialMessage);
  }
});
```

### Configuration Options

The package supports various configuration options for AI completions:

```typescript
// Example with multiple options
const result = await client.textCompletion("Your prompt here", {
  model: "gpt-4o",            // AI model to use
  temperature: 0.7,           // Randomness (0-2)
  maxTokens: 500,             // Maximum response length
  stop: ["\n\n", "THE END"],  // Stop sequences
  role: "user",               // Message role
  history: [                  // Conversation history
    { role: "system", content: "You are a helpful assistant." },
    { role: "user", content: "Who are you?" },
    { role: "assistant", content: "I'm an AI assistant." }
  ]
});
```

## Internal Architecture

The package uses a factory pattern with an abstract base class:

- `AIClient`: Abstract base class defining the common interface
- `OpenAIClient`: Implementation for OpenAI's API
- `getAIClient()`: Factory function that returns the appropriate client

The design allows for future expansion to other AI providers by creating new client implementations that extend the base class.

## Dependencies

- `openai`: The official OpenAI JavaScript/TypeScript client

## Development Guidelines

### Adding New AI Providers

To add support for a new AI provider:

1. Create a new client class that extends `AIClient`
2. Implement the required methods (especially `textCompletion`)
3. Update the type guard and factory function in `getAIClient()`
4. Add appropriate type definitions for the new provider's options

### Testing

The package includes tests for verifying client behavior:

```bash
pnpm test        # Run tests once
pnpm test:watch  # Run tests in watch mode
```

Mock the actual API calls in tests to avoid external dependencies.

### Building

Build the package with:

```bash
pnpm build       # Build once
pnpm build:watch # Build in watch mode
```

### Best Practices

- Keep API credentials secure (never hard-code them)
- Handle streaming responses efficiently
- Use appropriate error handling for API calls
- Set reasonable timeouts for AI model requests
- Consider rate limits of AI providers in implementation

This package serves as an abstraction layer over AI services, allowing the rest of the SDK to use AI capabilities without being tightly coupled to specific providers.
</file>

<file path="packages/files/src/filesystem.ts">
import path from 'path';
import os from 'os';
import { mkdir } from 'fs/promises';
import { getCached, setCached } from './index.js';

export interface FilesystemAdapterInterface {
  exists(path: string): Promise<boolean>;
  read(path: string): Promise<string>;
  write(path: string, content: string): Promise<void>;
  delete(path: string): Promise<void>;
  list(path: string): Promise<string[]>;
  mimeType(path: string): Promise<string>;
}

export interface FilesystemAdapterOptions {
  type?: string;
  cacheDir?: string;
}

export class FilesystemAdapter {
  protected options: FilesystemAdapterOptions;
  protected cacheDir: string;

  constructor(options: FilesystemAdapterOptions) {
    this.options = options;
    this.cacheDir =
      options.cacheDir || path.join(os.tmpdir(), 'have-sdk', '.cache');
  }

  static async create<T extends FilesystemAdapterOptions>(
    options: T,
  ): Promise<FilesystemAdapter> {
    const fs = new FilesystemAdapter(options);
    await fs.initialize();
    return fs;
  }

  protected async initialize() {
    await mkdir(this.cacheDir, { recursive: true });
  }

  async download(
    url: string,
    options: {
      force: boolean;
    } = {
      force: false,
    },
  ): Promise<string> {
    return '';
  }

  async exists(path: string): Promise<boolean> {
    // Dummy implementation
    return false;
  }

  async read(path: string): Promise<string> {
    // Dummy implementation
    return '';
  }

  async write(path: string, content: string): Promise<void> {
    // Dummy implementation
  }

  async delete(path: string): Promise<void> {
    // Dummy implementation
  }

  async list(path: string): Promise<string[]> {
    // Dummy implementation
    return [];
  }

  async getCached(file: string, expiry: number = 300000) {
    return getCached(file, expiry);
  }

  async setCached(file: string, data: string) {
    return setCached(file, data);
  }
}
</file>

<file path="packages/files/src/index.ts">
import { statSync, createWriteStream, Dirent, existsSync } from 'node:fs';
import {
  copyFile,
  mkdir,
  readdir,
  writeFile,
  readFile,
} from 'node:fs/promises';
import { tmpdir } from 'node:os';
import * as path from 'node:path';
import { dirname } from 'node:path';
import { URL } from 'node:url';

const TMP_DIR = path.resolve(`${tmpdir()}/kissd`);

export const isFile = (file: string): false | ReturnType<typeof statSync> => {
  try {
    const fileStat = statSync(file);
    return fileStat.isDirectory() ? false : fileStat;
  } catch {
    return false;
  }
};

export const isDirectory = (dir: string): boolean => {
  try {
    const dirStat = statSync(dir);
    if (dirStat.isDirectory()) return true;
    throw new Error(`${dir} exists but isn't a directory`);
  } catch (error) {
    if (error instanceof Error && error.message.includes('ENOENT')) {
      return false;
    }
    throw error;
  }
};

export const ensureDirectoryExists = async (dir: string): Promise<void> => {
  if (!isDirectory(dir)) {
    await mkdir(dir, { recursive: true });
  }
};

export const upload = async (
  url: string,
  data: string | Buffer,
): Promise<Response> => {
  try {
    const response = await fetch(url, {
      method: 'PUT',
      body: data,
      headers: { 'Content-Type': 'application/octet-stream' },
    });

    if (!response.ok) {
      throw new Error(`unexpected response ${response.statusText}`);
    }
    return response;
  } catch (error) {
    const err = error as Error;
    console.error(`Error uploading data to ${url}\nError: ${err.message}`);
    throw error; // Re-throw to allow proper error handling
  }
};

export async function download(url: string, filepath: string): Promise<void> {
  try {
    const response = await fetch(url);
    if (!response.ok) {
      throw new Error(`Unexpected response ${response.statusText}`);
    }

    const fileStream = createWriteStream(filepath);
    await response.body?.pipeTo(
      new WritableStream({
        write(chunk) {
          fileStream.write(Buffer.from(chunk));
        },
        close() {
          fileStream.end();
        },
      }),
    );
  } catch (error) {
    const err = error as Error;
    console.error('Error downloading file:', err);
    throw error;
  }
}

// return location of downloaded file
export const downloadFileWithCache = async (
  url: string,
  targetPath: string | null = null,
): Promise<string> => {
  const parsedUrl = new URL(url);
  const downloadPath =
    targetPath ||
    `${TMP_DIR}/downloads/${parsedUrl.hostname}${parsedUrl.pathname}`;

  if (!isFile(downloadPath)) {
    await ensureDirectoryExists(dirname(downloadPath));
    await download(url, downloadPath);
  }
  return downloadPath;
};

interface ListFilesOptions {
  match?: RegExp;
}

export const listFiles = async (
  dirPath: string,
  options: ListFilesOptions = { match: /.*/ },
): Promise<string[]> => {
  const entries: Dirent[] = await readdir(dirPath, { withFileTypes: true });
  const files = entries
    .filter((entry: Dirent) => entry.isFile())
    .map((entry: Dirent) => entry.name);

  return options.match
    ? files.filter((item) => options.match?.test(item))
    : files;
};

export async function getCached(file: string, expiry: number = 300000) {
  const cacheFile = path.resolve(TMP_DIR, file);
  const cached = existsSync(cacheFile);
  if (cached) {
    const stats = statSync(cacheFile);
    const modTime = new Date(stats.mtime);
    const now = new Date();
    const isExpired = expiry && now.getTime() - modTime.getTime() > expiry;
    if (!isExpired) {
      return await readFile(cacheFile, 'utf8');
    }
  }
}

export async function setCached(file: string, data: string) {
  const cacheFile = path.resolve(TMP_DIR, file);
  await ensureDirectoryExists(path.dirname(cacheFile));
  await writeFile(cacheFile, data);
}

const mimeTypes: { [key: string]: string } = {
  '.html': 'text/html',
  '.js': 'application/javascript',
  '.json': 'application/json',
  '.css': 'text/css',
  '.png': 'image/png',
  '.jpg': 'image/jpeg',
  '.jpeg': 'image/jpeg',
  '.gif': 'image/gif',
  '.txt': 'text/plain',
  '.doc': 'application/msword',
  '.docx':
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
  '.xls': 'application/vnd.ms-excel',
  '.xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
  '.pdf': 'application/pdf',
  '.xml': 'application/xml',
  '.zip': 'application/zip',
  '.rar': 'application/x-rar-compressed',
  '.mp3': 'audio/mpeg',
  '.mp4': 'video/mp4',
  '.avi': 'video/x-msvideo',
  '.mov': 'video/quicktime',
  // Add more mappings as needed
};

export function getMimeType(fileOrUrl: string): string {
  const urlPattern = /^[a-zA-Z][a-zA-Z\d+\-.]*:\/\//; // Matches any valid URL scheme
  let extension: string;

  if (urlPattern.test(fileOrUrl)) {
    // It's a URL, extract the pathname
    const url = new URL(fileOrUrl);
    extension = path.extname(url.pathname);
  } else {
    // It's a file path
    extension = path.extname(fileOrUrl);
  }

  return mimeTypes[extension.toLowerCase()] || 'application/octet-stream';
}

export * from './fetch.js';
export * from './filesystem.js';
</file>

<file path="packages/files/CLAUDE.md">
# @have/files: File System Interface Package

## Purpose and Responsibilities

The `@have/files` package provides a standardized interface for file system operations, supporting both local and potentially remote file systems. Its core responsibilities include:

- Reading and writing files with consistent APIs
- Managing directory creation and navigation
- Handling file paths across different platforms
- Supporting temporary file operations
- Providing utilities for common file operations

This package abstracts away the complexities of different file systems, allowing other packages to work with files in a consistent way regardless of the underlying storage.

## Key APIs

### Basic File Operations

```typescript
import { readFile, writeFile, fileExists } from '@have/files';

// Read a file
const content = await readFile('/path/to/file.txt');

// Write a file (creates directories if needed)
await writeFile('/path/to/new/file.txt', 'File content');

// Check if a file exists
const exists = await fileExists('/path/to/file.txt');
```

### Directory Operations

```typescript
import { 
  createDirectory, 
  ensureDirectory, 
  listDirectory 
} from '@have/files';

// Create a directory
await createDirectory('/path/to/new/dir');

// Ensure a directory exists (creates if it doesn't)
await ensureDirectory('/path/to/another/dir');

// List directory contents
const files = await listDirectory('/path/to/dir');
```

### Temporary Files

```typescript
import { 
  getTempDirectory, 
  createTempFile, 
  createTempDirectory 
} from '@have/files';

// Get path to a temporary directory
const tempDir = getTempDirectory('my-app');

// Create a temporary file
const { path, cleanup } = await createTempFile({ 
  prefix: 'data-', 
  extension: '.json',
  content: '{"key": "value"}'
});
// Use the file...
// Then clean it up
await cleanup();

// Create a temporary directory
const { path, cleanup } = await createTempDirectory('temp-data');
// Use the directory...
// Then clean it up
await cleanup();
```

### Path Utilities

```typescript
import { 
  resolvePath, 
  getExtension, 
  getFilename, 
  getDirectory 
} from '@have/files';

// Resolve a path (handles relative paths)
const absolutePath = resolvePath('~/documents/file.txt');

// Get file extension
const ext = getExtension('/path/to/document.pdf'); // => 'pdf'

// Get filename
const filename = getFilename('/path/to/document.pdf'); // => 'document.pdf'

// Get directory path
const dir = getDirectory('/path/to/document.pdf'); // => '/path/to'
```

### Content Handling

```typescript
import { 
  readJson, 
  writeJson, 
  readLines,
  appendFile
} from '@have/files';

// Read JSON file
const data = await readJson('/path/to/config.json');

// Write JSON file
await writeJson('/path/to/data.json', { key: 'value' });

// Read file line by line
const lines = await readLines('/path/to/log.txt');

// Append to file
await appendFile('/path/to/log.txt', 'New log entry\n');
```

## Dependencies

The package has minimal dependencies:

- `@have/utils`: For utility functions like path handling and temporary directory management

No external file system libraries are used, leveraging Node.js's built-in `fs/promises` module for most operations.

## Development Guidelines

### Error Handling

File operations can fail for various reasons (permissions, disk space, etc.). Handle these cases appropriately:

```typescript
try {
  await writeFile('/path/to/file.txt', 'content');
} catch (error) {
  if (error.code === 'ENOENT') {
    // Handle "no such file or directory" error
  } else if (error.code === 'EACCES') {
    // Handle permission error
  } else {
    // Handle other errors
  }
}
```

### Path Normalization

Always normalize paths to ensure consistency across different platforms:

```typescript
// Using built-in functions
const normalizedPath = resolvePath('~/documents/file.txt');
```

### Testing

The package includes tests for verifying file operations:

```bash
pnpm test        # Run tests once
pnpm test:watch  # Run tests in watch mode
```

Tests use temporary directories to avoid affecting the real file system.

### Building

Build the package with:

```bash
pnpm build       # Build once
pnpm build:watch # Build in watch mode
```

### Best Practices

- Always clean up temporary files and directories
- Use async/await with file operations to avoid blocking the event loop
- Prefer streaming for large files to manage memory usage
- Handle path separators carefully for cross-platform compatibility
- Use appropriate file permissions when creating files
- Consider file locking for operations that need exclusive access

This package provides the foundation for file operations across the HAVE SDK, ensuring consistent behavior regardless of the environment.
</file>

<file path="packages/pdf/src/index.spec.ts">
import { it, expect } from 'vitest';
import { join } from 'node:path';
import { fileURLToPath } from 'node:url';
import { extractTextFromPDF } from './index.js';
// skipping because it takes too long and doesnt provide much value
it('should extract text from an image pdf', async () => {
  // const pdfPath = path.join(
  //   __dirname,
  //   '..',
  //   '/Signed-Meeting-Minutes-October-8-2024-Regular-Council-Meeting-1.pdf',
  // );

  // const text = await scribe.extractText([pdfPath]);
  // console.log(text);
  const pdfPath = join(
    fileURLToPath(new URL('.', import.meta.url)),
    '..',
    'test',
    'Signed-Meeting-Minutes-October-8-2024-Regular-Council-Meeting-1.pdf',
  );
  const text = await extractTextFromPDF(pdfPath);
  expect(text).toBeDefined();
  // console.log(text);
}, 30000);

it('should extract text from a problematic pdf', async () => {
  const pdfPath = join(
    fileURLToPath(new URL('.', import.meta.url)),
    '..',
    'test',
    'Agenda-Package-October-24-2023-Regular-Council-Meeting.pdf',
  );
  const text = await extractTextFromPDF(pdfPath);
  expect(text).toBeDefined();
}, 30000);
</file>

<file path="packages/pdf/CLAUDE.md">
# @have/pdf: PDF Processing Package

## Purpose and Responsibilities

The `@have/pdf` package provides tools for working with PDF documents, focusing on:

- Extracting text and content from PDF files
- Converting PDFs to other formats (text, JSON)
- OCR capabilities for image-based PDFs
- Analyzing PDF structure and metadata
- Processing PDF documents for AI consumption

This package is particularly useful for AI agents that need to analyze document content, extract information from PDFs, or process document collections.

## Key APIs

### Basic PDF Text Extraction

```typescript
import { extractText } from '@have/pdf';

// Extract text from a PDF file
const text = await extractText('/path/to/document.pdf');

// Extract text with options
const textWithOptions = await extractText('/path/to/document.pdf', {
  pages: [1, 2, 3],        // Specific pages to extract
  includeMetadata: true,   // Include document metadata
  preserveFormatting: true // Attempt to preserve original formatting
});
```

### PDF Content Analysis

```typescript
import { analyzePdf } from '@have/pdf';

// Get detailed analysis of PDF content
const analysis = await analyzePdf('/path/to/document.pdf');

console.log(analysis.metadata);    // Document metadata
console.log(analysis.pageCount);   // Number of pages
console.log(analysis.structure);   // Document structure
console.log(analysis.textContent); // Extracted text
console.log(analysis.images);      // Information about embedded images
```

### OCR for Image-Based PDFs

```typescript
import { performOcr } from '@have/pdf';

// Extract text from image-based PDF using OCR
const result = await performOcr('/path/to/scanned-document.pdf', {
  language: 'eng',           // OCR language
  improveResolution: true,   // Enhance image before OCR
  outputFormat: 'text'       // Output format (text, json, hocr)
});

console.log(result.text);         // Extracted text
console.log(result.confidence);   // OCR confidence score
```

### PDF to JSON Conversion

```typescript
import { pdfToJson } from '@have/pdf';

// Convert PDF to structured JSON
const json = await pdfToJson('/path/to/document.pdf');

// The result includes structured content with layout information
console.log(json.pages);           // Array of page objects
console.log(json.pages[0].texts);  // Text elements on first page
console.log(json.pages[0].tables); // Detected tables on first page
```

### PDF Metadata Extraction

```typescript
import { extractMetadata } from '@have/pdf';

// Extract only metadata from a PDF
const metadata = await extractMetadata('/path/to/document.pdf');

console.log(metadata.title);       // Document title
console.log(metadata.author);      // Author
console.log(metadata.creationDate); // Creation date
console.log(metadata.keywords);    // Keywords
```

## Dependencies

The package has the following dependencies:

- `pdfjs-dist`: Mozilla's PDF.js for PDF parsing and rendering
- `tesseract.js`: For OCR capabilities
- `scribe.js-ocr`: Enhanced OCR processing
- `date-fns`: For date manipulation
- `pluralize`: For text processing utilities

## Development Guidelines

### PDF Processing Considerations

- PDFs can be large and complex; implement streaming where possible
- Handle different PDF versions and features gracefully
- Consider memory usage when processing large documents
- Implement timeout mechanisms for long-running operations

### OCR Strategy

- Use OCR only when necessary (image-based PDFs)
- Implement pre-processing to improve OCR results
- Consider language-specific OCR models for better accuracy
- Cache OCR results to avoid repeated processing

### Error Handling

- Handle malformed or password-protected PDFs
- Provide meaningful error messages for different failure modes
- Implement fallback strategies when primary extraction fails
- Validate PDF files before processing

### Testing

The package includes tests for verifying PDF processing:

```bash
pnpm test        # Run tests once
pnpm test:watch  # Run tests in watch mode
```

Tests use sample PDFs of different types and complexity.

### Building

Build the package with:

```bash
pnpm build       # Build once
pnpm build:watch # Build in watch mode
```

### Best Practices

- Log processing steps for debugging complex PDF issues
- Implement retry mechanisms for unreliable operations
- Use appropriate timeout values for processing operations
- Consider progressive enhancement (basic text extraction first, OCR as fallback)
- Normalize extracted text for consistent downstream processing
- Preserve document structure when possible for better analysis

This package provides specialized tools for working with PDF documents, making them accessible to AI agents and other components of the HAVE SDK.
</file>

<file path="packages/smrt/src/content.ts">
import type { BaseObjectOptions } from './object.js';
import { BaseObject } from './object.js';

export interface ContentOptions extends BaseObjectOptions {
  type?: string | null;
  fileKey?: string | null;
  author?: string | null;
  title?: string | null;
  description?: string | null;
  body?: string | null;
  publish_date?: Date | null;
  url?: string | null;
  source?: string | null;
  status?: 'published' | 'draft' | 'archived' | 'deleted' | null;
  state?: 'deprecated' | 'active' | 'highlighted' | null;
}

export class Content extends BaseObject<ContentOptions> {
  protected options: ContentOptions;
  protected references: Content[] = [];
  public type?: string | null;
  public fileKey: string | null | undefined;
  public author!: string | null | undefined;
  public title!: string | null | undefined;
  public description!: string | null | undefined;
  public body!: string | null | undefined;
  public publish_date!: Date | null | undefined;
  public url!: string | null | undefined;
  public source!: string | null | undefined;
  public status!: 'published' | 'draft' | 'archived' | 'deleted' | null;
  public state!: 'deprecated' | 'active' | 'highlighted' | null; // contested?
  constructor(options: ContentOptions) {
    super(options);
    this.options = options;
    this.type = options.type || null;
    this.name = options.title || '';
    this.author = options.author || null;
    this.title = options.title || '';
    this.description = options.description || null;
    this.body = options.body || '';
    this.publish_date = options.publish_date || null;
    this.fileKey = options.fileKey || null;
    this.url = options.url || null;
    this.source = options.source || null;
    this.status = options.status || 'draft';
    this.state = options.state || 'active';
  }

  static async create(options: ContentOptions) {
    if (!options.db) {
      options.db = {
        url: process.env.CONTENT_DB_URL || process.env.KISSD_DB_URL,
      };
    }
    const content = new Content(options);
    await content.initialize();
    return content;
  }

  async initialize() {
    await super.initialize();
  }

  public async loadReferences() {}

  public async addReference(content: Content | string) {
    if (typeof content === 'string') {
      content = await Content.create({
        db: this.options.db,
        ai: this.options.ai,
        url: content,
      });
    }
    this.references.push(content);
  }

  public async getReferences() {
    return this.references;
  }

  public toJSON() {
    return {
      id: this.id || '',
      slug: this.slug || '',
      context: this.context || '',
      type: this.type,
      fileKey: this.fileKey || '',
      author: this.author || '',
      title: this.title || '',
      description: this.description || '',
      body: this.body || '',
      publish_date: this.publish_date || '',
      url: this.url || '',
      source: this.source || '',
      status: this.status || 'draft',
      state: this.state || 'active',
    };
  }
}
</file>

<file path="packages/smrt/src/document.ts">
import os from 'os';
import path from 'path';
import { URL } from 'url';
import { FilesystemAdapter } from '@have/files';
import { downloadFileWithCache } from '@have/files';
import { extractTextFromPDF } from '@have/pdf';
import { getCached, setCached, getMimeType } from '@have/files';
import { makeSlug } from '@have/utils';
export interface DocumentOptions {
  fs?: FilesystemAdapter;
  cacheDir?: string;
  url: string;
  localPath?: string;
  type?: string | undefined | null;
}

export class Document {
  protected isRemote: boolean;
  protected options: DocumentOptions;
  protected localPath: string;
  protected cacheDir: string;
  public url: URL;
  public type: string | undefined | null;
  constructor(options: DocumentOptions) {
    this.options = options;
    this.url = new URL(options.url);

    this.type = options.type || getMimeType(this.url.toString());
    this.cacheDir =
      options.cacheDir || path.resolve(os.tmpdir(), '.cache', 'have-sdk');

    if (this.url.protocol.startsWith('file')) {
      this.localPath = this.url.pathname;
      this.isRemote = false;
    } else {
      this.localPath = path.join(
        this.cacheDir,
        makeSlug(this.url.hostname),
        this.url.pathname,
      );
      this.isRemote = true;
    }
  }

  static async create(options: DocumentOptions) {
    const document = new Document(options);
    await document.initialize();
    return document;
  }

  async initialize() {
    if (this.isRemote) {
      //todo: should be getCached?
      await downloadFileWithCache(this.url.toString(), this.localPath);
    }
  }

  async getText() {
    const cached = await getCached(this.localPath + '.extracted_text');
    if (cached) {
      return cached;
    }

    let extracted: string | null = '';
    switch (this.type) {
      case 'application/pdf':
        extracted = await extractTextFromPDF(this.localPath);
        break;
      case 'text':
      case 'json':
      default:
        throw new Error(
          'Getting text from ${this.type} types not yet implemented. I should check to see if its a text file here',
        );
    }
    if (extracted) {
      await setCached(this.localPath + '.extracted_text', extracted);
    }
    return extracted;
  }
}

export default {
  File,
};
</file>

<file path="packages/smrt/CLAUDE.md">
# @have/smrt: AI Agent Framework Package

## Purpose and Responsibilities

The `@have/smrt` package is the core framework for building vertical AI agents in the HAVE SDK. It integrates functionality from all other packages to provide:

- A coherent object model for AI agents with database persistence
- Collection-based management of objects
- Automatic schema generation and database table creation
- Standardized interfaces for AI interactions
- Utilities for working with different data sources

Despite its tongue-in-cheek name, this package is the central nervous system of the SDK, connecting database capabilities, file system operations, and AI model interactions.

## Key Concepts

### BaseClass

The foundation for all classes in the framework, providing:
- Initialization logic
- Access to AI client and database interfaces
- Shared utilities

### BaseObject

Extends BaseClass to represent individual entities that:
- Can be saved to a database
- Have unique identifiers (id, slug, etc.)
- Support property-based schema generation
- Include timestamps (created_at, updated_at)

### BaseCollection

Extends BaseClass to represent collections of objects that:
- Automatically set up database tables based on object schemas
- Provide CRUD operations for managing objects
- Support flexible querying with multiple operators
- Handle relationships between objects

## Key APIs

### Defining a Custom Object

```typescript
import { BaseObject } from '@have/smrt';

class Document extends BaseObject<any> {
  title: string = '';
  content: string = '';
  category: string = '';
  tags: string[] = [];
  isPriority: boolean = false;
  
  constructor(options: any) {
    super(options);
    // Copy properties from options to this instance
    Object.assign(this, options);
  }
  
  async summarize() {
    // Use AI to summarize the document
    if (this.options.ai && this.content) {
      return this.options.ai.textCompletion(
        `Summarize this document: ${this.content.substring(0, 2000)}`
      );
    }
    return null;
  }
}
```

### Defining a Collection

```typescript
import { BaseCollection } from '@have/smrt';
import { Document } from './document';

class DocumentCollection extends BaseCollection<Document> {
  static readonly _itemClass = Document;
  
  constructor(options: any) {
    super(options);
  }
  
  async findSimilar(documentId: string) {
    const document = await this.get(documentId);
    if (!document) return [];
    
    // Custom logic to find similar documents
    return this.list({
      where: { category: document.category },
      limit: 5
    });
  }
}
```

### Using Objects and Collections

```typescript
import { getAIClient } from '@have/ai';
import { getSqliteClient } from '@have/sql';
import { DocumentCollection } from './documentCollection';

async function main() {
  // Set up dependencies
  const ai = await getAIClient({ apiKey: 'your-api-key' });
  const db = await getSqliteClient({ filename: 'documents.db' });
  
  // Create and initialize collection
  const documents = new DocumentCollection({ ai, db });
  await documents.initialize();
  
  // Create and save an object
  const doc = await documents.create({
    title: 'Getting Started',
    content: 'This is a guide to getting started with the HAVE SDK...',
    category: 'Documentation'
  });
  await doc.save();
  
  // Query objects
  const docs = await documents.list({
    where: { category: 'Documentation' },
    limit: 10,
    orderBy: 'created_at DESC'
  });
  
  // Use AI capabilities
  const summary = await doc.summarize();
}
```

### Advanced Querying

```typescript
// Complex query example
const results = await collection.list({
  where: {
    'created_at >': '2023-01-01',
    'priority': 'high',
    'status in': ['pending', 'in-progress'],
    'title like': '%important%'
  },
  orderBy: ['priority DESC', 'created_at DESC'],
  limit: 20,
  offset: 0
});

// Count matching records
const count = await collection.count({
  where: { category: 'reports' }
});
```

## Internal Architecture

The package uses:
- Schema generation based on class properties
- SQLite triggers for automatic timestamp management
- A consistent pattern for database operations
- Integration with AI models via the `@have/ai` package

## Dependencies on Other Packages

`@have/smrt` depends on all other packages in the SDK:

- `@have/ai`: For AI model interactions
- `@have/files`: For file system operations
- `@have/pdf`: For PDF document processing
- `@have/sql`: For database operations
- `@have/spider`: For web content retrieval
- `@have/utils`: For utility functions

## Development Guidelines

### Extending the Framework

To extend the framework:

1. Create custom objects by extending `BaseObject`
2. Create custom collections by extending `BaseCollection`
3. Define properties on objects that will be persisted to the database
4. Implement custom methods that leverage AI capabilities when needed

### Database Schema Considerations

- Object properties define the database schema
- Initialize properties with default values in the constructor
- Use appropriate JavaScript types for proper schema generation
- Properties are converted to snake_case for database columns

### Testing

```bash
pnpm test        # Run tests once
pnpm test:watch  # Run tests in watch mode
```

### Building

```bash
pnpm build       # Build once
pnpm build:watch # Build in watch mode
```

### Best Practices

- Clearly define object schemas with appropriate defaults
- Use transactions for complex database operations
- Keep AI prompts clear and focused
- Handle failures gracefully, especially for AI and database operations
- Follow the collection pattern for managing groups of related objects
- Initialize properties in constructors to ensure proper schema generation

The `@have/smrt` package exemplifies the "fast and loose" approach mentioned in the README, prioritizing developer velocity while maintaining enough structure for consistent and reliable behavior.
</file>

<file path="packages/spider/CLAUDE.md">
# @have/spider: Web Crawling and Content Extraction Package

## Purpose and Responsibilities

The `@have/spider` package (formerly known as "web") provides tools for crawling websites, extracting content, and processing web data. It is designed to:

- Navigate and interact with web pages programmatically
- Extract structured content from HTML pages
- Convert web content into clean, readable formats
- Handle different content types and structures
- Support both simple requests and browser-based interactions

This package is particularly useful for AI agents that need to process web content for analysis, search, or knowledge extraction.

## Key APIs

### Basic Web Scraping

```typescript
import { scrapeUrl } from '@have/spider';

// Extract content from a URL
const content = await scrapeUrl('https://example.com/article');

// The result includes extracted text, metadata, and other useful information
console.log(content.title);       // Page title
console.log(content.text);        // Main content text
console.log(content.description); // Meta description
console.log(content.links);       // Array of links found on the page
```

### Browser-Based Crawling

```typescript
import { Browser } from '@have/spider';

// Initialize a browser instance
const browser = await Browser.create();

// Navigate to a page
const page = await browser.newPage('https://example.com');

// Wait for specific content to load
await page.waitForSelector('.content-loaded');

// Extract content after JavaScript execution
const content = await page.extractContent();

// Take a screenshot
await page.screenshot({ path: '/path/to/screenshot.png' });

// Close the browser when done
await browser.close();
```

### HTML Parsing with Cheerio

```typescript
import { parseHtml } from '@have/spider';

// Parse HTML content
const $ = parseHtml('<html><body><div class="content">Hello</div></body></html>');

// Extract data using Cheerio selectors
const text = $('.content').text();
const links = $('a').map((i, el) => $(el).attr('href')).get();
```

### Readability Processing

```typescript
import { makeReadable } from '@have/spider';

// Convert HTML to a clean, readable format
const article = await makeReadable('<html>complex page html...</html>');

// Access the cleaned content
console.log(article.title);   // Extracted title
console.log(article.content); // Clean HTML content
console.log(article.textContent); // Plain text content
```

### Recursive Crawling

```typescript
import { crawlSite } from '@have/spider';

// Crawl a site with options
const results = await crawlSite('https://example.com', {
  maxDepth: 2,
  maxPages: 50,
  include: [/\/blog\//],
  exclude: [/\/author\//],
  delay: 1000
});

// Process the results
for (const page of results) {
  console.log(page.url, page.title, page.text);
}
```

## Dependencies

The package has the following dependencies:

- `@have/files`: For file system operations (saving content, screenshots)
- `@have/utils`: For utility functions
- `@mozilla/readability`: For extracting readable content from web pages
- `playwright`: For browser automation and JavaScript-rendered content
- `cheerio`: For HTML parsing and manipulation

## Development Guidelines

### Web Scraping Ethics and Performance

- Respect `robots.txt` directives
- Implement rate limiting to avoid overwhelming servers
- Use conditional requests with appropriate headers (If-Modified-Since)
- Cache results when appropriate
- Add proper user agent identification

### Browser Management

- Reuse browser instances when possible
- Close browser instances when done to prevent resource leaks
- Use headless mode for production environments
- Handle network errors and timeouts gracefully

### Content Extraction

- Normalize extracted content (whitespace, encoding)
- Preserve important metadata (title, author, date)
- Remove boilerplate elements (ads, navigation)
- Convert relative URLs to absolute URLs
- Handle different content types appropriately

### Testing

The package includes tests for verifying scraping behavior:

```bash
pnpm test        # Run tests once
pnpm test:watch  # Run tests in watch mode
```

Use mock servers or recorded responses for testing to avoid external dependencies.

### Building

Build the package with:

```bash
pnpm build       # Build once
pnpm build:watch # Build in watch mode
```

### Best Practices

- Implement proper error handling for network issues
- Use selectors that are resistant to minor HTML changes
- Cache responses to reduce load on target servers
- Set appropriate timeouts for page loading
- Clean up resources (especially browser instances) after use

This package provides the web interaction capabilities needed by AI agents to process online content effectively and responsibly.
</file>

<file path="packages/sql/src/index.spec.ts">
import { it, describe, expect } from "vitest";
import { getDatabase } from "./index.js";
import path from "path";
import { tmpdir } from "os";
import { syncSchema } from "./index.js";
import { buildWhere } from "./index.js";
const TMP_DIR = path.resolve(`${tmpdir()}/kissd`);

it.skip("should be able to get the adapter for a postgres database", async () => {
  const db = await getDatabase({
    type: "postgres",
    database: process.env.SQLOO_NAME || "sqloo",
    host: process.env.SQLOO_HOST || "localhost",
    user: process.env.SQLOO_USER || "sqloo",
    password: process.env.SQLOO_PASS || "sqloo",
    port: Number(process.env.SQLOO_PORT) || 5432,
  });
  expect(db.client).toBeDefined();
});

it("should be able to get the adapter for a sqlite database", async () => {
  const db = await getDatabase({
    type: "sqlite",
  });
  expect(db.client).toBeDefined();
});

it("should be able to get the adapter for an in memory sqlite database", async () => {
  const db = await getDatabase({
    type: "sqlite",
    url: ":memory:",
  });
  expect(db.client).toBeDefined();
});

it("should be able to sync a table schema", async () => {
  const db = await getDatabase({
    type: "sqlite",
    url: ":memory:",
  });
  // console.log({ db });
  await syncSchema({
    db,
    schema: `
        CREATE TABLE test (
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          name TEXT
        )
      `,
  });
});

it("should handle basic usage with different operators", () => {
  const result = buildWhere({
    status: "active",
    "price >": 100,
    "stock <=": 5,
    "category in": ["A", "B"],
    "name like": "%shirt%",
  });

  expect(result.sql).toBe(
    "WHERE status = $1 AND price > $2 AND stock <= $3 AND category IN $4 AND name LIKE $5",
  );
  expect(result.values).toEqual(["active", 100, 5, ["A", "B"], "%shirt%"]);
});

it("should handle NULL values correctly", () => {
  const result = buildWhere({
    deleted_at: null,
    "updated_at !=": null,
    status: "active",
  });

  expect(result.sql).toBe(
    "WHERE deleted_at IS NULL AND updated_at IS NOT NULL AND status = $1",
  );
  expect(result.values).toEqual(["active"]);
});

it("should handle price range conditions", () => {
  const result = buildWhere({
    "price >=": 10,
    "price <": 100,
  });

  expect(result.sql).toBe("WHERE price >= $1 AND price < $2");
  expect(result.values).toEqual([10, 100]);
});

it("should handle date filtering with null check", () => {
  const startDate = new Date("2024-01-01");
  const endDate = new Date("2024-12-31");

  const result = buildWhere({
    "created_at >": startDate,
    "created_at <=": endDate,
    deleted_at: null,
  });

  expect(result.sql).toBe(
    "WHERE created_at > $1 AND created_at <= $2 AND deleted_at IS NULL",
  );
  expect(result.values).toEqual([startDate, endDate]);
});

it("should handle LIKE operators for search", () => {
  const result = buildWhere({
    "title like": "%search%",
    "description like": "%search%",
    status: "published",
  });

  expect(result.sql).toBe(
    "WHERE title LIKE $1 AND description LIKE $2 AND status = $3",
  );
  expect(result.values).toEqual(["%search%", "%search%", "published"]);
});

it("should handle IN clauses with arrays", () => {
  const result = buildWhere({
    "role in": ["admin", "editor"],
    active: true,
    "last_login !=": null,
  });

  expect(result.sql).toBe(
    "WHERE role IN $1 AND active = $2 AND last_login IS NOT NULL",
  );
  expect(result.values).toEqual([["admin", "editor"], true]);
});
</file>

<file path="packages/sql/CLAUDE.md">
# @have/sql: Database Interface Package

## Purpose and Responsibilities

The `@have/sql` package provides a standardized interface for SQL database operations, with specific support for SQLite and PostgreSQL. It is designed to:

- Abstract away database-specific implementation details
- Provide a consistent API for common database operations
- Support schema synchronization for easy table creation and updates
- Handle query building and parameter binding securely
- Enable vector search capabilities with SQLite-VSS

Unlike full-featured ORMs, this package is intentionally lightweight, focusing on providing just enough abstraction while maintaining direct SQL access when needed.

## Key APIs

### Database Client Creation

```typescript
import { getSqliteClient, getPostgresClient } from '@have/sql';

// Create an SQLite client
const sqliteDb = await getSqliteClient({
  filename: 'database.db'  // Creates in-memory database if not specified
});

// Create a PostgreSQL client
const pgDb = await getPostgresClient({
  host: 'localhost',
  port: 5432,
  database: 'mydb',
  user: 'username',
  password: 'password'
});
```

### Basic Query Operations

```typescript
// Run a simple query
const { rows } = await db.query('SELECT * FROM users WHERE id = ?', ['user123']);

// Run a parameterized query with named parameters
const result = await db.query(
  'INSERT INTO users (id, name, email) VALUES (?, ?, ?)',
  ['user123', 'John Doe', 'john@example.com']
);

// Get a single value
const count = await db.pluck`SELECT COUNT(*) FROM users WHERE active = ${true}`;
```

### Schema Operations

```typescript
// Define a schema
const schema = {
  users: {
    id: { type: 'TEXT', primaryKey: true },
    name: { type: 'TEXT', notNull: true },
    email: { type: 'TEXT', unique: true },
    created_at: { type: 'TEXT' },
    updated_at: { type: 'TEXT' }
  }
};

// Synchronize schema (creates or updates tables as needed)
await syncSchema({ db, schema });
```

### Query Building

```typescript
// Build a WHERE clause from an object
const { sql, values } = buildWhere({
  status: 'active',
  'created_at >': '2023-01-01',
  'role in': ['admin', 'editor']
});

// Use in a query
const { rows } = await db.query(
  `SELECT * FROM users ${sql}`,
  values
);
```

### Transaction Support

```typescript
// Run operations in a transaction
await db.transaction(async (tx) => {
  await tx.query('INSERT INTO users (id, name) VALUES (?, ?)', ['user1', 'User One']);
  await tx.query('INSERT INTO profiles (user_id, bio) VALUES (?, ?)', ['user1', 'My bio']);
});
```

### Vector Search (with SQLite-VSS)

```typescript
// Create a vector search table
await db.query(`
  CREATE VIRTUAL TABLE IF NOT EXISTS embeddings USING vss0(
    id TEXT,
    embedding(1536) FLOAT,
    content TEXT
  );
`);

// Insert vector data
await db.query(`
  INSERT INTO embeddings (id, embedding, content) VALUES (?, ?, ?)
`, [
  'doc1', 
  new Float32Array([0.1, 0.2, /* ... */]).buffer, 
  'Document content'
]);

// Perform vector search
const { rows } = await db.query(`
  SELECT id, content, distance
  FROM embeddings
  WHERE vss_search(embedding, ?)
  LIMIT 10
`, [new Float32Array([0.2, 0.3, /* ... */]).buffer]);
```

## Dependencies

The package has the following dependencies:

- `@libsql/client`: For SQLite database operations
- `sqlite-vss`: For vector search capabilities in SQLite
- `pg`: For PostgreSQL database operations

## Development Guidelines

### Adding New Database Features

When adding new features:

1. Ensure consistent API across database engines
2. Implement for both SQLite and PostgreSQL where applicable
3. Add appropriate error handling and type checking
4. Write tests that work with both database engines

### Query Safety

- Always use parameterized queries to prevent SQL injection
- Validate table and column names when dynamically generating SQL
- Use the query building utilities for complex conditions
- Add type definitions for query results where possible

### Schema Management

- Keep schema definitions declarative and database-agnostic
- Use proper SQL types that work across database engines
- Include constraints (primary keys, foreign keys, etc.) in schema definitions
- Follow a consistent pattern for timestamps and metadata columns

### Testing

The package includes tests for verifying database operations:

```bash
pnpm test        # Run tests once
pnpm test:watch  # Run tests in watch mode
```

Tests use in-memory databases to avoid external dependencies.

### Building

Build the package with:

```bash
pnpm build       # Build once
pnpm build:watch # Build in watch mode
```

### Best Practices

- Use transactions for operations that need to be atomic
- Close database connections when they're no longer needed
- Consider performance implications of schema designs
- Use appropriate indexing for frequently queried columns
- Keep vector dimensions consistent when using vector search

This package provides a foundation for data persistence in the HAVE SDK, designed to be lightweight but powerful enough for AI-driven applications.
</file>

<file path="packages/utils/src/index.ts">
import { tmpdir } from 'os';
import path from 'path';
import { URL } from 'url';

import { v4 as uuidv4 } from 'uuid';
export const TMP_DIR = path.resolve(`${tmpdir()}/.have-sdk/tests`);

export const urlPath = (url: string) => {
  const parsedUrl = new URL(url);
  return path.join(parsedUrl.hostname, parsedUrl.pathname);
};

export const urlFilename = (url: string) => {
  const parsedUrl = new URL(url);
  const filename = path.basename(parsedUrl.pathname);
  return filename || 'index.html';
};

export const makeId = () => {
  return uuidv4();
};

export const makeSlug = (str: string) => {
  const from =
    'àáâäæãåāăąçćčđďèéêëēėęěğǵḧîïíīįìıİłḿñńǹňôöòóœøōõőṕŕřßśšşșťțûüùúūǘůűųẃẍÿýžźż+·/_,:;';
  const to =
    'aaaaaaaaaacccddeeeeeeeegghiiiiiiiilmnnnnoooooooooprrsssssttuuuuuuuuuwxyyzzz--------------';
  const textToCompare = new RegExp(
    from.split('').join('|').replace(/\+/g, '\\+'),
    'g',
  );

  return str
    .toString()
    .toLowerCase()
    .replace('&', '-38-')
    .replace(/\s+/g, '-') // Replace spaces with -
    .replace(textToCompare, (c) => to.charAt(from.indexOf(c))) // Replace special characters
    .replace(/[&.]/g, '-') // Replace DOT with -
    .replace(/[^\w-º+]+/g, '') // Remove all non-word characters, except for º, + and -
    .replace(/--+/g, '-') // Replace multiple - with single -
    .replace(/^-+/, '') // Trim - from start of text
    .replace(/-+$/, ''); // Trim - from end of text
};

export const timeNow = () => {
  const time = process.hrtime();
  return Math.round(time[0] * 1e3 + time[1] / 1e6);
};

// it function
export function waitFor(
  it: () => Promise<any>,
  { timeout = 0, delay = 1000 }: { timeout?: number; delay?: number },
) {
  return new Promise((resolve, reject) => {
    const beginTime = timeNow();
    (async function waitATick() {
      const result = await it();
      if (typeof result !== 'undefined') {
        return resolve(result);
      }
      if (timeout > 0) {
        if (timeNow() > beginTime + timeout) {
          return reject('Timed out');
        }
      }
      setTimeout(waitATick, delay);
    })();
  });
}

export const sleep = (duration: number) => {
  return new Promise<void>((resolve) => {
    console.log(`sleeping for ${duration}ms`);
    setTimeout(resolve, duration);
  });
};

export const isArray = (obj: unknown): obj is unknown[] => {
  return Array.isArray(obj);
};

export const keysToCamel = (obj: unknown): unknown => {
  if (isPlainObject(obj)) {
    const n: Record<string, unknown> = {};
    Object.keys(obj as Record<string, unknown>).forEach(
      (k) =>
        (n[camelCase(k)] = keysToCamel((obj as Record<string, unknown>)[k])),
    );
    return n;
  } else if (isArray(obj)) {
    return (obj as unknown[]).map((i) => keysToCamel(i));
  }
  return obj;
};

export const domainToCamel = (domain: string): string => camelCase(domain);

export const keysToSnake = (obj: unknown): unknown => {
  if (isPlainObject(obj)) {
    const n: Record<string, unknown> = {};
    Object.keys(obj as Record<string, unknown>).forEach(
      (k) =>
        (n[snakeCase(k)] = keysToSnake((obj as Record<string, unknown>)[k])),
    );
    return n;
  } else if (isArray(obj)) {
    return (obj as unknown[]).map((i) => keysToSnake(i));
  }
  return obj;
};

export const parseAmazonDateString = (dateStr: string): Date => {
  const regex =
    /^([0-9]{4})([0-9]{2})([0-9]{2})T([0-9]{2})([0-9]{2})([0-9]{2})([A-Z0-9]+)/;
  const match = dateStr.match(regex);
  if (!match) {
    throw new Error('Couldnt parse date');
  }
  const [matched, year, month, day, hour, minutes, seconds, timezone] = match;
  if (matched !== dateStr) {
    throw new Error('Couldnt parse date');
  }

  const date = new Date(
    `${year}-${month}-${day}T${hour}:${minutes}:${seconds}${timezone}`,
  );
  return date;
};

// to append the repeated messages to indicate things are still happening
export const logTicker = (
  tick: string | null,
  options: { chars?: string[] } = {},
) => {
  const { chars = ['.', '..', '...'] } = options;
  if (tick) {
    const index = chars.indexOf(tick);
    return index + 1 >= chars.length ? chars[0] : chars[index + 1];
  } else {
    return chars[0];
  }
};

// export function addInterval(dateStr: string, interval: string): string {
//   // For dates without time, assume start of day in UTC
//   let date = dateFns.parse(dateStr, 'yyyy-MM-dd', new Date());
//   if (!dateFns.isValid(date)) {
//     date = dateFns.parseISO(dateStr);
//     if (!dateFns.isValid(date)) {
//       throw new Error('Invalid date string provided');
//     }
//   }

//   // split interval into value and unit
//   let [value, unit] = interval.split(' ');

//   // use pluralize to convert the unit to singular form
//   unit = pluralize.singular(unit);

//   // create an object for the add function with proper typing
//   const addOptions: dateFns.Duration = {};
//   const unitValue = Number(value);

//   switch (unit) {
//     case 'year':
//       addOptions.years = unitValue;
//       break;
//     case 'month':
//       addOptions.months = unitValue;
//       break;
//     case 'week':
//       addOptions.weeks = unitValue;
//       break;
//     case 'day':
//       addOptions.days = unitValue;
//       break;
//     case 'hour':
//       addOptions.hours = unitValue;
//       break;
//     case 'minute':
//       addOptions.minutes = unitValue;
//       break;
//     case 'second':
//       addOptions.seconds = unitValue;
//       break;
//     default:
//       throw new Error(`Unsupported time unit: ${unit}`);
//   }

//   const calculatedDate = dateFns.add(date, addOptions);
//   return dateFns.format(calculatedDate, 'yyyy-MM-dd HH:mm:ss');
// }

export const isUrl = (url: string): boolean => {
  try {
    const parsed = new URL(url);
    return true;
  } catch (err) {
    return false;
  }
};

export const isPlainObject = (obj: unknown): obj is Record<string, unknown> => {
  return typeof obj === 'object' && obj !== null && !Array.isArray(obj);
};

export const camelCase = (str: string): string => {
  return str
    .toLowerCase()
    .replace(/[-_]+/g, ' ')
    .replace(/[^\w\s]/g, '')
    .replace(/\s(.)/g, (_, char) => char.toUpperCase())
    .replace(/\s/g, '')
    .replace(/^(.)/, (_, char) => char.toLowerCase());
};

export const snakeCase = (str: string): string => {
  return str
    .replace(/([A-Z])/g, '_$1')
    .toLowerCase()
    .replace(/^_/, '')
    .replace(/[-\s]+/g, '_');
};

/**
 * Extracts and parses a date from a string
 * @param str The string to parse
 * @returns Date object if found, null otherwise
 */
export const dateInString = (str: string): Date | null => {
  // Get just the str without extension and path
  const cleanFilename =
    str.split('/').pop()?.replace('.pdf', '').toLowerCase() || '';

  const yearMatch = cleanFilename.match(/20\d{2}/);
  if (!yearMatch) return null;
  const year = parseInt(yearMatch[0], 10);
  const yearIndex = cleanFilename.indexOf(yearMatch[0]);

  const monthPatterns = {
    january: 1,
    jan: 1,
    february: 2,
    feb: 2,
    march: 3,
    mar: 3,
    april: 4,
    apr: 4,
    may: 5,
    june: 6,
    jun: 6,
    july: 7,
    jul: 7,
    august: 8,
    aug: 8,
    september: 9,
    sep: 9,
    october: 10,
    oct: 10,
    november: 11,
    nov: 11,
    december: 12,
    dec: 12,
  };

  // Find month and its position
  let foundMonth: number | null = null;
  let monthStart = -1;
  let monthName = '';

  for (const [name, monthNum] of Object.entries(monthPatterns)) {
    const monthIndex = cleanFilename.indexOf(name);
    if (monthIndex !== -1) {
      foundMonth = monthNum;
      monthStart = monthIndex;
      monthName = name;
      break;
    }
  }

  if (!foundMonth) return null;

  // Look for a day number before or after the month
  const beforeMonth = cleanFilename.substring(
    Math.max(0, monthStart - 15),
    monthStart,
  );
  const afterMonth = cleanFilename.substring(
    monthStart + monthName.length,
    Math.min(cleanFilename.length, monthStart + monthName.length + 15),
  );

  const dayMatch =
    beforeMonth.match(/(\d{1,2})\s*$/) || // number at the end before month
    afterMonth.match(/^\s*(\d{1,2})/) || // number at the start after month
    afterMonth.match(/(\d{1,2})/); // any number after month

  const day = dayMatch ? parseInt(dayMatch[1], 10) : null;
  if (!day) return null;

  // Construct and validate date
  const date = new Date(year, foundMonth - 1, day);
  return !isNaN(date.getTime()) ? date : null;
};


export const prettyDate = (dateString: string) => {
  const date = new Date(dateString);
  return new Intl.DateTimeFormat(undefined, {
    year: 'numeric',
    month: 'long',
    day: 'numeric'
  }).format(date);
};
</file>

<file path="packages/utils/CLAUDE.md">
# @have/utils: Utility Functions Package

## Purpose and Responsibilities

The `@have/utils` package provides foundational utility functions used throughout the HAVE SDK. It serves as the base dependency for most other packages and offers common functionality for:

- File system path handling
- URL parsing and manipulation
- String manipulation and formatting
- Date handling and parsing
- Data structure transformation
- Unique ID generation

This package is intentionally lightweight with minimal external dependencies and focused on providing pure utility functions.

## Key APIs

### ID and Slug Generation

```typescript
// Generate a UUID
const id = makeId();

// Convert a string to a URL-friendly slug
const slug = makeSlug("My Example Title");
```

### Path Utilities

```typescript
// Get a temporary directory path
const tempPath = tmpdir("my-folder");

// Extract path components from a URL
const urlPathString = urlPath("https://example.com/path/to/resource");

// Get filename from URL
const filename = urlFilename("https://example.com/path/to/file.pdf");
```

### String Manipulation

```typescript
// Convert keys to camelCase
const camelCaseObj = keysToCamel({ some_key: "value" });

// Convert keys to snake_case
const snakeCaseObj = keysToSnake({ someKey: "value" });

// Convert string to camelCase
const camelString = camelCase("some-string-here");

// Convert string to snake_case
const snakeString = snakeCase("someStringHere");
```

### Date Utilities

```typescript
// Parse a date from a string
const date = dateInString("Report_January_2023.pdf");

// Format a date in a pretty format
const formatted = prettyDate("2023-01-15T12:00:00Z");
```

### Async Utilities

```typescript
// Wait for a condition with timeout
await waitFor(
  async () => { /* return something when ready */ },
  { timeout: 5000, delay: 100 }
);

// Sleep for a duration
await sleep(1000);
```

### Type Checking

```typescript
// Check if value is an array
const isArrayVal = isArray(value);

// Check if value is a plain object
const isObjVal = isPlainObject(value);

// Check if string is a URL
const isValidUrl = isUrl("https://example.com");
```

## Dependencies

`@have/utils` has minimal external dependencies:

- `@paralleldrive/cuid2`: For ID generation
- `date-fns`: For date manipulation
- `pluralize`: For singular/plural string transformation
- `uuid`: For UUID generation

## Development Guidelines

### Adding New Utilities

When adding new utility functions:

1. Keep functions pure and focused on a single responsibility
2. Add type definitions for parameters and return values
3. Use descriptive names that indicate function purpose
4. Write unit tests for each new function

### Testing

The package uses Vitest for testing. Run tests with:

```bash
pnpm test        # Run tests once
pnpm test:watch  # Run tests in watch mode
```

### Building

Build the package with:

```bash
pnpm build       # Build once
pnpm build:watch # Build in watch mode
```

### Best Practices

- Keep utility functions stateless when possible
- Prefer functional programming patterns
- Document complex functions with JSDoc comments
- Write utilities to be reusable across different contexts
- Consider performance implications for functions that may be called frequently

This package should remain lightweight and focused on general-purpose utilities that might be needed by multiple other packages.
</file>

<file path="biome.json">
{
  "$schema": "https://biomejs.dev/schemas/1.5.3/schema.json",
  "organizeImports": {
    "enabled": true
  },
  "linter": {
    "enabled": true,
    "rules": {
      "recommended": true,
      "correctness": {
        "noUnusedVariables": "warn"
      },
      "suspicious": {
        "noExplicitAny": "warn",
        "noPrototypeBuiltins": "warn"
      },
      "style": {
        "noNonNullAssertion": "warn"
      }
    }
  },
  "formatter": {
    "enabled": true,
    "formatWithErrors": false,
    "indentStyle": "space",
    "indentWidth": 2,
    "lineWidth": 80
  },
  "javascript": {
    "formatter": {
      "quoteStyle": "single",
      "trailingCommas": "all",
      "semicolons": "always"
    }
  },
  "files": {
    "include": ["packages/**/src/**/*.{ts,tsx,js,jsx,json}"],
    "ignore": [
      "**/node_modules/**",
      "**/.svelte-kit/**",
      "**/build/**",
      "**/dist/**"
    ]
  }
}
</file>

<file path="CONTRIBUTING.md">
# Coding Guidelines
- Follow the Airbnb JavaScript Style Guide.
- Add comments to clarify non-obvious logic. **Ensure all comments are written in English.**
- Provide corresponding unit tests for all new features.
- After implementation, verify changes by running:
  ```bash
  pnpm lint  # Ensure code style compliance
  pnpm test  # Verify all tests pass
  ```

## Commit Messages
- Follow the [Conventional Commits](https://www.conventionalcommits.org/) specification for all commit messages
- Always include a scope in your commit messages
- Format: `type(scope): Description`
- Types: feat, fix, docs, style, refactor, test, chore, etc.
- Scope should indicate the affected part of the codebase (cli, core, website, security, etc.)
- Description should be clear and concise in present tense
- Description must start with a capital letter

## Pull Request Guidelines
- All pull requests must follow the template:
  ```md
  <!-- Please include a summary of the changes -->

  ## Checklist

  - [ ] Run `pnpm test`
  - [ ] Run `pnpm lint`
  ```
- Include a clear summary of the changes at the top of the pull request description
- Reference any related issues using the format `#issue-number` 

## Dependencies and Testing
- Inject dependencies through a deps object parameter for testability
- Example:
  ```typescript
  export const functionName = async (
    param1: Type1,
    param2: Type2,
    deps = {
      defaultFunction1,
      defaultFunction2,
    }
  ) => {
    // Use deps.defaultFunction1() instead of direct call
  };
  ```
- Mock dependencies by passing test doubles through deps object
- Use vi.mock() only when dependency injection is not feasible

## Generate Comprehensive Output
- Include all content without abbreviation, unless specified otherwise
- Optimize for handling large codebases while maintaining output quality
</file>

<file path="lefthook.yml">
pre-commit:
  commands:
    format:
      glob: "*.{js,ts,cjs,mjs,jsx,tsx,json}"
      run: pnpm biome format --write {staged_files}
      stage_fixed: true
    lint:
      glob: "*.{js,ts,cjs,mjs,jsx,tsx,json}"
      run: pnpm biome lint --apply {staged_files}
      stage_fixed: true
</file>

<file path="packages/smrt/src/contents.spec.ts">
import { it, expect } from 'vitest';
import os from 'node:os';
import path from 'node:path';
import fs from 'node:fs';
import { makeSlug } from '@have/utils';
import { Contents } from './contents.js';
import { faker } from '@faker-js/faker';

const TMP_DIR = path.resolve(`${os.tmpdir()}/.have-sdk-tests/contents`);
fs.mkdirSync(TMP_DIR, { recursive: true });

it('should be able to getOrInsert a content item', async () => {
  const contents = await Contents.create({
    ai: {
      type: 'openai',
      apiKey: process.env.OPENAI_API_KEY!,
    },
    db: {
      url: `file:${TMP_DIR}/test.db`,
    },
  });

  const fakeContentData = {
    title: faker.lorem.sentence(),
    body: faker.lorem.paragraph(),
    author: faker.person.fullName(),
    publish_date: faker.date.recent(),
  };

  const content = await contents.getOrUpsert(fakeContentData);
  expect(content.id).toBeDefined();

  const content2 = await contents.getOrUpsert(fakeContentData);
  expect(content2.id).toBe(content.id);

  const got = await contents.get({ id: content.id });
  expect(got?.id).toEqual(content.id);
});

it('should respect the context of the slug', async () => {
  const contents = await Contents.create({
    ai: {
      type: 'openai',
      apiKey: process.env.OPENAI_API_KEY!,
    },
    db: {
      url: `file:${TMP_DIR}/test.db`,
    },
  });

  const fakeContentData = {
    title: faker.lorem.sentence(),
    body: faker.lorem.paragraph(),
    author: faker.person.fullName(),
    publish_date: faker.date.recent(),
  };

  const slug = makeSlug(fakeContentData.title);

  const content = await contents.getOrUpsert({
    ...fakeContentData,
    url: 'http://setinfirst.com',
    slug,
    context: 'contextA',
  });
  expect(content.id).toBeDefined();

  const different = await contents.getOrUpsert({
    ...fakeContentData,
    slug,
    context: 'contextB',
    source: 'set in different context',
  });
  expect(different.id).not.toBe(content.id);

  const contextA = await contents.get({
    slug,
    context: 'contextA',
  });

  const contextB = await contents.get({
    slug,
    context: 'contextB',
  });

  const updated = await contents.getOrUpsert({
    description: 'foo',
    slug,
    context: 'contextA',
  });

  expect(updated.id).toBeDefined();
  expect(updated.description).toBe('foo');
  expect(updated.id).toBe(contextA?.id);
});

// skipped because it takes a long time
it.skip('should be able to mirror a bit of content give a url', async () => {
  const contents = await Contents.create({
    ai: {
      type: 'openai',
      apiKey: process.env.OPENAI_API_KEY!,
    },
    db: {
      url: `file:${TMP_DIR}/test.db`,
    },
  });

  const created = await contents.mirror({
    url: 'https://townofbentley.ca/wp-content/uploads/2024/12/Signed-Minutes-November-26-2024-Regular-Council-Meeting.pdf',
    mirrorDir: `${TMP_DIR}/mirror-test`,
  });
  expect(created?.id).toBeDefined();
}, 60000);

it.skip('should be able to sync a content dir', async () => {
  const contents = await Contents.create({
    ai: {
      type: 'openai',
      apiKey: process.env.OPENAI_API_KEY!,
    },
    db: {
      url: `file:${TMP_DIR}/test.db`,
    },
    fs: {
      type: 'filesystem',
      cacheDir: `${TMP_DIR}/cache`,
    },
  });

  // for (let x = 0; x < 10; x++) {
  await contents.getOrUpsert({
    type: 'article',
    title: faker.lorem.sentence(),
    description: faker.lorem.sentence(),
    body: faker.lorem.paragraph(),
    author: faker.person.fullName(),
    publish_date: faker.date.recent(),
  });
  // }

  // await contents.syncContentDir({ contentDir: `${TMP_DIR}/content` });
});

it('should be able to list content', async () => {
  const contents = await Contents.create({
    ai: {
      type: 'openai',
      apiKey: process.env.OPENAI_API_KEY!,
    },
    db: {
      url: `file::memory:?cache=shared`, //todo: memory doesnt work because we pass around the connection,
    },
  });

  const fakeContentData = {
    type: 'article',
    title: faker.lorem.sentence(),
    body: faker.lorem.paragraph(),
    author: faker.person.fullName(),
    publish_date: faker.date.recent(),
  };

  const content = await contents.getOrUpsert(fakeContentData);
  await content.save();

  const fakeContentData2 = {
    title: faker.lorem.sentence(),
    body: faker.lorem.paragraph(),
    author: faker.person.fullName(),
    publish_date: faker.date.recent(),
  };

  const content2 = await contents.getOrUpsert(fakeContentData2);
  await content2.save();

  const fakeContentData3 = {
    title: faker.lorem.sentence(),
    body: faker.lorem.paragraph(),
    author: faker.person.fullName(),
    publish_date: faker.date.recent(),
  };
  const content3 = await contents.getOrUpsert(fakeContentData3);
  await content3.save();

  expect(content.id).toBeDefined();

  // const content2 = await contents.getOrUpsert(fakeContentData);
  // expect(content2.id).toBe(content.id);

  const articles = await contents.list({
    where: {
      type: 'article',
    }
  });
  expect(articles?.length).toEqual(1);

  const articleCount = await contents.count({
    where: {
      type: 'article',
    }
  });
  expect(articleCount).toEqual(1);
});
</file>

<file path="packages/smrt/src/object.ts">
import type { AIMessageOptions } from '@have/ai';
import type { BaseClassOptions } from './class.js';

import {
  fieldsFromClass,
  tableNameFromClass,
  setupTableFromClass,
} from '@have/smrt/utils';
import { escapeSqlValue } from '@have/sql';

import { BaseClass } from './class.js';
import { BaseCollection } from './collection.js';

export interface BaseObjectOptions extends BaseClassOptions {
  id?: string;
  name?: string;
  slug?: string;
  context?: string;
  created_at?: Date;
  updated_at?: Date;
}

export class BaseObject<
  T extends BaseObjectOptions = BaseObjectOptions,
> extends BaseClass<T> {
  public _collection!: BaseCollection<BaseObject<T>>;
  public _tableName!: string;
  protected _id: string | null | undefined; // a unique identifier for the object
  protected _slug: string | null | undefined; // a slug, url friendly identifier
  protected _context: string | null | undefined; // an option context to scope the slug, could contain a path, domain&path etc

  public name: string | null | undefined; // a friendly name, mostly for humans.. unique is better but not required
  public created_at: Date | null | undefined;
  public updated_at: Date | null | undefined;

  constructor(options: T) {
    super(options);
    if (options === null) {
      throw new Error('options cant be null');
    }
    this._id = options.id || null;
    this._slug = options.slug || null;
    this._context = options.context || '';
    this.name = options.name || null;
    this.created_at = options.created_at || null;
    this.updated_at = options.updated_at || null;
  }

  get id(): string | null | undefined {
    return this._id;
  }

  set id(value: string | null | undefined) {
    if (!value || value === 'undefined' || value === 'null') {
      throw new Error(`id is required, ${value} given`);
    }
    this._id = value;
  }

  get slug(): string | null | undefined {
    return this._slug;
  }

  set slug(value: string | null | undefined) {
    if (!value || value === 'undefined' || value === 'null') {
      throw new Error(`slug is invalid, ${value} given`);
    }

    this._slug = value;
  }

  get context(): string {
    return this._context || '';
  }

  set context(value: string | null | undefined) {
    if (value !== '' && !value) {
      throw new Error(`context is invalid, ${value} given`);
    }
    this._context = value;
  }

  protected async initialize(): Promise<void> {
    await super.initialize();
    if (this.options.db) {
      await setupTableFromClass(this.db, this.constructor);
      await this.db.query(`
        CREATE UNIQUE INDEX IF NOT EXISTS idx_${this.tableName}_slug_context 
        ON ${this.tableName}(slug, context);
      `);
    }

    if (this.options.id) {
      await this.loadFromId();
    } else if (this.options.slug) {
      await this.loadFromSlug();
    }
  }

  loadDataFromDb(data: any) {
    const fields = this.getFields();
    for (const field in fields) {
      if (fields.hasOwnProperty(field)) {
        this[field as keyof this] = data[field];
      }
    }
  }

  allDescriptors() {
    const proto = Object.getPrototypeOf(this);
    const descriptors = Object.getOwnPropertyDescriptors(proto);
    return descriptors;
  }

  get tableName() {
    if (!this._tableName) {
      this._tableName = tableNameFromClass(this.constructor);
    }
    return this._tableName;
  }

  getFields() {
    // Get the static fields definition from the class
    const fields = fieldsFromClass(
      this.constructor as new (...args: any[]) => any,
    );

    // Add current instance values to the fields
    for (const key in fields) {
      fields[key].value = this[key as keyof this];
    }

    return fields;
  }

  generateUpsertStatement() {
    const fields = this.getFields();
    const columns = ['id', 'slug', 'context'];
    const id = escapeSqlValue(this.id) || '';
    const slug = escapeSqlValue(this.slug);
    const context = escapeSqlValue(this.context || '');
    const values = [id, slug, context];
    const updates = [`slug = ${slug}`, `context = ${context}`];

    for (const [key, field] of Object.entries(fields)) {
      if (key === 'slug' || key === 'context') continue;
      columns.push(key);
      const value =
        typeof field.value === 'boolean' ? (field.value ? 1 : 0) : field.value;

      const escapedValue = escapeSqlValue(value);

      values.push(escapedValue);
      updates.push(`${key} = ${escapedValue}`);
    }

    // Use UPSERT syntax with explicit ON CONFLICT handling
    const sql = `
      INSERT INTO ${this.tableName} (${columns.join(', ')})
      VALUES (${values.join(', ')})
      ON CONFLICT(slug, context) 
      WHERE slug = ${slug} AND context = ${context}
      DO UPDATE SET
        ${updates.join(',\n        ')}
      WHERE ${this.tableName}.slug = ${slug} AND ${this.tableName}.context = ${context};
    `;

    return sql;
  }

  // needs to be async to allow looking up existing in db by slug
  async getId() {
    // lookup by slug and context
    const saved = await this.db
      .pluck`SELECT id FROM ${this.tableName} WHERE slug = ${this.slug} AND context = ${this.context} LIMIT 1`;
    if (saved) {
      this.id = saved;
    }

    if (!this.id) {
      this.id = crypto.randomUUID();
    }
    return this.id;
  }

  // Objects will be named to match table names

  async getSlug() {
    if (!this.slug && this.name) {
      // Generate slug from name if not set
      this.slug = this.name
        .toLowerCase()
        .replace(/[^a-z0-9]+/g, '-')
        .replace(/(^-|-$)/g, '');
    }

    // check for existing slug and make unique?
    return this.slug;
  }

  async getSavedId() {
    const { pluck } = this.db;
    const saved =
      await pluck`SELECT id FROM ${this.tableName} WHERE id = ${this.id} OR slug = ${this.slug} LIMIT 1`;
    return saved;
  }

  async isSaved() {
    const saved = await this.getSavedId();
    return !!saved;
  }

  async save() {
    if (!this.id) {
      this.id = crypto.randomUUID();
    }

    if (!this.slug) {
      this.slug = await this.getSlug();
    }

    // Update the updated_at timestamp
    this.updated_at = new Date();

    if (!this.created_at) {
      this.created_at = new Date();
    }

    await setupTableFromClass(this.options.db, this.constructor);

    const sql = this.generateUpsertStatement();
    await this.db.query(sql);

    return this;
  }

  public async loadFromId() {
    const {
      rows: [existing],
    } = await this.db.query(`SELECT * FROM ${this.tableName} WHERE id = ?`, [
      this.options.id,
    ]);
    if (existing) {
      this.loadDataFromDb(existing);
    }
  }

  public async loadFromSlug() {
    const {
      rows: [existing],
    } = await this.db.query(
      `SELECT * FROM ${this.tableName} WHERE slug = ? AND context = ?`,
      [this.options.slug, this.options.context || ''],
    );
    if (existing) {
      this.loadDataFromDb(existing);
    }
  }

  public async is(criteria: string, options: AIMessageOptions = {}) {
    const prompt = `--- Beginning of criteria ---\n${criteria}\n--- End of criteria ---\nDoes the content meet all the given criteria? Reply with a json object with a single boolean 'result' property`;
    const message = await this.ai.message(prompt, {
      ...(options as any),
      responseFormat: { type: 'json_object' },
    });
    try {
      const { result } = JSON.parse(message);
      if (result === true || result === false) {
        return result;
      }
    } catch (e) {
      throw new Error(`Unexpected answer: ${message}`);
    }
  }

  public async do(instructions: string, options: AIMessageOptions = {}) {
    const prompt = `--- Beginning of instructions ---\n${instructions}\n--- End of instructions ---\nBased on the content body, please follow the instructions and provide a response. Never make use of codeblocks.`;
    const result = await this.ai.message(prompt, options);
    return result;
  }
}

// async function ensureTriggersExist(db: any, tableName: string) {
//   const triggers = [
//     `${tableName}_set_created_at`,
//     `${tableName}_set_updated_at`,
//   ];

//   for (const trigger of triggers) {
//     const exists = await db.get(
//       `SELECT name FROM sqlite_master WHERE type='trigger' AND name=?`,
//       [trigger],
//     );

//     if (!exists) {
//       if (trigger === `${tableName}_set_created_at`) {
//         await db.exec(`
//           CREATE TRIGGER ${trigger}
//           AFTER INSERT ON ${tableName}
//           BEGIN
//             UPDATE ${tableName}
//             SET created_at = CURRENT_TIMESTAMP, updated_at = CURRENT_TIMESTAMP
//             WHERE id = NEW.id;
//           END;
//         `);
//       } else if (trigger === `${tableName}_set_updated_at`) {
//         await db.exec(`
//           CREATE TRIGGER ${trigger}
//           AFTER UPDATE ON ${tableName}
//           BEGIN
//             UPDATE ${tableName}
//             SET updated_at = CURRENT_TIMESTAMP
//             WHERE id = NEW.id;
//           END;
//         `);
//       }
//     }
//   }
// }
</file>

<file path="packages/sql/src/index.ts">
import type { DatabaseInterface } from "./types.js";
import type { PostgresOptions } from "./postgres.js";
import type { SqliteOptions } from "./sqlite.js";

type GetDatabaseOptions =
  | (PostgresOptions & { type?: "postgres" })
  | (SqliteOptions & { type?: "sqlite" });

export async function getDatabase(
  options: GetDatabaseOptions = {},
): Promise<DatabaseInterface> {
  // if no type but url starts with file:, set to sqlite
  if (
    !options.type &&
    (options.url?.startsWith("file:") || options.url === ":memory:")
  ) {
    options.type = "sqlite";
  }

  if (options.type === "postgres") {
    const postgres = await import("./postgres.js");
    return postgres.getDatabase(options as PostgresOptions);
  } else if (options.type === "sqlite") {
    const sqlite = await import("./sqlite.js");
    return sqlite.getDatabase(options as SqliteOptions);
  } else {
    throw new Error("Invalid database type");
  }
}

function isValidTableName(name: string): boolean {
  // Simple regex to allow only alphanumeric characters and underscores
  return /^[a-zA-Z0-9_]+$/.test(name);
}

// takes a table definition and syncs it to the database
// caution: this will only be tested for schenarios within the sdk
export async function syncSchema(options: {
  db: DatabaseInterface;
  schema: string;
}) {
  const { db, schema } = options;
  if (!db || !schema) {
    throw new Error("db and schema are required");
  }
  const commands = schema
    .trim()
    .split(";")
    .filter((command) => command.trim() !== "");

  for (const command of commands) {
    const createTableRegex =
      /CREATE TABLE (IF NOT EXISTS )?(\w+) \(([\s\S]+)\)/i;
    const match = command.match(createTableRegex);

    if (match) {
      const tableName = match[2];
      const columns = match[3].trim().split(",\n");

      if (!isValidTableName(tableName)) {
        throw new Error("Invalid table name");
      }
      const tableExists =
        !!(await db.pluck`SELECT name FROM sqlite_master WHERE type='table' AND name=${tableName}`);
      if (!tableExists) {
        await db.query(command);
      } else {
        // 3. Check for column differences
        for (const column of columns) {
          const columnDef = column.trim();
          const [, columnName, columnType] =
            columnDef.match(/(\w+) (\w+)(.*)/) || [];

          if (columnName && columnType) {
            try {
              // Check if the column exists and has the correct type
              const columnInfo = await db.oO`
                SELECT *
                FROM pragma_table_info(${tableName})
                WHERE name = ${columnName}
              `;

              if (!columnInfo || columnInfo.length === 0) {
                // Column doesn't exist or has an incorrect type, apply changes
                const alterCommand = `ALTER TABLE ${tableName} ADD COLUMN ${columnDef};`;
                await db.query(alterCommand);
              }
            } catch (error) {
              // Column doesn't exist or has an incorrect type, apply changes
              const alterCommand = `ALTER TABLE ${tableName} ADD COLUMN ${columnDef};`;
              await db.query(alterCommand);
            }
          }
        }
      }
    }
  }
}

export async function tableExists(db: DatabaseInterface, tableName: string) {
  const tableExists =
    await db.pluck`SELECT name FROM sqlite_master WHERE type='table' AND name='${tableName}'`;
  return !!tableExists;
}

export function escapeSqlValue(value: any): string {
  if (value === null) {
    return "NULL";
  }
  if (value instanceof Date) {
    return `'${value.toISOString()}'`;
  }
  if (typeof value === "number") {
    return value.toString();
  }
  if (typeof value === "boolean") {
    return value ? "1" : "0";
  }
  // Escape single quotes and wrap in quotes
  return `'${String(value).replace(/'/g, "''")}'`;
}

export function validateColumnName(column: string): string {
  // Only allow alphanumeric characters, underscores, and dots (for table.column notation)
  if (!/^[a-zA-Z0-9_.]+$/.test(column)) {
    throw new Error(`Invalid column name: ${column}`);
  }
  return column;
}

const VALID_OPERATORS = {
  "=": "=",
  ">": ">",
  ">=": ">=",
  "<": "<",
  "<=": "<=",
  "!=": "!=",
  like: "LIKE",
  in: "IN",
} as const;

/**
 * Builds a SQL WHERE clause with parameterized values and flexible operators
 *
 * @param where Record of conditions with optional operators in keys
 * @param startIndex Starting index for parameter numbering (default: 1)
 * @returns Object containing the SQL clause and array of values
 *
 * @example Basic Usage:
 * ```typescript
 * buildWhere({
 *   'status': 'active',           // equals operator is default
 *   'price >': 100,              // greater than
 *   'stock <=': 5,               // less than or equal
 *   'category in': ['A', 'B'],   // IN clause for arrays
 *   'name like': '%shirt%'       // LIKE for pattern matching
 * });
 * ```
 *
 * @example NULL Handling:
 * ```typescript
 * buildWhere({
 *   'deleted_at': null,          // becomes "deleted_at IS NULL"
 *   'updated_at !=': null,       // becomes "updated_at IS NOT NULL"
 *   'status': 'active'           // regular comparison
 * });
 * ```
 *
 * @example Common Patterns:
 * ```typescript
 * // Price range
 * buildWhere({
 *   'price >=': 10,
 *   'price <': 100
 * });
 *
 * // Date filtering
 * buildWhere({
 *   'created_at >': startDate,
 *   'created_at <=': endDate,
 *   'deleted_at': null
 * });
 *
 * // Search with LIKE
 * buildWhere({
 *   'title like': '%search%',
 *   'description like': '%search%',
 *   'status': 'published'
 * });
 *
 * // Multiple values with IN
 * buildWhere({
 *   'role in': ['admin', 'editor'],
 *   'active': true,
 *   'last_login !=': null
 * });
 * ```
 *
 * The function handles:
 * - Standard comparisons (=, >, >=, <, <=, !=)
 * - NULL checks (IS NULL, IS NOT NULL)
 * - IN clauses for arrays
 * - LIKE for pattern matching
 * - Multiple conditions combined with AND
 */
export const buildWhere = (where: Record<string, any>, startIndex = 1) => {
  let sql = "";
  const values: any[] = [];
  let currIndex = startIndex;

  if (where && Object.keys(where).length > 0) {
    sql = "WHERE ";
    for (const [fullKey, value] of Object.entries(where)) {
      const [field, operator = "="] = fullKey.split(" ");
      const sqlOperator =
        VALID_OPERATORS[operator as keyof typeof VALID_OPERATORS] || "=";

      if (sql !== "WHERE ") {
        sql += " AND ";
      }

      if (value === null) {
        sql += `${field} IS ${sqlOperator === "=" ? "NULL" : "NOT NULL"}`;
      } else {
        sql += `${field} ${sqlOperator} $${currIndex++}`;
        values.push(value);
      }
    }
  }

  return { sql, values };
};

export * from "./types.js";

export default { getDatabase, syncSchema, tableExists, buildWhere };
</file>

<file path="packages/sql/src/sqlite.ts">
import { createClient } from "@libsql/client";
import type {
  QueryResult,
  DatabaseInterface,
  TableInterface,
} from "./types.js";
import { buildWhere } from "./index.js";

export interface SqliteOptions {
  url?: string;
  authToken?: string;
}

export function getDatabase(options: SqliteOptions = {}): DatabaseInterface {
  const { url = "file::memory:", authToken } = options;
  const client = createClient({ url, authToken });

  const insert = async (
    table: string,
    data: Record<string, any> | Record<string, any>[],
  ): Promise<QueryResult> => {
    let sql: string;
    let values: any[];

    if (Array.isArray(data)) {
      const keys = Object.keys(data[0]);
      const placeholders = data
        .map(() => `(${keys.map(() => "?").join(", ")})`)
        .join(", ");
      sql = `INSERT INTO ${table} (${keys.join(", ")}) VALUES ${placeholders}`;
      values = data.reduce(
        (acc, row) => acc.concat(Object.values(row)),
        [] as any[],
      );
    } else {
      const keys = Object.keys(data);
      const placeholders = keys.map(() => "?").join(", ");
      sql = `INSERT INTO ${table} (${keys.join(", ")}) VALUES (${placeholders})`;
      values = Object.values(data);
    }
    try {
      const result = await client.execute({ sql: sql, args: values });
      return { operation: "insert", affected: result.rowsAffected };
    } catch (e) {
      console.error(
        `Error executing SQL: ${sql}\nValues: ${JSON.stringify(values)}\nError: ${e}`,
      );
      throw e;
    }
  };

  const get = async (
    table: string,
    where: Record<string, any>,
  ): Promise<Record<string, any> | null> => {
    const keys = Object.keys(where);
    const values = Object.values(where);
    const whereClause = keys.map((key) => `${key} = ?`).join(" AND ");
    const sql = `SELECT * FROM ${table} WHERE ${whereClause}`;
    try {
      const result = await client.execute({ sql: sql, args: values });
      return result.rows[0] || null;
    } catch (e) {
      console.error(
        `Error executing SQL: ${sql}\nValues: ${JSON.stringify(values)}\nError: ${e}`,
      );
      throw e;
    }
  };

  const list = async (
    table: string,
    where: Record<string, any>,
  ): Promise<Record<string, any>[]> => {
    const { sql: whereClause, values } = buildWhere(where);
    const sql = `SELECT * FROM ${table} ${whereClause}`;
    try {
      const result = await client.execute({ sql, args: values });
      return result.rows;
    } catch (e) {
      console.error(
        `Error executing SQL: ${sql}\nValues: ${JSON.stringify(values)}\nError: ${e}`,
      );
      throw e;
    }
  };

  const update = async (
    table: string,
    where: Record<string, any>,
    data: Record<string, any>,
  ): Promise<QueryResult> => {
    const keys = Object.keys(data);
    const values = Object.values(data);
    const setClause = keys.map((key) => `${key} = ?`).join(", ");
    const whereKeys = Object.keys(where);
    const whereValues = Object.values(where);
    const whereClause = whereKeys.map((key) => `${key} = ?`).join(" AND ");

    const sql = `UPDATE ${table} SET ${setClause} WHERE ${whereClause}`;
    try {
      const result = await client.execute({
        sql,
        args: [...values, ...whereValues],
      });
      return { operation: "update", affected: result.rowsAffected };
    } catch (e) {
      console.error(
        `Error executing SQL: ${sql}\nValues: ${JSON.stringify([...values, ...whereValues])}\nError: ${e}`,
      );
      throw e;
    }
  };

  const getOrInsert = async (
    table: string,
    where: Record<string, any>,
    data: Record<string, any>,
  ): Promise<Record<string, any>> => {
    const result = await get(table, where);
    if (result) return result;
    await insert(table, data);

    const inserted = await get(table, where);
    if (!inserted) {
      throw new Error("Failed to insert and retrieve record");
    }
    return inserted;
  };

  const tableExists = async (tableName: string): Promise<boolean> => {
    const tableExists =
      !!(await pluck`SELECT name FROM sqlite_master WHERE type='table' AND name=${tableName}`);
    return tableExists;
  };

  const table = (tableName: string): TableInterface => ({
    insert: (data) => insert(tableName, data),
    get: (where) => get(tableName, where),
    list: (where) => list(tableName, where),
  });

  const parseTemplate = (strings: TemplateStringsArray, ...vars: any[]) => {
    let sql = strings[0];
    const values = [];
    for (let i = 0; i < vars.length; i++) {
      values.push(vars[i]);
      sql += "?" + strings[i + 1];
    }
    return { sql, values };
  };

  const pluck = async (
    strings: TemplateStringsArray,
    ...vars: any[]
  ): Promise<any> => {
    const { sql, values } = parseTemplate(strings, ...vars);
    try {
      const result = await client.execute({ sql, args: values });
      return result.rows[0]?.[Object.keys(result.rows[0])[0]] ?? null;
    } catch (e) {
      console.error(
        `Error executing SQL: ${sql}\nValues: ${JSON.stringify(values)}\nError: ${e}`,
      );
      throw e;
    }
  };

  const single = async (
    strings: TemplateStringsArray,
    ...vars: any[]
  ): Promise<Record<string, any> | null> => {
    const { sql, values } = parseTemplate(strings, ...vars);
    try {
      const result = await client.execute({ sql, args: values });
      return result.rows[0] || null;
    } catch (e) {
      console.error(
        `Error executing SQL: ${sql}\nValues: ${JSON.stringify(values)}\nError: ${e}`,
      );
      throw e;
    }
  };

  const many = async (
    strings: TemplateStringsArray,
    ...vars: any[]
  ): Promise<Record<string, any>[]> => {
    const { sql, values } = parseTemplate(strings, ...vars);
    try {
      const result = await client.execute({ sql, args: values });
      return result.rows;
    } catch (e) {
      console.error(
        `Error executing SQL: ${sql}\nValues: ${JSON.stringify(values)}\nError: ${e}`,
      );
      throw e;
    }
  };

  const execute = async (
    strings: TemplateStringsArray,
    ...vars: any[]
  ): Promise<void> => {
    const { sql, values } = parseTemplate(strings, ...vars);
    try {
      await client.execute({ sql, args: values });
    } catch (e) {
      console.error(
        `Error executing SQL: ${sql}\nValues: ${JSON.stringify(values)}\nError: ${e}`,
      );
      throw e;
    }
  };

  const query = async (str: string, ...values: any[]) => {
    const sql = str;
    const args = Array.isArray(values[0]) ? values[0] : values;
    try {
      const result = await client.execute({ sql, args });
      return {
        command: sql.split(" ")[0].toUpperCase(),
        rowCount: result.rowsAffected ?? result.rows.length,
        oid: null,
        fields: Object.keys(result.rows[0] || {}).map((name) => ({
          name,
          tableID: 0,
          columnID: 0,
          dataTypeID: 0,
          dataTypeSize: -1,
          dataTypeModifier: -1,
          format: "text",
        })),
        rows: result.rows,
      };
    } catch (e) {
      console.error(
        `Error executing SQL: ${sql}\nValues: ${JSON.stringify(args)}\nError: ${e}`,
      );
      throw e;
    }
  };

  // cute aliases
  const oo = many;
  const oO = single;
  const ox = pluck;
  const xx = execute;

  return {
    client,
    query,
    insert,
    update,
    get,
    list,
    getOrInsert,
    table,
    tableExists,
    many,
    single,
    pluck,
    execute,
    oo,
    oO,
    ox,
    xx,
  };
}
</file>

<file path=".gitignore">
# Dependencies
node_modules
packages/*/node_modules
packages/*/dist
.pnpm-store

# Environment variables
.envrc
.env
.env.local
.env.development
.env.production
.env.test

# Build outputs
dist/
build/

# TypeScript
*.tsbuildinfo
.tscache

# IDE and editors
.idea/
.vscode/
*.swp
*.swo
.DS_Store
Thumbs.db

# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
pnpm-debug.log*

# Cache directories
.npm
.eslintcache
.stylelintcache
.next
.nuxt
.cache
.turbo

# Test coverage
coverage/
.nyc_output

# Misc
.DS_Store
*.pem
.vercel

*.traineddata
.svelte-kit
.npmrc.local

**/.claude/settings.local.json
</file>

<file path="CLAUDE.md">
# HAppy VErtical SDK: Architecture and Development Guide

## Overview

The HAppy VErtical (HAVE) SDK is a TypeScript monorepo designed for building vertical AI agents. It follows these core principles:

- Pure TypeScript implementation to avoid CommonJS vs ESM compatibility issues
- Minimized dependencies through a modular monorepo architecture
- Compartmentalized code to keep AI agents lean and focused
- Support for testing and scaling with minimal overhead
- Standardized interfaces across different packages

## Monorepo Structure

The SDK is organized as a pnpm workspace with several packages that provide specific functionality:

- **ai**: A standardized interface for AI model interactions, currently supporting OpenAI
- **files**: Tools for interacting with file systems (local and remote)
- **pdf**: Utilities for parsing and processing PDF documents
- **smrt**: Core library for building AI agents with standardized collections and objects 
- **spider**: Web crawling and content parsing tools (renamed from "web")
- **sql**: Database interaction with support for SQLite and Postgres
- **utils**: Shared utility functions used across packages

## Development Patterns

### Dependency Management

- Package versioning is synchronized across the monorepo
- Internal dependencies use `workspace:*` to reference other packages
- External dependencies are kept to a minimum
- Node.js v22.x is required for all packages

### Build Process

The build process follows a specific order to respect internal dependencies:

1. `@have/utils` (base utilities used by all packages)
2. `@have/files` (file system interactions)
3. `@have/spider` (web crawling)
4. `@have/sql` (database interactions)
5. `@have/pdf` (PDF processing)
6. `@have/ai` (AI model interfaces)
7. `@have/smrt` (agent framework that depends on all the above)

### Code Style and Conventions

- Code formatting is enforced by Biome
- Spaces (2) for indentation
- Single quotes for strings
- Line width of 80 characters
- ESM module format exclusively
- Each package has its own tsconfig that extends from the root
- Use camelCase for variables and functions, PascalCase for classes
- Use conventional commits
- Dont include claude branding in commit messages

### Testing

- Tests are written using Vitest
- Each package has its own test suite
- Run tests with `pnpm test` or `pnpm test:watch`

### Common Development Commands

```bash
# Install dependencies
pnpm install

# Run tests
pnpm test

# Build all packages in correct order
pnpm build

# Watch mode development
pnpm dev

# Lint code
pnpm lint

# Format code
pnpm format
```

## Cross-Package Dependencies

The packages have these dependency relationships:

- `utils`: No internal dependencies
- `files`: Depends on `utils`
- `spider`: Depends on `utils` and `files`
- `sql`: No internal dependencies
- `pdf`: No internal dependencies
- `ai`: No internal dependencies
- `smrt`: Depends on all other packages

When adding new features, maintain this dependency hierarchy to avoid circular dependencies.

## Contribution Guidelines

1. Ensure code passes Biome linting (`pnpm lint`)
2. Write tests for new functionality
3. Update package documentation when adding new features
4. Follow existing code patterns in each package
5. Run the full test suite before submitting changes

## Tooling Configuration

- **TypeScript**: Configured for ES2022 with strict type checking
- **Biome**: Used for linting and formatting
- **pnpm**: Package management with workspace support
- **Vitest**: Testing framework
- **Changesets**: Used for versioning and publishing packages

This repository is designed to support building AI agents with minimal overhead and maximum flexibility.

Check for a repomix-output.xml file before crawling the codebase. Repomix is a tool that packs your entire repository into a single, AI-friendly file. It's designed to help you feed your codebase to Large Language Models (LLMs) like ChatGPT, DeepSeek, Perplexity, Gemini, Gemma, Llama, Grok, and more.
##
</file>

<file path="setup_dev.sh">
#!/usr/bin/env bash

# Get the directory where the script is located
SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"

# Unlink all packages globally first
pnpm unlink --global @have/ai @have/files @have/pdf @have/smrt @have/spider @have/sql @have/utils
pnpm unlink --global @happyvertical/praeco @have/svelte

# Link SDK packages
cd "$SCRIPT_DIR/packages/ai" && pnpm unlink && pnpm link --global
cd "$SCRIPT_DIR/packages/files" && pnpm unlink && pnpm link --global
cd "$SCRIPT_DIR/packages/pdf" && pnpm unlink && pnpm link --global
cd "$SCRIPT_DIR/packages/smrt" && pnpm unlink && pnpm link --global
cd "$SCRIPT_DIR/packages/spider" && pnpm unlink && pnpm link --global
cd "$SCRIPT_DIR/packages/sql" && pnpm unlink && pnpm link --global
cd "$SCRIPT_DIR/packages/utils" && pnpm unlink && pnpm link --global

# Link to praeco
cd "$SCRIPT_DIR/../praeco"
pnpm unlink @have/ai @have/files @have/smrt @have/spider @have/sql @have/utils
pnpm link --global @have/ai @have/files @have/smrt @have/spider @have/sql @have/utils
pnpm link --global

cd "$SCRIPT_DIR/../svelte"
pnpm unlink
pnpm link --global

# Link to bentleyalberta.com
cd "$SCRIPT_DIR/../bentleyalberta.com"
pnpm unlink @happyvertical/praeco @have/smrt @have/svelte @have/utils
pnpm link --global @happyvertical/praeco @have/smrt @have/svelte @have/utils
</file>

<file path="packages/smrt/src/collection.ts">
import type { BaseClassOptions } from './class.js';
import { BaseClass } from './class.js';
import {
  fieldsFromClass,
  tableNameFromClass,
  generateSchema,
  formatDataJs,
  formatDataSql,
} from './utils.js';
import { syncSchema, buildWhere } from '@have/sql';
import { BaseObject } from './object.js';

export interface BaseCollectionOptions extends BaseClassOptions {}

export class BaseCollection<
  ModelType extends BaseObject<any>,
  T extends BaseCollectionOptions = BaseCollectionOptions,
> extends BaseClass<T> {
  protected _db_setup_promise: Promise<void> | null = null;
  protected get _itemClass(): (new (options: any) => ModelType) & {
    create(options: any): ModelType | Promise<ModelType>;
  } {
    const constructor = this.constructor as {
      readonly _itemClass?: (new (options: any) => ModelType) & {
        create(options: any): ModelType | Promise<ModelType>;
      };
    };
    if (!constructor._itemClass) {
      // todo: sort out why Meetings._itemClass is undefined
      throw new Error(
        `Collection ${this.constructor.name} must define static _itemClass`,
      );
      //   console.warn(
      //     `Collection ${this.constructor.name} must define static _itemClass`,
      //   );
      // }
    }
    return constructor._itemClass;
  }

  static readonly _itemClass: any;
  public _tableName!: string;

  /**
   * Valid SQL operators that can be used in where conditions.
   * Keys are the operators as they appear in the query object,
   * values are their SQL equivalents.
   */
  private readonly VALID_OPERATORS = {
    '=': '=',
    '>': '>',
    '>=': '>=',
    '<': '<',
    '<=': '<=',
    '!=': '!=',
    like: 'LIKE',
    in: 'IN',
    // Add more operators as needed
  } as const;

  constructor(options: T) {
    super(options);
  }

  public async initialize() {
    await super.initialize();
    if (this.options.db) {
      await this.setupDb();
    }
  } 

  public async get(filter: string | Record<string, any>) {
    const where =
      typeof filter === 'string'
        ? /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i.test(
            filter,
          )
          ? { id: filter }
          : { slug: filter, context: '' }
        : filter;

    // let sql = `SELECT * FROM ${this.tableName}`;
    const { sql: whereSql, values: whereValues } = buildWhere(where);

    const { rows } = await this.db.query(
      `SELECT * FROM ${this.tableName} ${whereSql}`,
      whereValues,
    );
    if (!rows?.[0]) {
      return null;
    }

    return this.create(formatDataJs(rows[0]));
  }

  /**
   * Lists records from the collection with flexible filtering options.
   *
   * @param options Query options object
   * @param options.where Record of conditions to filter results. Each key can include an operator
   *                      separated by a space (e.g., 'price >', 'name like'). Default operator is '='.
   * @param options.offset Number of records to skip
   * @param options.limit Maximum number of records to return
   *
   * @example
   * ```typescript
   * // Find active products priced between $100-$200
   * await collection.list({
   *   where: {
   *     'price >': 100,
   *     'price <=': 200,
   *     'status': 'active',              // equals operator is default
   *     'category in': ['A', 'B', 'C'],  // IN operator for arrays
   *     'name like': '%shirt%',          // LIKE for pattern matching
   *     'deleted_at !=': null            // exclude deleted items
   *   },
   *   limit: 10,
   *   offset: 0
   * });
   *
   * // Find users matching pattern but not in specific roles
   * await users.list({
   *   where: {
   *     'email like': '%@company.com',
   *     'active': true,
   *     'role in': ['guest', 'blocked'],
   *     'last_login <': lastMonth
   *   }
   * });
   * ```
   *
   * @returns Promise resolving to an array of model instances
   */
  public async list(options: {
    where?: Record<string, any>;
    offset?: number;
    limit?: number;
    orderBy?: string | string[];
  }) {
    const { where, offset, limit, orderBy } = options;
    const { sql: whereSql, values: whereValues } = buildWhere(where || {});

    let orderBySql = '';
    if (orderBy) {
      orderBySql = ' ORDER BY ';
      const orderByItems = Array.isArray(orderBy) ? orderBy : [orderBy];

      orderBySql += orderByItems
        .map((item) => {
          const [field, direction = 'ASC'] = item.split(' ');

          // Validate field name
          if (!/^[a-zA-Z0-9_]+$/.test(field)) {
            throw new Error(`Invalid field name for ordering: ${field}`);
          }

          // Validate direction
          const normalizedDirection = direction.toUpperCase();
          if (normalizedDirection !== 'ASC' && normalizedDirection !== 'DESC') {
            throw new Error(
              `Invalid sort direction: ${direction}. Must be ASC or DESC.`,
            );
          }

          return `${field} ${normalizedDirection}`;
        })
        .join(', ');
    }

    let limitOffsetSql = '';
    const limitOffsetValues = [];

    if (limit !== undefined) {
      limitOffsetSql += ' LIMIT ?';
      limitOffsetValues.push(limit);
    }

    if (offset !== undefined) {
      limitOffsetSql += ' OFFSET ?';
      limitOffsetValues.push(offset);
    }

    const result = await this.db.query(
      `SELECT * FROM ${this.tableName} ${whereSql} ${orderBySql} ${limitOffsetSql}`,
      [...whereValues, ...limitOffsetValues],
    );
    return Promise.all(
      result.rows.map((item: object) => this.create(formatDataJs(item))),
    );
  }

  public create(options: any) {
    const params = {
      ai: this.options.ai,
      db: this.options.db,
      ...options,
    };
    return this._itemClass.create(params);
  }

  //todo: tx to protect against race condition
  public async getOrUpsert(data: any, defaults: any = {}) {
    data = formatDataSql(data);
    let where: any = {};
    if (data.id) {
      where = { id: data.id };
    } else if (data.slug) {
      where = { slug: data.slug, context: data.context || '' };
    } else {
      where = data;
    }
    const existing = await this.get(where);
    if (existing) {
      const diff = this.getDiff(existing, data);
      if (diff) {
        Object.assign(existing, diff);
        await existing.save();
        return existing;
      }
      return existing;
    }
    const upsertData = { ...defaults, ...data };
    const upserted = await this.create(upsertData);
    await upserted.save();
    return upserted;
  }

  getDiff(
    existing: Record<string, any>,
    data: Record<string, any>,
  ): Record<string, any> {
    const fields = this._itemClass.prototype.getFields();
    return Object.keys(data).reduce(
      (acc, key) => {
        if (fields[key] && existing[key] !== data[key]) {
          acc[key] = data[key];
        }
        return acc;
      },
      {} as Record<string, any>,
    );
  }

  async setupDb() {
    if (this._db_setup_promise) {
      return this._db_setup_promise;
    }

    this._db_setup_promise = (async () => {
      try {
        const schema = this.generateSchema();
        await syncSchema({ db: this.db, schema });
        await this.setupTriggers();
      } catch (error) {
        this._db_setup_promise = null; // Allow retry on failure
        throw error;
      }
    })();

    return this._db_setup_promise;
  }

  getFields() {
    return fieldsFromClass(this._itemClass);
  }

  generateSchema() {
    // Use the imported generateSchema function with the item class
    return generateSchema(this._itemClass);
  }

  async setupTriggers() {
    const triggers = [
      `${this.tableName}_set_created_at`,
      `${this.tableName}_set_updated_at`,
    ];

    for (const trigger of triggers) {
      const exists = await this.db
        .pluck`SELECT name FROM sqlite_master WHERE type='trigger' AND name=${trigger}`;
      if (!exists) {
        if (trigger === `${this.tableName}_set_created_at`) {
          const createTriggerSQL = `
            CREATE TRIGGER ${trigger}
            AFTER INSERT ON ${this.tableName}
            BEGIN
              UPDATE ${this.tableName} 
              SET created_at = CURRENT_TIMESTAMP, updated_at = CURRENT_TIMESTAMP 
              WHERE id = NEW.id;
            END;
          `;
          await this.db.query(createTriggerSQL);
        } else if (trigger === `${this.tableName}_set_updated_at`) {
          const createTriggerSQL = `
            CREATE TRIGGER ${trigger}
            AFTER UPDATE ON ${this.tableName}
            BEGIN
              UPDATE ${this.tableName} 
              SET updated_at = CURRENT_TIMESTAMP 
              WHERE id = NEW.id;
            END;
          `;
          await this.db.query(createTriggerSQL);
        }
      }
    }
  }

  get tableName() {
    if (!this._tableName) {
      this._tableName = tableNameFromClass(this.constructor);
    }
    return this._tableName;
  }

  generateTableName() {
    // Convert camelCase/PascalCase to snake_case and pluralize
    const tableName = this._className
      // Insert underscore between lower & upper case letters
      .replace(/([a-z])([A-Z])/g, '$1_$2')
      // Convert to lowercase
      .toLowerCase()
      // Handle basic pluralization rules
      .replace(/([^s])$/, '$1s')
      // Handle special cases ending in 'y'
      .replace(/y$/, 'ies');

    return tableName;
  }

  /**
   * Counts records in the collection matching the given filters.
   * Accepts the same where conditions as list() but ignores limit/offset/orderBy.
   * 
   * @param options Query options object
   * @param options.where Record of conditions to filter results
   * @returns Promise resolving to the total count of matching records
   */
  public async count(options: { where?: Record<string, any> } = {}) {
    const { where } = options;
    const { sql: whereSql, values: whereValues } = buildWhere(where || {});

    const result = await this.db.query(
      `SELECT COUNT(*) as count FROM ${this.tableName} ${whereSql}`,
      whereValues
    );
    
    return parseInt(result.rows[0].count, 10);
  }
}
</file>

<file path=".gitea/workflows/agents/claude/test-issue-trigger.yaml">
name: Test Issue Assignment Trigger
on:
  issues:
    types: [labeled, assigned] # Add 'assigned' to test that trigger too, or keep only 'labeled'
jobs:
  test_job:
    runs-on: ubuntu-latest
    steps:
      - name: Show Event Details
        run: |
          echo "Workflow triggered by event: ${{ gitea.event_name }}"
          echo "Action type: ${{ gitea.event.action }}"
          echo "Issue Number: ${{ gitea.event.issue.number }}"
          echo "Issue Title: ${{ gitea.event.issue.title }}"
          echo "Sender (user performing the action): ${{ gitea.event.sender.login }}"

      - name: Show Label Details (if action is 'labeled')
        if: gitea.event.action == 'labeled'
        run: |
          echo "Label Name: ${{ gitea.event.label.name }}"
          echo "Label Color: ${{ gitea.event.label.color }}"

      - name: Show Assignee Information
        run: |
          echo "Issue's Current Assignee (from issue object): ${{ gitea.event.issue.assignee.login }}"
          echo "Full Issue Assignee Object (from issue object): ${{ toJson(gitea.event.issue.assignee) }}"
          echo "Direct Event Assignee (populated for 'assigned' action): ${{ gitea.event.assignee.login }}"
          echo "Full Direct Event Assignee Object (for 'assigned' action): ${{ toJson(gitea.event.assignee) }}"
</file>

<file path="packages/smrt/src/contents.ts">
import type { AIClientOptions } from '@have/ai';
import type { BaseCollectionOptions } from './collection.js';
import YAML from 'yaml';
import path from 'path';
import { writeFile } from 'node:fs/promises';
import { ensureDirectoryExists } from '@have/files';
import { makeSlug } from '@have/utils';
import { BaseCollection } from './collection.js';
import { Content } from './content.js';
import { Document } from './document.js';

export interface ContentsOptions extends BaseCollectionOptions {
  ai?: AIClientOptions;
  contentDir?: string;
}

export class Contents extends BaseCollection<Content> {
  static _itemClass = Content;
  public options: ContentsOptions = {} as ContentsOptions;
  private exampleContent!: Content;
  private loaded: Map<string, Content>;
  public contentDir?: string;

  static async create(options: ContentsOptions): Promise<Contents> {
    const contents = new Contents(options);
    await contents.initialize();
    return contents;
  }

  constructor(options: ContentsOptions) {
    super(options);
    this.options = options; //needed cause redeclare above i think ?
    this.loaded = new Map();
  }

  getDb() {
    return this._db;
  }

  public async initialize(): Promise<void> {
    await super.initialize();
  }

  // todo: param to force refresh
  // todo: check age of mirror and if older than x check for updates
  public async mirror(options: {
    url: string;
    mirrorDir?: string;
    context?: string;
  }) {
    if (!options.url) {
      throw new Error('No URL provided');
    }
    let url: URL;
    try {
      // const url = new URL(options.url);
      // const existing = await this.db
      //   .oO`SELECT * FROM contents WHERE url = ${options.url}`;
      url = new URL(options.url); // validate url
    } catch (error) {
      console.error(error);
      throw new Error(`Invalid URL provided: ${options.url}`);
    }
    const existing = await this.get({ url: options.url });
    if (existing) {
      return existing;
    }

    const doc = await Document.create({
      cacheDir: options?.mirrorDir,
      url: options.url,
    });

    const filename = url.pathname.split('/').pop();
    const nameWithoutExtension = filename?.replace(/\.[^/.]+$/, '');
    const title = nameWithoutExtension?.replace(/[-_]/g, ' ');
    const slug = makeSlug(title as string);
    const body = await doc.getText();
    if (body) {
      const content = await Content.create({
        db: this.options.db,
        ai: this.options.ai,
        url: options.url,
        type: 'mirror',
        title,
        slug,
        context: options.context || '',
        body,
      });

      await content.save();
      return content;
    }
  }

  public async writeContentFile(options: {
    content: Content;
    contentDir: string;
  }) {
    const { content, contentDir } = options;
    if (!contentDir) {
      throw new Error('No content dir provided');
    }

    const { body } = content;
    const frontMatter = {
      title: content.title,
      slug: content.slug,
      context: content.context,
      author: content.author,
      publish_date: content.publish_date,
    };

    let output = '';
    if (frontMatter && Object.keys(frontMatter).length > 0) {
      output += '---\n';
      output += YAML.stringify(frontMatter);
      output += '---\n';
    }

    // Format body as markdown if it's plain text
    let formattedBody = body || '';
    if (body && !this.isMarkdown(body)) {
      formattedBody = this.formatAsMarkdown(body);
    }
    output += formattedBody;

    const pathParts = [
      contentDir,
      content.context || '', // if empty, use empty string
      content.slug,
      'index.md',
    ].filter(Boolean); // remove empty strings

    const outputFile = path.join(...(pathParts as string[]));
    await ensureDirectoryExists(path.dirname(outputFile));
    await writeFile(outputFile, output);
  }

  private isMarkdown(text: string): boolean {
    // Basic check for common markdown indicators
    const markdownIndicators = [
      /^#\s/m, // Headers
      /\*\*.+\*\*/, // Bold
      /\*.+\*/, // Italic
      /\[.+\]\(.+\)/, // Links
      /^\s*[-*+]\s/m, // Lists
      /^\s*\d+\.\s/m, // Numbered lists
      /```[\s\S]*```/, // Code blocks
      /^\s*>/m, // Blockquotes
    ];

    return markdownIndicators.some((indicator) => indicator.test(text));
  }

  private formatAsMarkdown(text: string): string {
    // Basic formatting of plain text to markdown
    return text
      .split(/\n\n+/)
      .map((paragraph) => paragraph.trim())
      .filter(Boolean)
      .join('\n\n');
  }

  public async syncContentDir(options: { contentDir?: string }) {
    const contentFilter = {
      type: 'article',
    };

    const contents = await this.list({ where: contentFilter });
    for (const content of contents) {
      await this.writeContentFile({
        content,
        contentDir: options.contentDir || this.options.contentDir || '',
      });
    }
  }

  // public async list(options: {
  //   where?: object;
  //   filter?: object;
  //   offset?: number;
  //   limit?: number;
  // }): Promise<Content[]> {
  //   const { where, filter, offset, limit } = options;

  //   const replacements: any[] = [];
  //   let currIndex = 1;

  //   let whereSql = '';
  //   if (where) {
  //     whereSql = 'where ';
  //     for (const [key, value] of Object.entries(where)) {
  //       whereSql += ` AND ${key} = $${currIndex++}`;
  //       replacements.push(value);
  //     }
  //   }

  //   let whereNotSql = '';
  //   if (filter) {
  //     if (whereSql) {
  //       whereNotSql = ' and ';
  //     } else {
  //       whereNotSql += ' where ';
  //     }
  //     for (const [key, value] of Object.entries(filter)) {
  //       whereNotSql += `${key} != $${currIndex++}`;
  //       replacements.push(value);
  //     }
  //   }

  //   const { rows } = await this._db.query(
  //     `SELECT * FROM contents ${whereSql} ${whereNotSql} LIMIT ${limit} OFFSET ${offset}`,
  //     replacements,
  //   );

  //   return Promise.all(rows.map((row: any) => this.create(row)));
  // }
}
</file>

<file path=".gitea/workflows/agents/claude/on-assigned-pr.yaml">
name: Process PR Review on Assignment

on:
  pull_request:
    types: [assigned]

jobs:
  process-pr-on-assignment:
    runs-on: ubuntu-latest
    # Only run when the PR is assigned to the designated bot user
    if: gitea.event.pr.assignee.login == 'claude'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0
      
      - name: Setup Tea CLI and get PR details
        id: pr
        run: |
          # Install gitea-cli if needed
          if ! command -v tea &> /dev/null; then
            curl -sL https://dl.gitea.io/tea/latest/linux/amd64/tea -o tea
            chmod +x tea
            mv tea /usr/local/bin/
          fi
          
          # Configure tea client
          tea login add -u ${{ vars.GITEA_URL }} --token ${{ secrets.GITEA_TOKEN }}
          
          # Get PR details
          REPO_NAME="${{ gitea.repository }}"
          PR_NUM="${{ gitea.event.pull_request.number }}"
          
          # Get branch name
          PR_BRANCH=$(tea pulls view "$REPO_NAME#$PR_NUM" --format '{{ .Head.Ref }}')
          echo "branch=$PR_BRANCH" >> $GITHUB_OUTPUT
          
          # Get PR comments
          PR_COMMENTS=$(tea pulls comments "$REPO_NAME#$PR_NUM" --format '{{ range . }}{{ .Body }}{{ "\n\n" }}{{ end }}')
          echo "comments<<EOF" >> $GITHUB_OUTPUT
          echo "$PR_COMMENTS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          # Get PR review comments
          PR_REVIEW_COMMENTS=$(tea pulls reviews "$REPO_NAME#$PR_NUM" --format '{{ range . }}{{ range .Comments }}{{ .Body }}{{ "\n\n" }}{{ end }}{{ end }}')
          echo "review_comments<<EOF" >> $GITHUB_OUTPUT
          echo "$PR_REVIEW_COMMENTS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: 'npm'
      
      - name: Install Claude Code CLI
        run: npm install -g @anthropic-ai/claude-code
      
      - name: Checkout PR branch
        run: |
          git checkout ${{ steps.pr.outputs.branch }}
      
      - name: Process PR comments with Claude Code
        run: |
          ALL_COMMENTS="${{ steps.pr.outputs.review_comments }}
          ${{ steps.pr.outputs.comments }}"
          # Pass the comments to Claude Code to process and make changes
          claude --print "Review the following PR feedback and make the requested changes: $ALL_COMMENTS"
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
      
      - name: Commit and push changes
        run: |
          git config user.name "Gitea Actions Bot"
          git config user.email "actions-bot@example.com"
          git add .
          git commit -m "Address PR review comments triggered by assignment" || echo "No changes to commit"
          git push origin ${{ steps.pr.outputs.branch }}
      
      - name: Add response comment to PR and unassign
        run: |
          REPO_NAME="${{ gitea.repository }}"
          PR_NUM="${{ gitea.event.pull_request.number }}"
          
          # Add comment to PR
          tea pulls comment "$REPO_NAME#$PR_NUM" --body "I've processed all review comments and made the requested changes. Please review the new commits."
          
          # Unassign the bot to indicate work is complete
          tea pulls edit "$REPO_NAME#$PR_NUM" --unassign ${{ gitea.event.assignee.login }}
</file>

<file path="CHANGELOG.md">
# Changelog

All notable changes to this project will be documented in this file. See [standard-version](https://github.com/conventional-changelog/standard-version) for commit guidelines.

### [0.0.50](https://git.grffn.net/happyvertical/sdk/compare/v0.0.49...v0.0.50) (2025-05-20)


### Features

* more details about assigned in test trigger ([3bc89a6](https://git.grffn.net/happyvertical/sdk/commit/3bc89a6eb0a2a42bde8c6436802878025e52b1bd))

### [0.0.49](https://git.grffn.net/happyvertical/sdk/compare/v0.0.48...v0.0.49) (2025-05-20)


### Features

* a setup_dev script for those who have all the repos in the same parent, eg me ([176c9da](https://git.grffn.net/happyvertical/sdk/commit/176c9daa057cd1237ca931980910ca98d2cf7b80))
* add gitea workflows for Claude agent integration ([a293227](https://git.grffn.net/happyvertical/sdk/commit/a2932276a0fb7de73dc5af86187e77ea1edb827c))
* added prettyDate function to utils ([41b0dfc](https://git.grffn.net/happyvertical/sdk/commit/41b0dfcdd484106105b6274cea2479e2bf6aca02))
* here comes the agentic coding, CLAUDE.md ([0bde29f](https://git.grffn.net/happyvertical/sdk/commit/0bde29f22ac9063fa6c21554088108306574ee98))
* migrated to biome ([b2c611c](https://git.grffn.net/happyvertical/sdk/commit/b2c611c7b8948f0cc0d0703434bb765ea4973429))
* the starts of a contributing guide ripped off from repomix base rules ([c0d7425](https://git.grffn.net/happyvertical/sdk/commit/c0d7425a605107df9707452cd41fc1bde6a0b7d6))
* update git hooks to use lefthook ([ad5261e](https://git.grffn.net/happyvertical/sdk/commit/ad5261ef917c1815c4f08cd56d1d8504acc33f2c))


### Bug Fixes

* setup_dev relative to script and use bin/env ([af3ccd1](https://git.grffn.net/happyvertical/sdk/commit/af3ccd17fbc262f27828f795c147bace54812f36))

### [0.0.48](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.47...v0.0.48) (2025-03-26)


### Features

* **smrt:** added count method to collection ([1feef8d](https://git.grffn.net/happyvertical/have-sdk/commit/1feef8ddaecf1a2ebcfeb97ac950b82d8ce2a90e))


### Bug Fixes

* **svelte:** description in list rendered as html ([83284fb](https://git.grffn.net/happyvertical/have-sdk/commit/83284fbda58d829cd0b73ba09076cdd360375df3))

### [0.0.47](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.46...v0.0.47) (2025-03-12)


### Bug Fixes

* import uses .js ([f52f924](https://git.grffn.net/happyvertical/have-sdk/commit/f52f92491784b8c4bec87376ace4ca752af19e8a))

### [0.0.46](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.45...v0.0.46) (2025-03-12)

### [0.0.45](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.44...v0.0.45) (2025-03-12)


### Features

* added orderBy to collection list ([caa9ded](https://git.grffn.net/happyvertical/have-sdk/commit/caa9ded99ad80bca8a1d3b135e82951dfec3d860))

### [0.0.44](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.43...v0.0.44) (2025-02-26)


### Features

* build:watch script for packages ([2e05566](https://git.grffn.net/happyvertical/have-sdk/commit/2e05566816d1965a16e7d7db68ce34eec9f01260))
* standardised buildWhere for sql queries, comparisons operators managed in object keys ([2b33211](https://git.grffn.net/happyvertical/have-sdk/commit/2b332118764d8731a32f38464c47244fab0f78ae))
* standardized scripts in like packages, added dev script ([c388a34](https://git.grffn.net/happyvertical/have-sdk/commit/c388a344af994f05f51b573cc66ffbd9eda3bb7e))

### [0.0.43](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.42...v0.0.43) (2025-02-22)


### Features

* replace semi-implemented "depreacted" field with "state" ([75a0b4a](https://git.grffn.net/happyvertical/have-sdk/commit/75a0b4ac4a21a1092563d832e241093e0d2f42ff))

### [0.0.42](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.41...v0.0.42) (2025-02-22)


### Bug Fixes

* loadFromSlug context default to blank string ([2c07bf7](https://git.grffn.net/happyvertical/have-sdk/commit/2c07bf702683884e0632a5bce7aaecf0f42eb8b1))

### [0.0.41](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.40...v0.0.41) (2025-02-22)


### Bug Fixes

* missing context vars ([e0c3db8](https://git.grffn.net/happyvertical/have-sdk/commit/e0c3db80d35eba692c7433a6fc7c705bd777b564))

### [0.0.40](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.39...v0.0.40) (2025-02-21)


### Features

* added a general purpose context to go along with the slug ([bbf9ef2](https://git.grffn.net/happyvertical/have-sdk/commit/bbf9ef29f7eb778f547941985237e10037cf90c8))

### [0.0.39](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.38...v0.0.39) (2025-02-19)


### Features

* **smrt:** added toJSON to Content ([897cb4f](https://git.grffn.net/happyvertical/have-sdk/commit/897cb4f431108b6b37ee51fea8b5f74cc4bea755))

### [0.0.38](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.37...v0.0.38) (2025-02-18)


### Bug Fixes

* storybook fixes ([d74d142](https://git.grffn.net/happyvertical/have-sdk/commit/d74d1423b3fb789c429ddc24bfa1815578ee8a1e))

### [0.0.37](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.36...v0.0.37) (2025-02-17)


### Features

* (barely) improve styling of article list and article ([9e6b5be](https://git.grffn.net/happyvertical/have-sdk/commit/9e6b5be456d18a45ae771a1684af3cd1a8217ef6))


### Bug Fixes

* css imports ([4c92e94](https://git.grffn.net/happyvertical/have-sdk/commit/4c92e941f6753e46a6baa9a3e8bf0583f3b551e0))

### [0.0.36](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.35...v0.0.36) (2025-02-17)


### Features

* added status column to content ([7830150](https://git.grffn.net/happyvertical/have-sdk/commit/78301500e2ae8045ac0440df0d89b6f6f5ca2537))

### [0.0.35](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.34...v0.0.35) (2025-02-17)


### Bug Fixes

* collection.get formats data to js ([a3e8dea](https://git.grffn.net/happyvertical/have-sdk/commit/a3e8deab555139eba8b03d8c40f6a9e16da7a4a2))

### [0.0.34](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.33...v0.0.34) (2025-02-16)


### Features

* specify contents directory for mirror function ([868f7c8](https://git.grffn.net/happyvertical/have-sdk/commit/868f7c8f0fa7a5fcaa56ce9a13872930c3da0422))

### [0.0.33](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.32...v0.0.33) (2025-02-15)


### Bug Fixes

* **svelte:** remove test style ([b32b3d5](https://git.grffn.net/happyvertical/have-sdk/commit/b32b3d5f37b6bd9e080b4362ff5f088de6c82ab4))

### [0.0.32](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.31...v0.0.32) (2025-02-15)


### Bug Fixes

* contentToString and stringToContent dont need to be async ([8279dd9](https://git.grffn.net/happyvertical/have-sdk/commit/8279dd92feb7c61652e5191bc26cace16dc2d901))

### [0.0.31](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.30...v0.0.31) (2025-02-15)


### Bug Fixes

* move pg from devDeps to deps in sql ([d27cdca](https://git.grffn.net/happyvertical/have-sdk/commit/d27cdca65880a0f2d22fa984a3ad7a40572c5462))

### [0.0.30](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.29...v0.0.30) (2025-02-15)

### [0.0.29](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.28...v0.0.29) (2025-02-15)


### Bug Fixes

* removed build config ([1dafd38](https://git.grffn.net/happyvertical/have-sdk/commit/1dafd382aa82450c4f07dbf2db81b3dad891a5a5))

### [0.0.28](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.27...v0.0.28) (2025-02-15)


### Features

* added vitest.config to smrt, vitest.workspace to root ([2791894](https://git.grffn.net/happyvertical/have-sdk/commit/279189473509d04054c6c46a0b1f7b8ceaa07ce4))
* ignore .svelte-kit ([8ba87d9](https://git.grffn.net/happyvertical/have-sdk/commit/8ba87d936d9a720f608a635bfb346a484a14cc9a))
* **smrt:** contentToString and stringToContent functions ([3b7b004](https://git.grffn.net/happyvertical/have-sdk/commit/3b7b004cc5261da990778e368ef23d85a5cb7740))

### [0.0.27](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.26...v0.0.27) (2025-02-15)

### [0.0.26](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.25...v0.0.26) (2025-02-15)


### Bug Fixes

* dont verify commit in version bump ([42c27a1](https://git.grffn.net/happyvertical/have-sdk/commit/42c27a1cef4a1ecbb1c9ca487217f8230439269e))

### [0.0.25](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.24...v0.0.25) (2025-02-15)


### Features

* package component exports ([edf178d](https://git.grffn.net/happyvertical/have-sdk/commit/edf178d36020bdd59481c2e3a954fdf78db0afbb))
* **svelte:** a very basic article component intial commit ([d7c279b](https://git.grffn.net/happyvertical/have-sdk/commit/d7c279bee760cb95b01d56dfddcb86cf3e8095a8))

### [0.0.24](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.23...v0.0.24) (2025-02-14)

### [0.0.23](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.22...v0.0.23) (2025-02-14)


### Bug Fixes

* remove the import style that i thought i already had ([32cf26a](https://git.grffn.net/happyvertical/have-sdk/commit/32cf26a3b77374f3c357dabc35a649f37145cbc2))

### [0.0.22](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.21...v0.0.22) (2025-02-14)


### Features

* moved styles to own directory, renamed export styles ([00b9b6a](https://git.grffn.net/happyvertical/have-sdk/commit/00b9b6a67ed005c0e8dde0fef3a976db8f898fc7))


### Bug Fixes

* added clsx and tailwind-merge to deps ([caf1f5b](https://git.grffn.net/happyvertical/have-sdk/commit/caf1f5bc85352fa5e294f211492f116b02dafe2d))
* dont import styles in index.ts ([96eab25](https://git.grffn.net/happyvertical/have-sdk/commit/96eab25070c1395cf18493905b95e703ea457d8b))

### [0.0.21](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.20...v0.0.21) (2025-02-14)


### Features

* **svelte:** export styles ([e3a3c9e](https://git.grffn.net/happyvertical/have-sdk/commit/e3a3c9e632af89fa673e2e3220bcc79de0a3b6c8))

### [0.0.20](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.19...v0.0.20) (2025-02-14)


### Bug Fixes

* more default exports ([c5a5be5](https://git.grffn.net/happyvertical/have-sdk/commit/c5a5be54db6e84c062e71e8c80e4b418c47d8605))

### [0.0.19](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.18...v0.0.19) (2025-02-14)


### Features

* **svelte:** added utils and tailwind-merge dep ([2876a80](https://git.grffn.net/happyvertical/have-sdk/commit/2876a80501cbf18e53215c641847220c9f331134))

### [0.0.18](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.17...v0.0.18) (2025-02-14)


### Bug Fixes

* set custom registry to default and also also in the svelte npmrc ([9908bde](https://git.grffn.net/happyvertical/have-sdk/commit/9908bded4e9f2fa8d3029230ed3071d580d1fe91))

### [0.0.17](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.16...v0.0.17) (2025-02-14)


### Features

* export Card ([38201be](https://git.grffn.net/happyvertical/have-sdk/commit/38201be9a5940e39ab552e8f8a44025fba11b1eb))


### Bug Fixes

* card export ([47f7807](https://git.grffn.net/happyvertical/have-sdk/commit/47f7807f158565566c19ed32ea395fef09697739))

### [0.0.16](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.15...v0.0.16) (2025-02-14)


### Features

* installed eslint, fixed a couple errors, added some rules to skip others and a bunch of warnings ([c3178bc](https://git.grffn.net/happyvertical/have-sdk/commit/c3178bc7ec8433d32b8191d35f4c247f5d5ea441))
* **svelte:** initial commit ([028c884](https://git.grffn.net/happyvertical/have-sdk/commit/028c884ecdf2c0e8f37e4298d30fb711dc2e6268))


### Bug Fixes

* better typing ([92c032d](https://git.grffn.net/happyvertical/have-sdk/commit/92c032dfdffceb66b87a742d3748054a135086fe))
* unignore lib and commit sveltes ([4440ae1](https://git.grffn.net/happyvertical/have-sdk/commit/4440ae12ce72e01854f2680fa15555010b88e759))

### [0.0.15](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.14...v0.0.15) (2025-02-13)


### Bug Fixes

* missed some contentDir ([46f7448](https://git.grffn.net/happyvertical/have-sdk/commit/46f744826ceaae6b36ad1f50eb855cf5c2581da4))

### [0.0.14](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.13...v0.0.14) (2025-02-13)


### Bug Fixes

* **pdf:** add vite config, more pdfs ([386fcc7](https://git.grffn.net/happyvertical/have-sdk/commit/386fcc7a21263cc052aaa419a0647629d25b4464))

### [0.0.13](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.12...v0.0.13) (2025-02-13)

### [0.0.12](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.11...v0.0.12) (2025-02-13)

### [0.0.11](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.10...v0.0.11) (2025-02-13)


### Bug Fixes

* .js on dynamic imports for db adapter ([0e11c6b](https://git.grffn.net/happyvertical/have-sdk/commit/0e11c6be252b834aaf24d9dc43950e66af4227b0))

### [0.0.10](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.9...v0.0.10) (2025-02-13)


### Bug Fixes

* proper extension for pdfjs ([01ffa20](https://git.grffn.net/happyvertical/have-sdk/commit/01ffa20f236cae3b3f9e348b85b843d630f28bc1))

### [0.0.9](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.8...v0.0.9) (2025-02-13)


### Bug Fixes

* couple missed ones ([febcbb1](https://git.grffn.net/happyvertical/have-sdk/commit/febcbb1672cdeff05006c1e314d4fc27b6c43485))

### [0.0.8](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.7...v0.0.8) (2025-02-13)

### [0.0.7](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.6...v0.0.7) (2025-02-13)

### [0.0.6](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.5...v0.0.6) (2025-02-12)

### [0.0.5](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.4...v0.0.5) (2025-02-12)

### [0.0.4](https://git.grffn.net/happyvertical/have-sdk/compare/v0.0.3...v0.0.4) (2025-02-12)

### 0.0.3 (2025-02-12)


### Features

* added publish command to root package.json ([20a6b00](https://git.grffn.net/happyvertical/have-sdk/commit/20a6b00b5ea9c239d71146783eded7090b2c044e))
* **ai:** intial commit ([12b2039](https://git.grffn.net/happyvertical/have-sdk/commit/12b20393b29d6248a5c3749beb6318736474b20f))
* **db:** initial commit, will be renamed from sql to db ([c6e2010](https://git.grffn.net/happyvertical/have-sdk/commit/c6e2010b0ef51af1772db961dc3ffebe49fbe75b))
* **files:** initial commit ([4ae52a9](https://git.grffn.net/happyvertical/have-sdk/commit/4ae52a94f2d91f5abb4ec8af4889a93c1ca44954))
* initial commit ([2d174da](https://git.grffn.net/happyvertical/have-sdk/commit/2d174da8910155b7d969d88a91210d5fba73c195))
* **pdf:** intiaial commit ([1d99717](https://git.grffn.net/happyvertical/have-sdk/commit/1d99717a259a866e1476f20e70f00c2441306883))
* publish-packages script ([3495ef3](https://git.grffn.net/happyvertical/have-sdk/commit/3495ef3064e3b96e0ff30a1600715aa8e3287cde))
* **smrt:** inital comit .. i mean c-o-m-m-i-t ([5251819](https://git.grffn.net/happyvertical/have-sdk/commit/525181921cb55a5b7e4856ac85205a8221a2dcfd))
* **spider:** initial commit ([d23c0c7](https://git.grffn.net/happyvertical/have-sdk/commit/d23c0c73de53735921a472ded710a0f52d91c364))
* **svelte:** initial commit ([384a812](https://git.grffn.net/happyvertical/have-sdk/commit/384a812cdb0843e0f18d1eb783db3847dd71722a))
* typescript happy.. for now ([ed0071e](https://git.grffn.net/happyvertical/have-sdk/commit/ed0071e7d449fce9ed9103d28f22b23a4bc0579b))
* use standard commits to bump version ([c2a789b](https://git.grffn.net/happyvertical/have-sdk/commit/c2a789ba253002aa8d0bb07a51372f6ed10c5925))
* **utils:** initial commit ([3a03ba2](https://git.grffn.net/happyvertical/have-sdk/commit/3a03ba210115ef23f3713bfdbf2ce1c0844aa5a3))


### Bug Fixes

* add auth for package repo ([fe3b7e0](https://git.grffn.net/happyvertical/have-sdk/commit/fe3b7e0d7792ed98e9c87400ea587d03da4da3d3))
* added build, skip verify in commit - should only need one, trying both ([0be2e61](https://git.grffn.net/happyvertical/have-sdk/commit/0be2e61f2d79d5a988a2aad642b00f0b6bea7267))
* added uuid dep ([fea128a](https://git.grffn.net/happyvertical/have-sdk/commit/fea128ad7ba3058947b3755befd713af4ae0fdf5))
* align svelte with base tsconfig compiler options ([fb25953](https://git.grffn.net/happyvertical/have-sdk/commit/fb259537fe5067124dbef21998c1c4d475efd2e8))
* build and typescript fixes for cicd.. i think baseUrl in tsconfig was the head vampire ([62fc552](https://git.grffn.net/happyvertical/have-sdk/commit/62fc552ef528553767bd9f041b6a7a7a5c7d7832))
* config git before release ([55b161b](https://git.grffn.net/happyvertical/have-sdk/commit/55b161be820fd7b29f7c8a16fd159254b99265a9))
* consolidate vite includes to root config ([f02d454](https://git.grffn.net/happyvertical/have-sdk/commit/f02d45495ed28495f711ac684becebdb4999f1a9))
* fetch in exports ([7c753da](https://git.grffn.net/happyvertical/have-sdk/commit/7c753da0754b7c8c77956620764443c3a41d20fc))
* install playwright browsers in cicd ([b0498c6](https://git.grffn.net/happyvertical/have-sdk/commit/b0498c6e7938f3d07f1425badeb07e1e1e048cc3))
* more getTempDir missed ([bb77fba](https://git.grffn.net/happyvertical/have-sdk/commit/bb77fba462d99d8698979a9e245a56d17d6746f0))
* remove packages from deps, exports from files for now ([253b777](https://git.grffn.net/happyvertical/have-sdk/commit/253b777fbf44f45a88608d9297e4eaf7421b3fa5))
* set root to private ([c6d7bb7](https://git.grffn.net/happyvertical/have-sdk/commit/c6d7bb7760e96b3d369926bdd297fef78f07645e))
* setup customer registry sooner ([27dfa34](https://git.grffn.net/happyvertical/have-sdk/commit/27dfa343c288d7914eea54e285a1c14b85f4212d))
* try just no-verify while investigating new build error for svelte ([bf3f5cc](https://git.grffn.net/happyvertical/have-sdk/commit/bf3f5ccef8bb943e5eb940bb9b5c052a23a95ad3))
* verticle -> vertical ([81b8ade](https://git.grffn.net/happyvertical/have-sdk/commit/81b8adec768382abe4170900b621e1cfc74e748d))

### [0.0.2](https://git.grffn.net:2222/happyvertical/have-sdk/compare/v0.0.1...v0.0.2) (2025-02-12)

### 0.0.1 (2025-02-12)


### Features

* added publish command to root package.json ([20a6b00](https://git.grffn.net:2222/happyvertical/have-sdk/commit/20a6b00b5ea9c239d71146783eded7090b2c044e))
* **ai:** intial commit ([12b2039](https://git.grffn.net:2222/happyvertical/have-sdk/commit/12b20393b29d6248a5c3749beb6318736474b20f))
* **db:** initial commit, will be renamed from sql to db ([c6e2010](https://git.grffn.net:2222/happyvertical/have-sdk/commit/c6e2010b0ef51af1772db961dc3ffebe49fbe75b))
* **files:** initial commit ([4ae52a9](https://git.grffn.net:2222/happyvertical/have-sdk/commit/4ae52a94f2d91f5abb4ec8af4889a93c1ca44954))
* initial commit ([2d174da](https://git.grffn.net:2222/happyvertical/have-sdk/commit/2d174da8910155b7d969d88a91210d5fba73c195))
* **pdf:** intiaial commit ([1d99717](https://git.grffn.net:2222/happyvertical/have-sdk/commit/1d99717a259a866e1476f20e70f00c2441306883))
* publish-packages script ([3495ef3](https://git.grffn.net:2222/happyvertical/have-sdk/commit/3495ef3064e3b96e0ff30a1600715aa8e3287cde))
* **smrt:** inital comit .. i mean c-o-m-m-i-t ([5251819](https://git.grffn.net:2222/happyvertical/have-sdk/commit/525181921cb55a5b7e4856ac85205a8221a2dcfd))
* **spider:** initial commit ([d23c0c7](https://git.grffn.net:2222/happyvertical/have-sdk/commit/d23c0c73de53735921a472ded710a0f52d91c364))
* **svelte:** initial commit ([384a812](https://git.grffn.net:2222/happyvertical/have-sdk/commit/384a812cdb0843e0f18d1eb783db3847dd71722a))
* typescript happy.. for now ([ed0071e](https://git.grffn.net:2222/happyvertical/have-sdk/commit/ed0071e7d449fce9ed9103d28f22b23a4bc0579b))
* **utils:** initial commit ([3a03ba2](https://git.grffn.net:2222/happyvertical/have-sdk/commit/3a03ba210115ef23f3713bfdbf2ce1c0844aa5a3))


### Bug Fixes

* add auth for package repo ([fe3b7e0](https://git.grffn.net:2222/happyvertical/have-sdk/commit/fe3b7e0d7792ed98e9c87400ea587d03da4da3d3))
* added build, skip verify in commit - should only need one, trying both ([0be2e61](https://git.grffn.net:2222/happyvertical/have-sdk/commit/0be2e61f2d79d5a988a2aad642b00f0b6bea7267))
* added uuid dep ([fea128a](https://git.grffn.net:2222/happyvertical/have-sdk/commit/fea128ad7ba3058947b3755befd713af4ae0fdf5))
* align svelte with base tsconfig compiler options ([fb25953](https://git.grffn.net:2222/happyvertical/have-sdk/commit/fb259537fe5067124dbef21998c1c4d475efd2e8))
* build and typescript fixes for cicd.. i think baseUrl in tsconfig was the head vampire ([62fc552](https://git.grffn.net:2222/happyvertical/have-sdk/commit/62fc552ef528553767bd9f041b6a7a7a5c7d7832))
* consolidate vite includes to root config ([f02d454](https://git.grffn.net:2222/happyvertical/have-sdk/commit/f02d45495ed28495f711ac684becebdb4999f1a9))
* fetch in exports ([7c753da](https://git.grffn.net:2222/happyvertical/have-sdk/commit/7c753da0754b7c8c77956620764443c3a41d20fc))
* more getTempDir missed ([bb77fba](https://git.grffn.net:2222/happyvertical/have-sdk/commit/bb77fba462d99d8698979a9e245a56d17d6746f0))
* remove packages from deps, exports from files for now ([253b777](https://git.grffn.net:2222/happyvertical/have-sdk/commit/253b777fbf44f45a88608d9297e4eaf7421b3fa5))
* set root to private ([c6d7bb7](https://git.grffn.net:2222/happyvertical/have-sdk/commit/c6d7bb7760e96b3d369926bdd297fef78f07645e))
* setup customer registry sooner ([27dfa34](https://git.grffn.net:2222/happyvertical/have-sdk/commit/27dfa343c288d7914eea54e285a1c14b85f4212d))
* try just no-verify while investigating new build error for svelte ([bf3f5cc](https://git.grffn.net:2222/happyvertical/have-sdk/commit/bf3f5ccef8bb943e5eb940bb9b5c052a23a95ad3))
* verticle -> vertical ([81b8ade](https://git.grffn.net:2222/happyvertical/have-sdk/commit/81b8adec768382abe4170900b621e1cfc74e748d))
</file>

<file path="packages/utils/package.json">
{
  "name": "@have/utils",
  "version": "0.0.50",
  "type": "module",
  "main": "dist/index.js",
  "types": "dist/index.d.ts",
  "exports": {
    ".": "./dist/index.js"
  },
  "scripts": {
    "test": "vitest",
    "test:watch": "vitest --watch",
    "build": "tsc -b",
    "build:watch": "tsc -b --watch",
    "clean": "rm -rf dist tsconfig.tsbuildinfo"
  },
  "engines": {
    "node": "22.x"
  },
  "dependencies": {
    "@paralleldrive/cuid2": "^2.2.2",
    "date-fns": "^3.3.1",
    "pluralize": "^8.0.0",
    "uuid": "^9.0.1"
  },
  "devDependencies": {
    "@types/node": "^20.12.8",
    "@types/pluralize": "^0.0.33",
    "@types/uuid": "^10.0.0"
  },
  "files": [
    "dist"
  ]
}
</file>

<file path="packages/ai/package.json">
{
  "name": "@have/ai",
  "version": "0.0.50",
  "main": "dist/index.js",
  "types": "dist/index.d.ts",
  "exports": {
    ".": "./dist/index.js"
  },
  "type": "module",
  "scripts": {
    "test": "vitest",
    "test:watch": "vitest --watch",
    "build": "tsc -b",
    "build:watch": "tsc -b --watch",
    "clean": "rm -rf dist tsconfig.tsbuildinfo",
    "prebuild": "npm run clean",
    "dev": "pnpm run build:watch & pnpm run test:watch"
  },
  "engines": {
    "node": "22.x"
  },
  "dependencies": {
    "openai": "^4.78.1"
  },
  "devDependencies": {
    "vitest": "^1.2.2",
    "@types/node": "^22.10.7"
  }
}
</file>

<file path="packages/files/package.json">
{
  "name": "@have/files",
  "version": "0.0.50",
  "type": "module",
  "main": "dist/index.js",
  "types": "dist/index.d.ts",
  "exports": {
    ".": "./dist/index.js"
  },
  "scripts": {
    "test": "vitest",
    "test:watch": "vitest --watch",
    "build": "tsc -b",
    "build:watch": "tsc -b --watch",
    "clean": "rm -rf dist tsconfig.tsbuildinfo",
    "prebuild": "npm run clean",
    "dev": "pnpm run build:watch & pnpm run test:watch"
  },
  "engines": {
    "node": "22.x"
  },
  "dependencies": {
    "@have/utils": "workspace:*"
  },
  "devDependencies": {
    "@types/node": "^20.12.8"
  },
  "files": [
    "dist"
  ]
}
</file>

<file path="packages/smrt/package.json">
{
  "name": "@have/smrt",
  "version": "0.0.50",
  "author": "Will Griffin <willgriffin@gmail.com>",
  "type": "module",
  "main": "dist/index.js",
  "types": "dist/index.d.ts",
  "exports": {
    ".": "./dist/index.js",
    "./utils": "./dist/utils.js"
  },
  "dependencies": {
    "@have/ai": "workspace:*",
    "@have/files": "workspace:*",
    "@have/pdf": "workspace:*",
    "@have/sql": "workspace:*",
    "@have/spider": "workspace:*",
    "@have/utils": "workspace:*",
    "@langchain/community": "^0.3.24",
    "cheerio": "^1.0.0",
    "yaml": "^2.7.0"
  },
  "scripts": {
    "test": "vitest",
    "test:watch": "vitest --watch",
    "build": "tsc -b",
    "build:watch": "tsc -b --watch",
    "clean": "rm -rf dist",
    "prebuild": "npm run clean",
    "dev": "pnpm run build:watch & pnpm run test:watch"
  },
  "engines": {
    "node": "22.x"
  },
  "devDependencies": {
    "@faker-js/faker": "^9.4.0",
    "@paralleldrive/cuid2": "^2.2.2",
    "@types/node": "^22.10.7",
    "pdf-parse": "^1.1.1",
    "pdfjs-dist": "^4.10.38",
    "scribe.js-ocr": "^0.7.0"
  }
}
</file>

<file path="packages/spider/package.json">
{
  "name": "@have/spider",
  "version": "0.0.50",
  "type": "module",
  "main": "dist/index.js",
  "types": "dist/index.d.ts",
  "exports": {
    ".": "./dist/index.js"
  },
  "scripts": {
    "test": "vitest",
    "test:watch": "vitest --watch",
    "build": "tsc -b",
    "build:watch": "tsc -b --watch",
    "clean": "rm -rf dist",
    "prebuild": "npm run clean",
    "dev": "pnpm run build:watch & pnpm run test:watch"
  },
  "engines": {
    "node": "22.x"
  },
  "dependencies": {
    "@have/files": "workspace:*",
    "@have/utils": "workspace:*",
    "@mozilla/readability": "^0.5.0",
    "@playwright/browser-chromium": "^1.49.1",
    "cheerio": "^1.0.0",
    "playwright": "^1.49.1",
    "playwright-core": "^1.49.1"
  }
}
</file>

<file path="packages/sql/package.json">
{
  "name": "@have/sql",
  "version": "0.0.50",
  "type": "module",
  "main": "dist/index.js",
  "types": "dist/index.d.ts",
  "exports": {
    ".": "./dist/index.js"
  },
  "scripts": {
    "test": "vitest",
    "test:watch": "vitest --watch",
    "build": "tsc -b",
    "build:watch": "tsc -b --watch",
    "clean": "rm -rf dist",
    "prebuild": "npm run clean",
    "dev": "pnpm run build:watch & pnpm run test:watch"
  },
  "keywords": [],
  "author": "willgriffin@gmail.com",
  "license": "ISC",
  "dependencies": {
    "@libsql/client": "^0.14.0",
    "sqlite-vss": "^0.1.2",
    "pg": "^8.13.1"
  },
  "devDependencies": {
    "@types/node": "^22.10.7",
    "@types/pg": "^8.11.10",
    "vitest": "^1.2.2"
  },
  "engines": {
    "node": "22.x"
  }
}
</file>

<file path="packages/pdf/package.json">
{
  "name": "@have/pdf",
  "version": "0.0.50",
  "type": "module",
  "main": "dist/index.js",
  "types": "dist/index.d.ts",
  "exports": {
    ".": "./dist/index.js"
  },
  "scripts": {
    "test": "vitest",
    "test:watch": "vitest --watch",
    "build": "tsc -b",
    "build:watch": "tsc -b --watch",
    "clean": "rm -rf dist",
    "prebuild": "npm run clean",
    "dev": "pnpm run build:watch & pnpm run test:watch"
  },
  "engines": {
    "node": "22.x"
  },
  "dependencies": {
    "date-fns": "^4.1.0",
    "pluralize": "^8.0.0",
    "pdfjs-dist": "^4.10.38",
    "scribe.js-ocr": "^0.8.0",
    "tesseract.js": "^6.0.0"
  },
  "devDependencies": {
    "@types/pdfjs-dist": "^2.10.378",
    "@types/pluralize": "^0.0.33"
  }
}
</file>

<file path="package.json">
{
  "name": "@have/sdk",
  "private": true,
  "author": "Will Griffin <willgriffin@gmail.com>",
  "type": "module",
  "version": "0.0.50",
  "scripts": {
    "format": "biome format --write .",
    "format-check": "biome format --check .",
    "prepare": "lefthook install",
    "test": "vitest",
    "test:watch": "vitest --watch",
    "lint": "biome lint .",
    "lint:fix": "biome lint --apply .",
    "clean": "pnpm -r exec rm -rf dist && pnpm -r exec rm -rf tsconfig.tsbuildinfo",
    "build": "pnpm clean && pnpm --filter @have/utils build && pnpm --filter @have/files build && pnpm --filter @have/spider build && pnpm --filter @have/sql build && pnpm --filter @have/pdf build && pnpm --filter @have/ai build && pnpm --filter @have/smrt build && pnpm --filter @have/svelte build && pnpm repomix",
    "dev": "pnpm --parallel -r build:watch",
    "publish-packages": "pnpm build && changeset publish",
    "release": "standard-version --no-verify",
    "postrelease": "node scripts/update-package-versions.cjs"
  },
  "devDependencies": {
    "@biomejs/biome": "^1.5.3",
    "@changesets/cli": "^2.27.12",
    "conventional-changelog-cli": "^5.0.0",
    "lefthook": "^1.11.13",
    "repomix": "^0.3.6",
    "standard-version": "^9.5.0",
    "typescript": "^5.7.3",
    "vitest": "^3.1.1"
  },
  "resolutions": {
    "@types/node": "22.13.0"
  },
  "engines": {
    "node": "22.x"
  }
}
</file>

<file path=".gitea/workflows/agents/claude/on-assigned-issue.yaml">
name: Create PR from Issue Assignment

on:
  issues:
    types: [assigned]

jobs:
  create-pr-on-assignment:
    runs-on: ubuntu-latest
    if: gitea.event.issue.assignee.login == 'claude'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Get issue details
        id: get-issue-details
        run: |
          echo "Fetching issue details..."
          echo "Gitea Token: ${{ secrets.GITEA_TOKEN }}"

          # Install gitea-cli if needed
          if ! command -v tea &> /dev/null; then
            echo "Installing gitea-cli..."
            curl -sL https://dl.gitea.io/tea/main/tea-main-linux-amd64 -o tea
            chmod +x tea
            mv tea /usr/local/bin/
          fi
          REPO_NAME="${{ gitea.repository }}"
          echo $REPO_NAME
          ISSUE_NUM="${{ gitea.event.issue.number }}"
          echo $ISSUE_NUM
          tea login add -u https://git.grffn.net/ --token ${{ secrets.GITEA_TOKEN }}
          echo "logged in successfully"
          # tea issue view "$REPO_NAME#$ISSUE_NUM" --format '{{ .Title }}''
          ISSUE_TITLE=$(tea issue --repo $REPO_NAME $ISSUE_NUM --format '{{ .Title }}')
          echo $ISSUE_TITLE
          ISSUE_BODY=$(tea issue --repo $REPO_NAME $ISSUE_NUM)
          echo $ISSUE_BODY
          echo "title=$ISSUE_TITLE" >> $GITHUB_OUTPUT
          echo "body=<<EOF" >> $GITHUB_OUTPUT
          echo "$ISSUE_BODY" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
      
      - name: Install Claude Code CLI
        run: npm install -g @anthropic-ai/claude-code
      
      - name: Create branch and changes
        run: |
          # Use issue number for branch name
          BRANCH_NAME="issue-${{ gitea.event.issue.number }}"
          git checkout -b $BRANCH_NAME
          git push --set-upstream origin $BRANCH_NAME
          REPO_NAME="${{ gitea.repository }}"
          echo $REPO_NAME
          ISSUE_NUM="${{ gitea.event.issue.number }}"
          echo $ISSUE_NUM

          ISSUE_BODY=$(tea issue --repo $REPO_NAME $ISSUE_NUM)

          echo "Create changes to address this issue: 
          Title: ${{ steps.get-issue-details.outputs.title }} 
          Description: ${{ steps.get-issue-details.outputs.body }}"

          # Call Claude Code with issue content as context
          claude  --print "Create changes to address this issue: 
          Title: ${{ steps.get-issue-details.outputs.title }} 
          Description: $ISSUE_BODY"
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
      
      - name: Push changes and create PR
        run: |
          git config user.name "Gitea Actions Bot"
          git config user.email "actions-bot@example.com"
          git add .
          git commit -m "Address issue #${{ gitea.event.issue.number }}" || echo "No changes to commit"
          git push origin $BRANCH_NAME          
          # Create PR using tea CLI
          REPO_NAME="${{ gitea.repository }}"
          tea pulls create \
            --repo "$REPO_NAME" \
            --base "main" \
            --head "$BRANCH_NAME" \
            --title "Fix #${{ gitea.event.issue.number }}: ${{ steps.get-issue-details.outputs.title }}" \
            --body "This PR addresses issue #${{ gitea.event.issue.number }} \
              Original issue description: \
              ${{ steps.get-issue-details.outputs.body }}"          
          # Add a comment on the issue with the PR link
          PR_URL="${{ vars.GITEA_URL }}/$REPO_NAME/pulls/$(tea pulls list --repo "$REPO_NAME" --head "$BRANCH_NAME" --format '{{ .Index }}')"
          tea issue comment "$REPO_NAME#${{ gitea.event.issue.number }}" --body "I've created PR: $PR_URL to address this issue."
          tea issue label "$REPO_NAME#${{ gitea.event.issue.number }}" --add "pr-created"
</file>

</files>
